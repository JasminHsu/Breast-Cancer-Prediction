{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "caaf154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import model_selection, linear_model, preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve, \\\n",
    "StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, average_precision_score, roc_curve, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85faa5",
   "metadata": {},
   "source": [
    "## Numeric Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24faf8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety  class\n",
       "0     vhigh  vhigh      2       2    small    low  unacc\n",
       "1     vhigh  vhigh      2       2    small    med  unacc\n",
       "2     vhigh  vhigh      2       2    small   high  unacc\n",
       "3     vhigh  vhigh      2       2      med    low  unacc\n",
       "4     vhigh  vhigh      2       2      med    med  unacc\n",
       "...     ...    ...    ...     ...      ...    ...    ...\n",
       "1723    low    low  5more    more      med    med   good\n",
       "1724    low    low  5more    more      med   high  vgood\n",
       "1725    low    low  5more    more      big    low  unacc\n",
       "1726    low    low  5more    more      big    med   good\n",
       "1727    low    low  5more    more      big   high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "car = pd.read_csv('car.data', names=['buying','maint','doors','persons','lug_boot','safety','class'])\n",
    "car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b26e317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh' 'high' 'med' 'low'] : 4\n",
      "['vhigh' 'high' 'med' 'low'] : 4\n",
      "['2' '3' '4' '5more'] : 4\n",
      "['2' '4' 'more'] : 3\n",
      "['small' 'med' 'big'] : 3\n",
      "['low' 'med' 'high'] : 3\n",
      "['unacc' 'acc' 'vgood' 'good'] : 4\n"
     ]
    }
   ],
   "source": [
    "# As all the columns are categorical, check for unique values of each column\n",
    "# Check categorical values in each column\n",
    "for i in car.columns:\n",
    "    print(car[i].unique(),':',car[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "55a0676e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      False\n",
       "maint       False\n",
       "doors       False\n",
       "persons     False\n",
       "lug_boot    False\n",
       "safety      False\n",
       "class       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing value\n",
    "car.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92a540f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying  maint  doors  persons  lug_boot  safety  class\n",
       "0     1.0    1.0    0.0      0.0       0.0     0.0  unacc\n",
       "1     1.0    1.0    0.0      0.0       0.0     0.5  unacc\n",
       "2     1.0    1.0    0.0      0.0       0.0     1.0  unacc\n",
       "3     1.0    1.0    0.0      0.0       0.5     0.0  unacc\n",
       "4     1.0    1.0    0.0      0.0       0.5     0.5  unacc"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numeric variable\n",
    "car.replace({'buying':{'low':0,'med':1/3,'high':2/3, 'vhigh':1}},inplace=True)\n",
    "car.replace({'maint':{'low':0,'med':1/3,'high':2/3, 'vhigh':1}},inplace=True)\n",
    "car.replace({'doors':{'2':0,'3':1/3,'4':2/3,'5more':1}},inplace=True)\n",
    "car.replace({'persons':{'2':0,'4':0.5,'more':1}},inplace=True)\n",
    "car.replace({'lug_boot':{'small':0,'med':0.5,'big':1}},inplace=True)\n",
    "car.replace({'safety':{'low':0,'med':0.5,'high':1}},inplace=True)\n",
    "#car.replace({'class':{'unacc':0,'acc':1/3,'good':2/3,'vgood':1}},inplace=True)\n",
    "car.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af9a94",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4d6be792",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = car.iloc[:,:6]\n",
    "y = car['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=45)\n",
    "f_measure_score = {'decision_tree':{},'knn':{},'logistic':{},'NB':{},'svm':{}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e974e1",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bef81dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756        nan 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      "        nan 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756        nan 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      "        nan 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574        nan 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      "        nan 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574        nan 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      "        nan 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345        nan 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      "        nan 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345        nan 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      "        nan 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609        nan 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      "        nan 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609        nan 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      "        nan 0.90404048 0.90404048 0.90404048 0.90404048 0.90404048\n",
      " 0.90317091 0.90317091 0.90230885        nan 0.90404048 0.90404048\n",
      " 0.90404048 0.90404048 0.90404048 0.90317091 0.90317091 0.90230885\n",
      "        nan 0.90317091 0.90317091 0.90317091 0.90317091 0.90317091\n",
      " 0.90317091 0.90317091 0.90230885        nan 0.90144678 0.90144678\n",
      " 0.90144678 0.90144678 0.90144678 0.90144678 0.90144678 0.90058471\n",
      "        nan 0.92133433 0.92305847 0.92392054 0.92392054 0.92305847\n",
      " 0.92218891 0.92218891 0.92132684        nan 0.92392054 0.92392054\n",
      " 0.92392054 0.92392054 0.92305847 0.92218891 0.92218891 0.92132684\n",
      "        nan 0.92478261 0.92478261 0.92478261 0.92478261 0.92478261\n",
      " 0.92478261 0.92478261 0.92392054        nan 0.92478261 0.92478261\n",
      " 0.92478261 0.92478261 0.92478261 0.92478261 0.92478261 0.92392054\n",
      "        nan 0.9489955  0.95072714 0.94727136 0.94727136 0.94295352\n",
      " 0.9412069  0.93862069 0.93342579        nan 0.94553223 0.94553223\n",
      " 0.94553223 0.94985757 0.94553973 0.9437931  0.94034483 0.93514993\n",
      "        nan 0.94467016 0.94467016 0.94467016 0.94467016 0.94467016\n",
      " 0.94465517 0.9412069  0.93601199        nan 0.93688906 0.93688906\n",
      " 0.93688906 0.93688906 0.93688906 0.93688906 0.93688906 0.93341829\n",
      "        nan 0.961994   0.96373313 0.95766867 0.96112444 0.9568066\n",
      " 0.95504498 0.9489955  0.9412069         nan 0.95937781 0.95937781\n",
      " 0.95937781 0.96110945 0.96025487 0.95763118 0.95071964 0.94293103\n",
      "        nan 0.95764618 0.95764618 0.95764618 0.95764618 0.95764618\n",
      " 0.95849325 0.95071214 0.94466267        nan 0.94726387 0.94726387\n",
      " 0.94726387 0.94726387 0.94726387 0.94726387 0.94726387 0.94293103\n",
      "        nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721        nan 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      "        nan 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721        nan 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      "        nan 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654        nan 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      "        nan 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654        nan 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      "        nan 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099         nan 0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      "        nan 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099         nan 0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      "        nan 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687        nan 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      "        nan 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687        nan 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      "        nan 0.91352324 0.91352324 0.91352324 0.91352324 0.91352324\n",
      " 0.91352324 0.91352324 0.91266117        nan 0.91352324 0.91352324\n",
      " 0.91352324 0.91352324 0.91352324 0.91352324 0.91352324 0.91266117\n",
      "        nan 0.91352324 0.91352324 0.91352324 0.91352324 0.91352324\n",
      " 0.91352324 0.91352324 0.91266117        nan 0.9117991  0.9117991\n",
      " 0.9117991  0.9117991  0.9117991  0.9117991  0.9117991  0.91093703\n",
      "        nan 0.92910795 0.92910795 0.92824588 0.92824588 0.92824588\n",
      " 0.92824588 0.92910795 0.92824588        nan 0.92910795 0.92910795\n",
      " 0.92910795 0.92910795 0.92910795 0.92910795 0.92910795 0.92824588\n",
      "        nan 0.92910795 0.92910795 0.92910795 0.92910795 0.92910795\n",
      " 0.92910795 0.92910795 0.92824588        nan 0.92651424 0.92651424\n",
      " 0.92651424 0.92651424 0.92651424 0.92651424 0.92651424 0.92651424\n",
      "        nan 0.95330585 0.95503748 0.95158921 0.95245127 0.95071964\n",
      " 0.95071964 0.95158171 0.94724888        nan 0.94986507 0.94986507\n",
      " 0.94986507 0.95245127 0.95071964 0.95071964 0.95158171 0.94724888\n",
      "        nan 0.95071964 0.95071964 0.95071964 0.95071964 0.95071964\n",
      " 0.95071964 0.95071964 0.94638681        nan 0.94638681 0.94638681\n",
      " 0.94638681 0.94638681 0.94638681 0.94638681 0.94638681 0.94377811\n",
      "        nan 0.96369565 0.96370315 0.96025487 0.95938531 0.95852324\n",
      " 0.95938531 0.95937031 0.95331334        nan 0.9567916  0.9567916\n",
      " 0.9567916  0.95850825 0.95938531 0.95938531 0.95937031 0.95331334\n",
      "        nan 0.96024738 0.96024738 0.96024738 0.96024738 0.96024738\n",
      " 0.95938531 0.95764618 0.95158921        nan 0.9516042  0.9516042\n",
      " 0.9516042  0.9516042  0.9516042  0.9516042  0.9516042  0.94985757]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085        nan 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      "        nan 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085        nan 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      "        nan 0.84562862 0.84562862 0.84562862 0.84562862 0.84562862\n",
      " 0.84562862 0.84562862 0.84562862        nan 0.84562862 0.84562862\n",
      " 0.84562862 0.84562862 0.84562862 0.84562862 0.84562862 0.84562862\n",
      "        nan 0.84562862 0.84562862 0.84562862 0.84562862 0.84562862\n",
      " 0.84562862 0.84562862 0.84562862        nan 0.84562862 0.84562862\n",
      " 0.84562862 0.84562862 0.84562862 0.84562862 0.84562862 0.84562862\n",
      "        nan 0.87329611 0.87329611 0.87329611 0.87329611 0.87329611\n",
      " 0.87329611 0.87329611 0.87329611        nan 0.87329611 0.87329611\n",
      " 0.87329611 0.87329611 0.87329611 0.87329611 0.87329611 0.87329611\n",
      "        nan 0.87329611 0.87329611 0.87329611 0.87329611 0.87329611\n",
      " 0.87329611 0.87329611 0.87329611        nan 0.87329611 0.87329611\n",
      " 0.87329611 0.87329611 0.87329611 0.87329611 0.87329611 0.87329611\n",
      "        nan 0.93437138 0.93437138 0.93437138 0.93437138 0.93437138\n",
      " 0.93437138 0.93437138 0.93437138        nan 0.93437138 0.93437138\n",
      " 0.93437138 0.93437138 0.93437138 0.93437138 0.93437138 0.93437138\n",
      "        nan 0.93437138 0.93437138 0.93437138 0.93437138 0.93437138\n",
      " 0.93437138 0.93437138 0.93437138        nan 0.93437138 0.93437138\n",
      " 0.93437138 0.93437138 0.93437138 0.93437138 0.93437138 0.93437138\n",
      "        nan 0.92666667 0.92666667 0.92666667 0.92666667 0.92666667\n",
      " 0.92666667 0.92666667 0.92666667        nan 0.92666667 0.92666667\n",
      " 0.92666667 0.92666667 0.92666667 0.92666667 0.92666667 0.92666667\n",
      "        nan 0.92666667 0.92666667 0.92666667 0.92666667 0.92666667\n",
      " 0.92666667 0.92666667 0.92666667        nan 0.92666667 0.92666667\n",
      " 0.92666667 0.92666667 0.92666667 0.92666667 0.92666667 0.92666667\n",
      "        nan 0.9691067  0.9691067  0.9691067  0.9691067  0.96461125\n",
      " 0.95945409 0.95817204 0.95753102        nan 0.96781638 0.96781638\n",
      " 0.96781638 0.96781638 0.96461125 0.95945409 0.95817204 0.95753102\n",
      "        nan 0.96267577 0.96267577 0.96267577 0.96267577 0.96267577\n",
      " 0.95945409 0.95817204 0.95753102        nan 0.95688586 0.95688586\n",
      " 0.95688586 0.95688586 0.95688586 0.95688586 0.95688586 0.95624483\n",
      "        nan 0.97104632 0.97040116 0.96847395 0.96911497 0.96461952\n",
      " 0.96010339 0.95560794 0.95304384        nan 0.96911084 0.96911084\n",
      " 0.96911084 0.96911084 0.96526055 0.96010339 0.95560794 0.95304384\n",
      "        nan 0.96332506 0.96332506 0.96332506 0.96332506 0.96332506\n",
      " 0.96010339 0.95560794 0.95304384        nan 0.95432175 0.95432175\n",
      " 0.95432175 0.95432175 0.95432175 0.95432175 0.95432175 0.9530397\n",
      "        nan 0.9839206  0.98263027 0.9800579  0.9761952  0.97041356\n",
      " 0.96075269 0.95624897 0.95368486        nan 0.97747725 0.97747725\n",
      " 0.97747725 0.97554591 0.97105459 0.96075269 0.95624897 0.95368486\n",
      "        nan 0.96782878 0.96782878 0.96782878 0.96782878 0.96782878\n",
      " 0.96075269 0.95624897 0.95368486        nan 0.95496278 0.95496278\n",
      " 0.95496278 0.95496278 0.95496278 0.95496278 0.95496278 0.95368073\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085        nan 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      "        nan 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085        nan 0.79033085 0.79033085\n",
      " 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085 0.79033085\n",
      "        nan 0.83664185 0.83664185 0.83664185 0.83664185 0.83664185\n",
      " 0.83664185 0.83664185 0.83664185        nan 0.83664185 0.83664185\n",
      " 0.83664185 0.83664185 0.83664185 0.83664185 0.83664185 0.83664185\n",
      "        nan 0.83664185 0.83664185 0.83664185 0.83664185 0.83664185\n",
      " 0.83664185 0.83664185 0.83664185        nan 0.83664185 0.83664185\n",
      " 0.83664185 0.83664185 0.83664185 0.83664185 0.83664185 0.83664185\n",
      "        nan 0.85979322 0.85979322 0.85979322 0.85979322 0.85979322\n",
      " 0.85979322 0.85979322 0.85979322        nan 0.85979322 0.85979322\n",
      " 0.85979322 0.85979322 0.85979322 0.85979322 0.85979322 0.85979322\n",
      "        nan 0.85979322 0.85979322 0.85979322 0.85979322 0.85979322\n",
      " 0.85979322 0.85979322 0.85979322        nan 0.85979322 0.85979322\n",
      " 0.85979322 0.85979322 0.85979322 0.85979322 0.85979322 0.85979322\n",
      "        nan 0.91444996 0.91444996 0.91444996 0.91444996 0.91444996\n",
      " 0.91444996 0.91444996 0.91444996        nan 0.91444996 0.91444996\n",
      " 0.91444996 0.91444996 0.91444996 0.91444996 0.91444996 0.91444996\n",
      "        nan 0.91444996 0.91444996 0.91444996 0.91444996 0.91444996\n",
      " 0.91444996 0.91444996 0.91444996        nan 0.91444996 0.91444996\n",
      " 0.91444996 0.91444996 0.91444996 0.91444996 0.91444996 0.91444996\n",
      "        nan 0.92411497 0.92411497 0.92411497 0.92411497 0.92411497\n",
      " 0.92411497 0.92411497 0.92411497        nan 0.92411497 0.92411497\n",
      " 0.92411497 0.92411497 0.92411497 0.92411497 0.92411497 0.92411497\n",
      "        nan 0.92411497 0.92411497 0.92411497 0.92411497 0.92411497\n",
      " 0.92411497 0.92411497 0.92411497        nan 0.92411497 0.92411497\n",
      " 0.92411497 0.92411497 0.92411497 0.92411497 0.92411497 0.92411497\n",
      "        nan 0.95754342 0.95754342 0.95754342 0.95754342 0.95754342\n",
      " 0.95432175 0.95175765 0.95111663        nan 0.95754342 0.95754342\n",
      " 0.95754342 0.95754342 0.95754342 0.95432175 0.95175765 0.95111663\n",
      "        nan 0.95560794 0.95560794 0.95560794 0.95560794 0.95560794\n",
      " 0.95432175 0.95175765 0.95111663        nan 0.95240281 0.95240281\n",
      " 0.95240281 0.95240281 0.95240281 0.95240281 0.95240281 0.95176179\n",
      "        nan 0.96911497 0.96783292 0.96526055 0.96589744 0.96654673\n",
      " 0.96203474 0.96011166 0.95754756        nan 0.96654673 0.96654673\n",
      " 0.96654673 0.9665426  0.96654673 0.96203474 0.96011166 0.95754756\n",
      "        nan 0.96525641 0.96525641 0.96525641 0.96525641 0.96525641\n",
      " 0.96332506 0.96140199 0.95883788        nan 0.96141026 0.96141026\n",
      " 0.96141026 0.96141026 0.96141026 0.96141026 0.96141026 0.96012821\n",
      "        nan 0.97489247 0.97297767 0.97104632 0.97040116 0.96976013\n",
      " 0.96203474 0.96075682 0.95754342        nan 0.97040116 0.97040116\n",
      " 0.97040116 0.97040116 0.96976013 0.96203474 0.96075682 0.95754342\n",
      "        nan 0.96718362 0.96718362 0.96718362 0.96718362 0.96718362\n",
      " 0.96332506 0.96140199 0.95883375        nan 0.96141026 0.96141026\n",
      " 0.96141026 0.96141026 0.96141026 0.96141026 0.96141026 0.96012407]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182        nan 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      "        nan 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182        nan 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      "        nan 0.84179901 0.84179901 0.84179901 0.84179901 0.84179901\n",
      " 0.84179901 0.84179901 0.84179901        nan 0.84179901 0.84179901\n",
      " 0.84179901 0.84179901 0.84179901 0.84179901 0.84179901 0.84179901\n",
      "        nan 0.84179901 0.84179901 0.84179901 0.84179901 0.84179901\n",
      " 0.84179901 0.84179901 0.84179901        nan 0.84179901 0.84179901\n",
      " 0.84179901 0.84179901 0.84179901 0.84179901 0.84179901 0.84179901\n",
      "        nan 0.87842432 0.87842432 0.87842432 0.87842432 0.87842432\n",
      " 0.87842432 0.87842432 0.87842432        nan 0.87842432 0.87842432\n",
      " 0.87842432 0.87842432 0.87842432 0.87842432 0.87842432 0.87842432\n",
      "        nan 0.87842432 0.87842432 0.87842432 0.87842432 0.87842432\n",
      " 0.87842432 0.87842432 0.87842432        nan 0.87842432 0.87842432\n",
      " 0.87842432 0.87842432 0.87842432 0.87842432 0.87842432 0.87842432\n",
      "        nan 0.9357072  0.9357072  0.9357072  0.9357072  0.9357072\n",
      " 0.9357072  0.9357072  0.9357072         nan 0.9357072  0.9357072\n",
      " 0.9357072  0.9357072  0.9357072  0.9357072  0.9357072  0.9357072\n",
      "        nan 0.9357072  0.9357072  0.9357072  0.9357072  0.9357072\n",
      " 0.9357072  0.9357072  0.9357072         nan 0.9357072  0.9357072\n",
      " 0.9357072  0.9357072  0.9357072  0.9357072  0.9357072  0.9357072\n",
      "        nan 0.91963606 0.91963606 0.91963606 0.91963606 0.91963606\n",
      " 0.91963606 0.91963606 0.91963606        nan 0.91963606 0.91963606\n",
      " 0.91963606 0.91963606 0.91963606 0.91963606 0.91963606 0.91963606\n",
      "        nan 0.91963606 0.91963606 0.91963606 0.91963606 0.91963606\n",
      " 0.91963606 0.91963606 0.91963606        nan 0.91963606 0.91963606\n",
      " 0.91963606 0.91963606 0.91963606 0.91963606 0.91963606 0.91963606\n",
      "        nan 0.96847395 0.96847395 0.96847395 0.96847395 0.96398263\n",
      " 0.95882961 0.9569024  0.9569024         nan 0.96526882 0.96526882\n",
      " 0.96526882 0.96526882 0.96398263 0.95882961 0.9569024  0.9569024\n",
      "        nan 0.96140199 0.96140199 0.96140199 0.96140199 0.96140199\n",
      " 0.95882961 0.9569024  0.9569024         nan 0.9569024  0.9569024\n",
      " 0.9569024  0.9569024  0.9569024  0.9569024  0.9569024  0.9569024\n",
      "        nan 0.97041356 0.97105459 0.97105459 0.97169975 0.9678536\n",
      " 0.96141853 0.95434657 0.95370968        nan 0.96978081 0.96978081\n",
      " 0.96978081 0.96978081 0.96913978 0.96141853 0.95562862 0.95499173\n",
      "        nan 0.96463193 0.96463193 0.96463193 0.96463193 0.96463193\n",
      " 0.96077337 0.95498346 0.95434657        nan 0.95691894 0.95691894\n",
      " 0.95691894 0.95691894 0.95691894 0.95691894 0.95691894 0.95563689\n",
      "        nan 0.97555004 0.9761952  0.97684036 0.97748553 0.97105873\n",
      " 0.96141853 0.95434243 0.95306452        nan 0.97492556 0.97492556\n",
      " 0.97492556 0.97492556 0.97298594 0.96270058 0.95562448 0.95434657\n",
      "        nan 0.96912324 0.96912324 0.96912324 0.96912324 0.96912324\n",
      " 0.96205542 0.95562448 0.95434657        nan 0.95755997 0.95755997\n",
      " 0.95755997 0.95755997 0.95755997 0.95755997 0.95755997 0.95563689\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182        nan 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      "        nan 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182        nan 0.79420182 0.79420182\n",
      " 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182 0.79420182\n",
      "        nan 0.8327957  0.8327957  0.8327957  0.8327957  0.8327957\n",
      " 0.8327957  0.8327957  0.8327957         nan 0.8327957  0.8327957\n",
      " 0.8327957  0.8327957  0.8327957  0.8327957  0.8327957  0.8327957\n",
      "        nan 0.8327957  0.8327957  0.8327957  0.8327957  0.8327957\n",
      " 0.8327957  0.8327957  0.8327957         nan 0.8327957  0.8327957\n",
      " 0.8327957  0.8327957  0.8327957  0.8327957  0.8327957  0.8327957\n",
      "        nan 0.86107113 0.86107113 0.86107113 0.86107113 0.86107113\n",
      " 0.86107113 0.86107113 0.86107113        nan 0.86107113 0.86107113\n",
      " 0.86107113 0.86107113 0.86107113 0.86107113 0.86107113 0.86107113\n",
      "        nan 0.86107113 0.86107113 0.86107113 0.86107113 0.86107113\n",
      " 0.86107113 0.86107113 0.86107113        nan 0.86107113 0.86107113\n",
      " 0.86107113 0.86107113 0.86107113 0.86107113 0.86107113 0.86107113\n",
      "        nan 0.91768404 0.91768404 0.91768404 0.91768404 0.91768404\n",
      " 0.91768404 0.91768404 0.91768404        nan 0.91768404 0.91768404\n",
      " 0.91768404 0.91768404 0.91768404 0.91768404 0.91768404 0.91768404\n",
      "        nan 0.91768404 0.91768404 0.91768404 0.91768404 0.91768404\n",
      " 0.91768404 0.91768404 0.91768404        nan 0.91768404 0.91768404\n",
      " 0.91768404 0.91768404 0.91768404 0.91768404 0.91768404 0.91768404\n",
      "        nan 0.92284533 0.92284533 0.92284533 0.92284533 0.92284533\n",
      " 0.92284533 0.92284533 0.92284533        nan 0.92284533 0.92284533\n",
      " 0.92284533 0.92284533 0.92284533 0.92284533 0.92284533 0.92284533\n",
      "        nan 0.92284533 0.92284533 0.92284533 0.92284533 0.92284533\n",
      " 0.92284533 0.92284533 0.92284533        nan 0.92284533 0.92284533\n",
      " 0.92284533 0.92284533 0.92284533 0.92284533 0.92284533 0.92284533\n",
      "        nan 0.96396609 0.96396609 0.96396609 0.96396609 0.96204301\n",
      " 0.96075269 0.95882548 0.9562531         nan 0.96204301 0.96204301\n",
      " 0.96204301 0.96204301 0.96204301 0.96075269 0.95882548 0.9562531\n",
      "        nan 0.96075269 0.96075269 0.96075269 0.96075269 0.96075269\n",
      " 0.96075269 0.95882548 0.9562531         nan 0.95689826 0.95689826\n",
      " 0.95689826 0.95689826 0.95689826 0.95689826 0.95689826 0.95689826\n",
      "        nan 0.96783706 0.96719603 0.96783706 0.96912324 0.96720017\n",
      " 0.96333747 0.96011993 0.95626551        nan 0.96720017 0.96720017\n",
      " 0.96720017 0.96720017 0.96720017 0.96333747 0.96011993 0.95626551\n",
      "        nan 0.96526468 0.96526468 0.96526468 0.96526468 0.96526468\n",
      " 0.96269231 0.95947477 0.95562035        nan 0.95947891 0.95947891\n",
      " 0.95947891 0.95947891 0.95947891 0.95947891 0.95947891 0.95819686\n",
      "        nan 0.97102978 0.97424731 0.9723201  0.97361042 0.97105045\n",
      " 0.96397849 0.95883788 0.95562448        nan 0.96911911 0.96911911\n",
      " 0.96911911 0.96976427 0.97105045 0.96397849 0.95883788 0.95562448\n",
      "        nan 0.969756   0.969756   0.969756   0.969756   0.969756\n",
      " 0.96268817 0.95754756 0.95433416        nan 0.95819272 0.95819272\n",
      " 0.95819272 0.95819272 0.95819272 0.95819272 0.95819272 0.95626964]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836        nan 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      "        nan 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836        nan 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      "        nan 0.84633581 0.84633581 0.84633581 0.84633581 0.84633581\n",
      " 0.84633581 0.84633581 0.84633581        nan 0.84633581 0.84633581\n",
      " 0.84633581 0.84633581 0.84633581 0.84633581 0.84633581 0.84633581\n",
      "        nan 0.84633581 0.84633581 0.84633581 0.84633581 0.84633581\n",
      " 0.84633581 0.84633581 0.84633581        nan 0.84633581 0.84633581\n",
      " 0.84633581 0.84633581 0.84633581 0.84633581 0.84633581 0.84633581\n",
      "        nan 0.87012821 0.87012821 0.87012821 0.87012821 0.87012821\n",
      " 0.87012821 0.87012821 0.87012821        nan 0.87012821 0.87012821\n",
      " 0.87012821 0.87012821 0.87012821 0.87012821 0.87012821 0.87012821\n",
      "        nan 0.87012821 0.87012821 0.87012821 0.87012821 0.87012821\n",
      " 0.87012821 0.87012821 0.87012821        nan 0.87012821 0.87012821\n",
      " 0.87012821 0.87012821 0.87012821 0.87012821 0.87012821 0.87012821\n",
      "        nan 0.93312242 0.93312242 0.93312242 0.93312242 0.93312242\n",
      " 0.93312242 0.93312242 0.93312242        nan 0.93312242 0.93312242\n",
      " 0.93312242 0.93312242 0.93312242 0.93312242 0.93312242 0.93312242\n",
      "        nan 0.93312242 0.93312242 0.93312242 0.93312242 0.93312242\n",
      " 0.93312242 0.93312242 0.93312242        nan 0.93312242 0.93312242\n",
      " 0.93312242 0.93312242 0.93312242 0.93312242 0.93312242 0.93312242\n",
      "        nan 0.90997519 0.90997519 0.90997519 0.90997519 0.90997519\n",
      " 0.90997519 0.90997519 0.90997519        nan 0.90997519 0.90997519\n",
      " 0.90997519 0.90997519 0.90997519 0.90997519 0.90997519 0.90997519\n",
      "        nan 0.90997519 0.90997519 0.90997519 0.90997519 0.90997519\n",
      " 0.90997519 0.90997519 0.90997519        nan 0.90997519 0.90997519\n",
      " 0.90997519 0.90997519 0.90997519 0.90997519 0.90997519 0.90997519\n",
      "        nan 0.96527295 0.96527295 0.96527295 0.9639909  0.96141853\n",
      " 0.95820513 0.95048801 0.95048801        nan 0.9639909  0.9639909\n",
      " 0.9639909  0.9639909  0.96141853 0.95820513 0.95048801 0.95048801\n",
      "        nan 0.95884615 0.95884615 0.95884615 0.95884615 0.95884615\n",
      " 0.95820513 0.95048801 0.95048801        nan 0.95177006 0.95177006\n",
      " 0.95177006 0.95177006 0.95177006 0.95177006 0.95177006 0.95177006\n",
      "        nan 0.96527709 0.96527709 0.9639909  0.96013234 0.95884202\n",
      " 0.95691894 0.95112903 0.94855666        nan 0.96334988 0.96334988\n",
      " 0.96334988 0.96206369 0.96077337 0.95820513 0.95112903 0.94855666\n",
      "        nan 0.95820099 0.95820099 0.95820099 0.95820099 0.95820099\n",
      " 0.95820513 0.95112903 0.94855666        nan 0.95177006 0.95177006\n",
      " 0.95177006 0.95177006 0.95177006 0.95177006 0.95177006 0.95112903\n",
      "        nan 0.97556658 0.97621588 0.97171216 0.96656741 0.96270471\n",
      " 0.9575641  0.95112903 0.94855666        nan 0.9678536  0.9678536\n",
      " 0.9678536  0.96721257 0.96463606 0.95885029 0.95112903 0.94855666\n",
      "        nan 0.95949545 0.95949545 0.95949545 0.95949545 0.95949545\n",
      " 0.95885029 0.95112903 0.94855666        nan 0.95177006 0.95177006\n",
      " 0.95177006 0.95177006 0.95177006 0.95177006 0.95177006 0.95112903\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836        nan 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      "        nan 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836        nan 0.79421836 0.79421836\n",
      " 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836 0.79421836\n",
      "        nan 0.83283292 0.83283292 0.83283292 0.83283292 0.83283292\n",
      " 0.83283292 0.83283292 0.83283292        nan 0.83283292 0.83283292\n",
      " 0.83283292 0.83283292 0.83283292 0.83283292 0.83283292 0.83283292\n",
      "        nan 0.83283292 0.83283292 0.83283292 0.83283292 0.83283292\n",
      " 0.83283292 0.83283292 0.83283292        nan 0.83283292 0.83283292\n",
      " 0.83283292 0.83283292 0.83283292 0.83283292 0.83283292 0.83283292\n",
      "        nan 0.86369313 0.86369313 0.86369313 0.86369313 0.86369313\n",
      " 0.86369313 0.86369313 0.86369313        nan 0.86369313 0.86369313\n",
      " 0.86369313 0.86369313 0.86369313 0.86369313 0.86369313 0.86369313\n",
      "        nan 0.86369313 0.86369313 0.86369313 0.86369313 0.86369313\n",
      " 0.86369313 0.86369313 0.86369313        nan 0.86369313 0.86369313\n",
      " 0.86369313 0.86369313 0.86369313 0.86369313 0.86369313 0.86369313\n",
      "        nan 0.91833333 0.91833333 0.91833333 0.91833333 0.91833333\n",
      " 0.91833333 0.91833333 0.91833333        nan 0.91833333 0.91833333\n",
      " 0.91833333 0.91833333 0.91833333 0.91833333 0.91833333 0.91833333\n",
      "        nan 0.91833333 0.91833333 0.91833333 0.91833333 0.91833333\n",
      " 0.91833333 0.91833333 0.91833333        nan 0.91833333 0.91833333\n",
      " 0.91833333 0.91833333 0.91833333 0.91833333 0.91833333 0.91833333\n",
      "        nan 0.90935897 0.90935897 0.90935897 0.90935897 0.90935897\n",
      " 0.90935897 0.90935897 0.90935897        nan 0.90935897 0.90935897\n",
      " 0.90935897 0.90935897 0.90935897 0.90935897 0.90935897 0.90935897\n",
      "        nan 0.90935897 0.90935897 0.90935897 0.90935897 0.90935897\n",
      " 0.90935897 0.90935897 0.90935897        nan 0.90935897 0.90935897\n",
      " 0.90935897 0.90935897 0.90935897 0.90935897 0.90935897 0.90935897\n",
      "        nan 0.95497932 0.95497932 0.95497932 0.95369727 0.9511249\n",
      " 0.94855252 0.9440488  0.9440488         nan 0.95369727 0.95369727\n",
      " 0.95369727 0.95369727 0.9511249  0.94855252 0.9440488  0.9440488\n",
      "        nan 0.94984285 0.94984285 0.94984285 0.94984285 0.94984285\n",
      " 0.94855252 0.9440488  0.9440488         nan 0.9440488  0.9440488\n",
      " 0.9440488  0.9440488  0.9440488  0.9440488  0.9440488  0.9440488\n",
      "        nan 0.96912738 0.96912738 0.96783706 0.96590984 0.96333747\n",
      " 0.95947891 0.9543383  0.95176592        nan 0.96784119 0.96784119\n",
      " 0.96784119 0.96719603 0.96462366 0.9607651  0.9543383  0.95176592\n",
      "        nan 0.96205128 0.96205128 0.96205128 0.96205128 0.96205128\n",
      " 0.9607651  0.9543383  0.95176592        nan 0.95241108 0.95241108\n",
      " 0.95241108 0.95241108 0.95241108 0.95241108 0.95241108 0.95241108\n",
      "        nan 0.97620347 0.9774938  0.97556245 0.97299421 0.96656328\n",
      " 0.95948304 0.95498759 0.95048387        nan 0.9742804  0.9742804\n",
      " 0.9742804  0.97299421 0.96784946 0.96076923 0.95498759 0.95048387\n",
      "        nan 0.9639909  0.9639909  0.9639909  0.9639909  0.9639909\n",
      " 0.96076923 0.95498759 0.95048387        nan 0.95241935 0.95241935\n",
      " 0.95241935 0.95241935 0.95241935 0.95241935 0.95241935 0.95112903]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493        nan 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      "        nan 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493        nan 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      "        nan 0.85531431 0.85531431 0.85531431 0.85531431 0.85531431\n",
      " 0.85531431 0.85531431 0.85531431        nan 0.85531431 0.85531431\n",
      " 0.85531431 0.85531431 0.85531431 0.85531431 0.85531431 0.85531431\n",
      "        nan 0.85531431 0.85531431 0.85531431 0.85531431 0.85531431\n",
      " 0.85531431 0.85531431 0.85531431        nan 0.85531431 0.85531431\n",
      " 0.85531431 0.85531431 0.85531431 0.85531431 0.85531431 0.85531431\n",
      "        nan 0.87138544 0.87138544 0.87138544 0.87138544 0.87138544\n",
      " 0.87138544 0.87138544 0.87138544        nan 0.87138544 0.87138544\n",
      " 0.87138544 0.87138544 0.87138544 0.87138544 0.87138544 0.87138544\n",
      "        nan 0.87138544 0.87138544 0.87138544 0.87138544 0.87138544\n",
      " 0.87138544 0.87138544 0.87138544        nan 0.87138544 0.87138544\n",
      " 0.87138544 0.87138544 0.87138544 0.87138544 0.87138544 0.87138544\n",
      "        nan 0.93053763 0.93053763 0.93053763 0.93053763 0.93053763\n",
      " 0.93053763 0.93053763 0.93053763        nan 0.93053763 0.93053763\n",
      " 0.93053763 0.93053763 0.93053763 0.93053763 0.93053763 0.93053763\n",
      "        nan 0.93053763 0.93053763 0.93053763 0.93053763 0.93053763\n",
      " 0.93053763 0.93053763 0.93053763        nan 0.93053763 0.93053763\n",
      " 0.93053763 0.93053763 0.93053763 0.93053763 0.93053763 0.93053763\n",
      "        nan 0.92086849 0.92086849 0.92086849 0.92086849 0.92086849\n",
      " 0.92086849 0.92086849 0.92086849        nan 0.92086849 0.92086849\n",
      " 0.92086849 0.92086849 0.92086849 0.92086849 0.92086849 0.92086849\n",
      "        nan 0.92086849 0.92086849 0.92086849 0.92086849 0.92086849\n",
      " 0.92086849 0.92086849 0.92086849        nan 0.92086849 0.92086849\n",
      " 0.92086849 0.92086849 0.92086849 0.92086849 0.92086849 0.92086849\n",
      "        nan 0.96591398 0.96591398 0.96591398 0.96462366 0.96333333\n",
      " 0.96075269 0.95818445 0.95818445        nan 0.96462366 0.96462366\n",
      " 0.96462366 0.96462366 0.96333333 0.96075269 0.95818445 0.95818445\n",
      "        nan 0.96139785 0.96139785 0.96139785 0.96139785 0.96139785\n",
      " 0.96075269 0.95818445 0.95818445        nan 0.95818445 0.95818445\n",
      " 0.95818445 0.95818445 0.95818445 0.95818445 0.95818445 0.95818445\n",
      "        nan 0.96718362 0.96526055 0.96526055 0.96397022 0.96332506\n",
      " 0.96074855 0.95689413 0.95753515        nan 0.96526055 0.96526055\n",
      " 0.96526055 0.96526055 0.96397022 0.96074855 0.95689413 0.95753515\n",
      "        nan 0.96267577 0.96267577 0.96267577 0.96267577 0.96267577\n",
      " 0.96138958 0.95753515 0.95817618        nan 0.95559967 0.95559967\n",
      " 0.95559967 0.95559967 0.95559967 0.95559967 0.95559967 0.95624069\n",
      "        nan 0.97747725 0.9761952  0.97361869 0.97168734 0.96911084\n",
      " 0.96267577 0.95753929 0.95753515        nan 0.97361869 0.97361869\n",
      " 0.97361869 0.97297767 0.969756   0.96267577 0.95753929 0.95753515\n",
      "        nan 0.96717535 0.96717535 0.96717535 0.96717535 0.96717535\n",
      " 0.96331679 0.95818031 0.95817618        nan 0.95559967 0.95559967\n",
      " 0.95559967 0.95559967 0.95559967 0.95559967 0.95559967 0.95624069\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493        nan 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      "        nan 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493        nan 0.79356493 0.79356493\n",
      " 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493 0.79356493\n",
      "        nan 0.8405335  0.8405335  0.8405335  0.8405335  0.8405335\n",
      " 0.8405335  0.8405335  0.8405335         nan 0.8405335  0.8405335\n",
      " 0.8405335  0.8405335  0.8405335  0.8405335  0.8405335  0.8405335\n",
      "        nan 0.8405335  0.8405335  0.8405335  0.8405335  0.8405335\n",
      " 0.8405335  0.8405335  0.8405335         nan 0.8405335  0.8405335\n",
      " 0.8405335  0.8405335  0.8405335  0.8405335  0.8405335  0.8405335\n",
      "        nan 0.86174938 0.86174938 0.86174938 0.86174938 0.86174938\n",
      " 0.86174938 0.86174938 0.86174938        nan 0.86174938 0.86174938\n",
      " 0.86174938 0.86174938 0.86174938 0.86174938 0.86174938 0.86174938\n",
      "        nan 0.86174938 0.86174938 0.86174938 0.86174938 0.86174938\n",
      " 0.86174938 0.86174938 0.86174938        nan 0.86174938 0.86174938\n",
      " 0.86174938 0.86174938 0.86174938 0.86174938 0.86174938 0.86174938\n",
      "        nan 0.90866832 0.90866832 0.90866832 0.90866832 0.90866832\n",
      " 0.90866832 0.90866832 0.90866832        nan 0.90866832 0.90866832\n",
      " 0.90866832 0.90866832 0.90866832 0.90866832 0.90866832 0.90866832\n",
      "        nan 0.90866832 0.90866832 0.90866832 0.90866832 0.90866832\n",
      " 0.90866832 0.90866832 0.90866832        nan 0.90866832 0.90866832\n",
      " 0.90866832 0.90866832 0.90866832 0.90866832 0.90866832 0.90866832\n",
      "        nan 0.92215881 0.92215881 0.92215881 0.92215881 0.92215881\n",
      " 0.92215881 0.92215881 0.92215881        nan 0.92215881 0.92215881\n",
      " 0.92215881 0.92215881 0.92215881 0.92215881 0.92215881 0.92215881\n",
      "        nan 0.92215881 0.92215881 0.92215881 0.92215881 0.92215881\n",
      " 0.92215881 0.92215881 0.92215881        nan 0.92215881 0.92215881\n",
      " 0.92215881 0.92215881 0.92215881 0.92215881 0.92215881 0.92215881\n",
      "        nan 0.95754756 0.95754756 0.95754756 0.9569024  0.9569024\n",
      " 0.95625724 0.95239868 0.95239868        nan 0.9569024  0.9569024\n",
      " 0.9569024  0.9569024  0.9569024  0.95625724 0.95239868 0.95239868\n",
      "        nan 0.9569024  0.9569024  0.9569024  0.9569024  0.9569024\n",
      " 0.95625724 0.95239868 0.95239868        nan 0.95239868 0.95239868\n",
      " 0.95239868 0.95239868 0.95239868 0.95239868 0.95239868 0.95239868\n",
      "        nan 0.96846981 0.96718776 0.96589744 0.96653433 0.96396195\n",
      " 0.96331679 0.96074855 0.95945823        nan 0.96589744 0.96589744\n",
      " 0.96589744 0.96717949 0.96460711 0.96331679 0.96074855 0.95945823\n",
      "        nan 0.96331266 0.96331266 0.96331266 0.96331266 0.96331266\n",
      " 0.96395782 0.96138958 0.96009926        nan 0.96009926 0.96009926\n",
      " 0.96009926 0.96009926 0.96009926 0.96009926 0.96009926 0.95880893\n",
      "        nan 0.96912738 0.96977667 0.96719603 0.969756   0.96461125\n",
      " 0.96202647 0.96009926 0.96009926        nan 0.96719603 0.96719603\n",
      " 0.96719603 0.97040116 0.96525641 0.96202647 0.96009926 0.96009926\n",
      "        nan 0.96267163 0.96267163 0.96267163 0.96267163 0.96267163\n",
      " 0.96266749 0.96074028 0.96074028        nan 0.95944996 0.95944996\n",
      " 0.95944996 0.95944996 0.95944996 0.95944996 0.95944996 0.95944996]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878        nan 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      "        nan 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878        nan 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      "        nan 0.85081059 0.85081059 0.85081059 0.85081059 0.85081059\n",
      " 0.85081059 0.85081059 0.85081059        nan 0.85081059 0.85081059\n",
      " 0.85081059 0.85081059 0.85081059 0.85081059 0.85081059 0.85081059\n",
      "        nan 0.85081059 0.85081059 0.85081059 0.85081059 0.85081059\n",
      " 0.85081059 0.85081059 0.85081059        nan 0.85081059 0.85081059\n",
      " 0.85081059 0.85081059 0.85081059 0.85081059 0.85081059 0.85081059\n",
      "        nan 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275        nan 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      "        nan 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275        nan 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      "        nan 0.9311828  0.9311828  0.9311828  0.9311828  0.9311828\n",
      " 0.9311828  0.9311828  0.9311828         nan 0.9311828  0.9311828\n",
      " 0.9311828  0.9311828  0.9311828  0.9311828  0.9311828  0.9311828\n",
      "        nan 0.9311828  0.9311828  0.9311828  0.9311828  0.9311828\n",
      " 0.9311828  0.9311828  0.9311828         nan 0.9311828  0.9311828\n",
      " 0.9311828  0.9311828  0.9311828  0.9311828  0.9311828  0.9311828\n",
      "        nan 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465        nan 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      "        nan 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465        nan 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      "        nan 0.9691067  0.9691067  0.9691067  0.9691067  0.96781638\n",
      " 0.96459471 0.95945823 0.95881307        nan 0.96781638 0.96781638\n",
      " 0.96781638 0.96781638 0.96781638 0.96459471 0.95945823 0.95881307\n",
      "        nan 0.96588089 0.96588089 0.96588089 0.96588089 0.96588089\n",
      " 0.96459471 0.95945823 0.95881307        nan 0.95689413 0.95689413\n",
      " 0.95689413 0.95689413 0.95689413 0.95689413 0.95689413 0.95624897\n",
      "        nan 0.969756   0.96846981 0.96782465 0.96846981 0.96782465\n",
      " 0.96459884 0.96267163 0.9620306         nan 0.96782465 0.96782465\n",
      " 0.96782465 0.96782465 0.96846981 0.96459884 0.96267163 0.9620306\n",
      "        nan 0.96588503 0.96588503 0.96588503 0.96588503 0.96588503\n",
      " 0.96459884 0.96267163 0.9620306         nan 0.96268404 0.96268404\n",
      " 0.96268404 0.96268404 0.96268404 0.96268404 0.96268404 0.96204301\n",
      "        nan 0.9819727  0.98004136 0.9729694  0.97104218 0.96782465\n",
      " 0.96459471 0.96267163 0.9620306         nan 0.97232423 0.97232423\n",
      " 0.97232423 0.96975186 0.96846981 0.96459471 0.96267163 0.9620306\n",
      "        nan 0.96717535 0.96717535 0.96717535 0.96717535 0.96717535\n",
      " 0.96588503 0.96267163 0.9620306         nan 0.96268404 0.96268404\n",
      " 0.96268404 0.96268404 0.96268404 0.96268404 0.96268404 0.96204301\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878        nan 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      "        nan 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878        nan 0.78971878 0.78971878\n",
      " 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878 0.78971878\n",
      "        nan 0.83473945 0.83473945 0.83473945 0.83473945 0.83473945\n",
      " 0.83473945 0.83473945 0.83473945        nan 0.83473945 0.83473945\n",
      " 0.83473945 0.83473945 0.83473945 0.83473945 0.83473945 0.83473945\n",
      "        nan 0.83473945 0.83473945 0.83473945 0.83473945 0.83473945\n",
      " 0.83473945 0.83473945 0.83473945        nan 0.83473945 0.83473945\n",
      " 0.83473945 0.83473945 0.83473945 0.83473945 0.83473945 0.83473945\n",
      "        nan 0.86364764 0.86364764 0.86364764 0.86364764 0.86364764\n",
      " 0.86364764 0.86364764 0.86364764        nan 0.86364764 0.86364764\n",
      " 0.86364764 0.86364764 0.86364764 0.86364764 0.86364764 0.86364764\n",
      "        nan 0.86364764 0.86364764 0.86364764 0.86364764 0.86364764\n",
      " 0.86364764 0.86364764 0.86364764        nan 0.86364764 0.86364764\n",
      " 0.86364764 0.86364764 0.86364764 0.86364764 0.86364764 0.86364764\n",
      "        nan 0.90160463 0.90160463 0.90160463 0.90160463 0.90160463\n",
      " 0.90160463 0.90160463 0.90160463        nan 0.90160463 0.90160463\n",
      " 0.90160463 0.90160463 0.90160463 0.90160463 0.90160463 0.90160463\n",
      "        nan 0.90160463 0.90160463 0.90160463 0.90160463 0.90160463\n",
      " 0.90160463 0.90160463 0.90160463        nan 0.90160463 0.90160463\n",
      " 0.90160463 0.90160463 0.90160463 0.90160463 0.90160463 0.90160463\n",
      "        nan 0.92218362 0.92218362 0.92218362 0.92218362 0.92218362\n",
      " 0.92218362 0.92218362 0.92218362        nan 0.92218362 0.92218362\n",
      " 0.92218362 0.92218362 0.92218362 0.92218362 0.92218362 0.92218362\n",
      "        nan 0.92218362 0.92218362 0.92218362 0.92218362 0.92218362\n",
      " 0.92218362 0.92218362 0.92218362        nan 0.92218362 0.92218362\n",
      " 0.92218362 0.92218362 0.92218362 0.92218362 0.92218362 0.92218362\n",
      "        nan 0.95496278 0.95496278 0.95496278 0.95496278 0.95496278\n",
      " 0.95367246 0.94918114 0.94724566        nan 0.95496278 0.95496278\n",
      " 0.95496278 0.95496278 0.95496278 0.95367246 0.94918114 0.94724566\n",
      "        nan 0.95367246 0.95367246 0.95367246 0.95367246 0.95367246\n",
      " 0.95367246 0.94918114 0.94724566        nan 0.94661704 0.94661704\n",
      " 0.94661704 0.94661704 0.94661704 0.94661704 0.94661704 0.94468156\n",
      "        nan 0.97039289 0.96975186 0.96846567 0.96911084 0.96911084\n",
      " 0.965244   0.96010753 0.9594665         nan 0.96975186 0.96975186\n",
      " 0.96975186 0.96975186 0.96975186 0.96588503 0.96010753 0.9594665\n",
      "        nan 0.96717122 0.96717122 0.96717122 0.96717122 0.96717122\n",
      " 0.96588503 0.96010753 0.9594665         nan 0.95882961 0.95882961\n",
      " 0.95882961 0.95882961 0.95882961 0.95882961 0.95882961 0.95818859\n",
      "        nan 0.97425972 0.97361456 0.97168734 0.97040116 0.96782878\n",
      " 0.96396195 0.95882548 0.95753929        nan 0.97297353 0.97297353\n",
      " 0.97297353 0.97104218 0.96911497 0.96460298 0.95882548 0.95753929\n",
      "        nan 0.96653846 0.96653846 0.96653846 0.96653846 0.96653846\n",
      " 0.96460298 0.95882548 0.95753929        nan 0.95754756 0.95754756\n",
      " 0.95754756 0.95754756 0.95754756 0.95754756 0.95754756 0.95626137]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.84502481 0.84502481 0.84502481 0.84502481 0.84502481\n",
      " 0.84502481 0.84502481 0.84502481        nan 0.84502481 0.84502481\n",
      " 0.84502481 0.84502481 0.84502481 0.84502481 0.84502481 0.84502481\n",
      "        nan 0.84502481 0.84502481 0.84502481 0.84502481 0.84502481\n",
      " 0.84502481 0.84502481 0.84502481        nan 0.84502481 0.84502481\n",
      " 0.84502481 0.84502481 0.84502481 0.84502481 0.84502481 0.84502481\n",
      "        nan 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275        nan 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      "        nan 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275        nan 0.86752275 0.86752275\n",
      " 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275 0.86752275\n",
      "        nan 0.93248553 0.93248553 0.93248553 0.93248553 0.93248553\n",
      " 0.93248553 0.93248553 0.93248553        nan 0.93248553 0.93248553\n",
      " 0.93248553 0.93248553 0.93248553 0.93248553 0.93248553 0.93248553\n",
      "        nan 0.93248553 0.93248553 0.93248553 0.93248553 0.93248553\n",
      " 0.93248553 0.93248553 0.93248553        nan 0.93248553 0.93248553\n",
      " 0.93248553 0.93248553 0.93248553 0.93248553 0.93248553 0.93248553\n",
      "        nan 0.91191481 0.91191481 0.91191481 0.91191481 0.91191481\n",
      " 0.91191481 0.91191481 0.91191481        nan 0.91191481 0.91191481\n",
      " 0.91191481 0.91191481 0.91191481 0.91191481 0.91191481 0.91191481\n",
      "        nan 0.91191481 0.91191481 0.91191481 0.91191481 0.91191481\n",
      " 0.91191481 0.91191481 0.91191481        nan 0.91191481 0.91191481\n",
      " 0.91191481 0.91191481 0.91191481 0.91191481 0.91191481 0.91191481\n",
      "        nan 0.97235318 0.97235318 0.97235318 0.97171216 0.96785773\n",
      " 0.96528536 0.96143093 0.96078577        nan 0.97235318 0.97235318\n",
      " 0.97235318 0.97171216 0.96785773 0.96528536 0.96143093 0.96078577\n",
      "        nan 0.96785773 0.96785773 0.96785773 0.96785773 0.96785773\n",
      " 0.96528536 0.96143093 0.96078577        nan 0.96143093 0.96143093\n",
      " 0.96143093 0.96143093 0.96143093 0.96143093 0.96143093 0.96078577\n",
      "        nan 0.9639909  0.96334988 0.96205955 0.96206369 0.95885443\n",
      " 0.95885029 0.95627792 0.95628205        nan 0.96526882 0.96526882\n",
      " 0.96526882 0.96462779 0.96141853 0.96013234 0.95627792 0.95628205\n",
      "        nan 0.96141853 0.96141853 0.96141853 0.96141853 0.96141853\n",
      " 0.9607775  0.95692308 0.95692721        nan 0.95627792 0.95627792\n",
      " 0.95627792 0.95627792 0.95627792 0.95627792 0.95627792 0.95628205\n",
      "        nan 0.97493797 0.97815136 0.97363937 0.97235318 0.96657155\n",
      " 0.95949132 0.95627792 0.95628205        nan 0.97491315 0.97491315\n",
      " 0.97491315 0.97491729 0.96913565 0.96077337 0.95627792 0.95628205\n",
      "        nan 0.9639909  0.9639909  0.9639909  0.9639909  0.9639909\n",
      " 0.9607775  0.95628205 0.95692721        nan 0.95499173 0.95499173\n",
      " 0.95499173 0.95499173 0.95499173 0.95499173 0.95499173 0.95628205\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.83025641 0.83025641 0.83025641 0.83025641 0.83025641\n",
      " 0.83025641 0.83025641 0.83025641        nan 0.83025641 0.83025641\n",
      " 0.83025641 0.83025641 0.83025641 0.83025641 0.83025641 0.83025641\n",
      "        nan 0.83025641 0.83025641 0.83025641 0.83025641 0.83025641\n",
      " 0.83025641 0.83025641 0.83025641        nan 0.83025641 0.83025641\n",
      " 0.83025641 0.83025641 0.83025641 0.83025641 0.83025641 0.83025641\n",
      "        nan 0.84822167 0.84822167 0.84822167 0.84822167 0.84822167\n",
      " 0.84822167 0.84822167 0.84822167        nan 0.84822167 0.84822167\n",
      " 0.84822167 0.84822167 0.84822167 0.84822167 0.84822167 0.84822167\n",
      "        nan 0.84822167 0.84822167 0.84822167 0.84822167 0.84822167\n",
      " 0.84822167 0.84822167 0.84822167        nan 0.84822167 0.84822167\n",
      " 0.84822167 0.84822167 0.84822167 0.84822167 0.84822167 0.84822167\n",
      "        nan 0.9208933  0.9208933  0.9208933  0.9208933  0.9208933\n",
      " 0.9208933  0.9208933  0.9208933         nan 0.9208933  0.9208933\n",
      " 0.9208933  0.9208933  0.9208933  0.9208933  0.9208933  0.9208933\n",
      "        nan 0.9208933  0.9208933  0.9208933  0.9208933  0.9208933\n",
      " 0.9208933  0.9208933  0.9208933         nan 0.9208933  0.9208933\n",
      " 0.9208933  0.9208933  0.9208933  0.9208933  0.9208933  0.9208933\n",
      "        nan 0.91704715 0.91704715 0.91704715 0.91704715 0.91704715\n",
      " 0.91704715 0.91704715 0.91704715        nan 0.91704715 0.91704715\n",
      " 0.91704715 0.91704715 0.91704715 0.91704715 0.91704715 0.91704715\n",
      "        nan 0.91704715 0.91704715 0.91704715 0.91704715 0.91704715\n",
      " 0.91704715 0.91704715 0.91704715        nan 0.91704715 0.91704715\n",
      " 0.91704715 0.91704715 0.91704715 0.91704715 0.91704715 0.91704715\n",
      "        nan 0.95885029 0.95885029 0.95885029 0.95885029 0.95756824\n",
      " 0.95499586 0.95114144 0.95114144        nan 0.95885029 0.95885029\n",
      " 0.95885029 0.95885029 0.95756824 0.95499586 0.95114144 0.95114144\n",
      "        nan 0.95885029 0.95885029 0.95885029 0.95885029 0.95885029\n",
      " 0.95627792 0.95242349 0.95242349        nan 0.95242349 0.95242349\n",
      " 0.95242349 0.95242349 0.95242349 0.95242349 0.95242349 0.95242349\n",
      "        nan 0.96722084 0.96722084 0.96721671 0.96657568 0.96336228\n",
      " 0.96143093 0.95885856 0.9588627         nan 0.96785773 0.96785773\n",
      " 0.96785773 0.96785773 0.96464433 0.96207196 0.95885856 0.9588627\n",
      "        nan 0.96592639 0.96592639 0.96592639 0.96592639 0.96592639\n",
      " 0.96335401 0.96014061 0.96014475        nan 0.95950372 0.95950372\n",
      " 0.95950372 0.95950372 0.95950372 0.95950372 0.95950372 0.95950786\n",
      "        nan 0.97172043 0.96978495 0.97171216 0.97107527 0.96914806\n",
      " 0.96207196 0.95758065 0.95758065        nan 0.97170802 0.97170802\n",
      " 0.97170802 0.97235732 0.97043011 0.96271299 0.95758065 0.95758065\n",
      "        nan 0.96785773 0.96785773 0.96785773 0.96785773 0.96785773\n",
      " 0.96335401 0.95822167 0.9588627         nan 0.95758478 0.95758478\n",
      " 0.95758478 0.95758478 0.95758478 0.95758478 0.95758478 0.95822581]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.83663358 0.83663358 0.83663358 0.83663358 0.83663358\n",
      " 0.83663358 0.83663358 0.83663358        nan 0.83663358 0.83663358\n",
      " 0.83663358 0.83663358 0.83663358 0.83663358 0.83663358 0.83663358\n",
      "        nan 0.83663358 0.83663358 0.83663358 0.83663358 0.83663358\n",
      " 0.83663358 0.83663358 0.83663358        nan 0.83663358 0.83663358\n",
      " 0.83663358 0.83663358 0.83663358 0.83663358 0.83663358 0.83663358\n",
      "        nan 0.86300248 0.86300248 0.86300248 0.86300248 0.86300248\n",
      " 0.86300248 0.86300248 0.86300248        nan 0.86300248 0.86300248\n",
      " 0.86300248 0.86300248 0.86300248 0.86300248 0.86300248 0.86300248\n",
      "        nan 0.86300248 0.86300248 0.86300248 0.86300248 0.86300248\n",
      " 0.86300248 0.86300248 0.86300248        nan 0.86300248 0.86300248\n",
      " 0.86300248 0.86300248 0.86300248 0.86300248 0.86300248 0.86300248\n",
      "        nan 0.93244003 0.93244003 0.93244003 0.93244003 0.93244003\n",
      " 0.93244003 0.93244003 0.93244003        nan 0.93244003 0.93244003\n",
      " 0.93244003 0.93244003 0.93244003 0.93244003 0.93244003 0.93244003\n",
      "        nan 0.93244003 0.93244003 0.93244003 0.93244003 0.93244003\n",
      " 0.93244003 0.93244003 0.93244003        nan 0.93244003 0.93244003\n",
      " 0.93244003 0.93244003 0.93244003 0.93244003 0.93244003 0.93244003\n",
      "        nan 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465        nan 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      "        nan 0.92282465 0.92282465 0.92282465 0.92282465 0.92282465\n",
      " 0.92282465 0.92282465 0.92282465        nan 0.9215426  0.9215426\n",
      " 0.9215426  0.9215426  0.9215426  0.9215426  0.9215426  0.9215426\n",
      "        nan 0.96397849 0.96397849 0.96397849 0.96268817 0.96140199\n",
      " 0.96140612 0.96011993 0.96011993        nan 0.96268817 0.96268817\n",
      " 0.96268817 0.96268817 0.96140199 0.96140612 0.96011993 0.96011993\n",
      "        nan 0.96140199 0.96140199 0.96140199 0.96140199 0.96140199\n",
      " 0.96140612 0.96011993 0.96011993        nan 0.95948304 0.95948304\n",
      " 0.95948304 0.95948304 0.95948304 0.95948304 0.95948304 0.95948304\n",
      "        nan 0.96269644 0.96269644 0.96269231 0.96204301 0.95947477\n",
      " 0.95626964 0.95369727 0.95176179        nan 0.96268817 0.96268817\n",
      " 0.96268817 0.96268817 0.96011993 0.95626964 0.95369727 0.95176179\n",
      "        nan 0.95755583 0.95755583 0.95755583 0.95755583 0.95755583\n",
      " 0.95626964 0.95369727 0.95176179        nan 0.95241522 0.95241522\n",
      " 0.95241522 0.95241522 0.95241522 0.95241522 0.95241522 0.95241522\n",
      "        nan 0.97363524 0.97299421 0.97041356 0.9665426  0.96012407\n",
      " 0.95755583 0.95369727 0.95176179        nan 0.97040943 0.97040943\n",
      " 0.97040943 0.96783292 0.96076923 0.95755583 0.95369727 0.95176179\n",
      "        nan 0.95819686 0.95819686 0.95819686 0.95819686 0.95819686\n",
      " 0.95755583 0.95369727 0.95176179        nan 0.95241522 0.95241522\n",
      " 0.95241522 0.95241522 0.95241522 0.95241522 0.95241522 0.95241522\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567        nan 0.79035567 0.79035567\n",
      " 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567 0.79035567\n",
      "        nan 0.83342432 0.83342432 0.83342432 0.83342432 0.83342432\n",
      " 0.83342432 0.83342432 0.83342432        nan 0.83342432 0.83342432\n",
      " 0.83342432 0.83342432 0.83342432 0.83342432 0.83342432 0.83342432\n",
      "        nan 0.83342432 0.83342432 0.83342432 0.83342432 0.83342432\n",
      " 0.83342432 0.83342432 0.83342432        nan 0.83342432 0.83342432\n",
      " 0.83342432 0.83342432 0.83342432 0.83342432 0.83342432 0.83342432\n",
      "        nan 0.86495451 0.86495451 0.86495451 0.86495451 0.86495451\n",
      " 0.86495451 0.86495451 0.86495451        nan 0.86495451 0.86495451\n",
      " 0.86495451 0.86495451 0.86495451 0.86495451 0.86495451 0.86495451\n",
      "        nan 0.86495451 0.86495451 0.86495451 0.86495451 0.86495451\n",
      " 0.86495451 0.86495451 0.86495451        nan 0.86495451 0.86495451\n",
      " 0.86495451 0.86495451 0.86495451 0.86495451 0.86495451 0.86495451\n",
      "        nan 0.90930108 0.90930108 0.90930108 0.90930108 0.90930108\n",
      " 0.90930108 0.90930108 0.90930108        nan 0.90930108 0.90930108\n",
      " 0.90930108 0.90930108 0.90930108 0.90930108 0.90930108 0.90930108\n",
      "        nan 0.90930108 0.90930108 0.90930108 0.90930108 0.90930108\n",
      " 0.90930108 0.90930108 0.90930108        nan 0.90930108 0.90930108\n",
      " 0.90930108 0.90930108 0.90930108 0.90930108 0.90930108 0.90930108\n",
      "        nan 0.91898677 0.91898677 0.91898677 0.91898677 0.91898677\n",
      " 0.91898677 0.91898677 0.91898677        nan 0.91898677 0.91898677\n",
      " 0.91898677 0.91898677 0.91898677 0.91898677 0.91898677 0.91898677\n",
      "        nan 0.91898677 0.91898677 0.91898677 0.91898677 0.91898677\n",
      " 0.91898677 0.91898677 0.91898677        nan 0.92026882 0.92026882\n",
      " 0.92026882 0.92026882 0.92026882 0.92026882 0.92026882 0.92026882\n",
      "        nan 0.95369727 0.95369727 0.95113317 0.94984285 0.95112076\n",
      " 0.95176592 0.94791977 0.94791977        nan 0.94984285 0.94984285\n",
      " 0.94984285 0.94984285 0.95112076 0.95176592 0.94791977 0.94791977\n",
      "        nan 0.95112076 0.95112076 0.95112076 0.95112076 0.95112076\n",
      " 0.95176592 0.94791977 0.94791977        nan 0.95112903 0.95112903\n",
      " 0.95112903 0.95112903 0.95112903 0.95112903 0.95112903 0.95112903\n",
      "        nan 0.96462779 0.96462779 0.96205955 0.96269644 0.96141026\n",
      " 0.95884202 0.95498759 0.95498759        nan 0.96205542 0.96205542\n",
      " 0.96205542 0.96269644 0.96141026 0.95884202 0.95498759 0.95498759\n",
      "        nan 0.96012821 0.96012821 0.96012821 0.96012821 0.96012821\n",
      " 0.95884202 0.95498759 0.95498759        nan 0.95755583 0.95755583\n",
      " 0.95755583 0.95755583 0.95755583 0.95755583 0.95755583 0.95755583\n",
      "        nan 0.96205128 0.96397849 0.95948304 0.96141026 0.96012407\n",
      " 0.95883788 0.95305624 0.95369727        nan 0.96076923 0.96076923\n",
      " 0.96076923 0.96270058 0.96076923 0.95883788 0.95305624 0.95369727\n",
      "        nan 0.96076923 0.96076923 0.96076923 0.96076923 0.96076923\n",
      " 0.95883788 0.95369727 0.95177419        nan 0.95562448 0.95562448\n",
      " 0.95562448 0.95562448 0.95562448 0.95562448 0.95562448 0.95562448]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601        nan 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      "        nan 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601        nan 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      "        nan 0.84758478 0.84758478 0.84758478 0.84758478 0.84758478\n",
      " 0.84758478 0.84758478 0.84758478        nan 0.84758478 0.84758478\n",
      " 0.84758478 0.84758478 0.84758478 0.84758478 0.84758478 0.84758478\n",
      "        nan 0.84758478 0.84758478 0.84758478 0.84758478 0.84758478\n",
      " 0.84758478 0.84758478 0.84758478        nan 0.84758478 0.84758478\n",
      " 0.84758478 0.84758478 0.84758478 0.84758478 0.84758478 0.84758478\n",
      "        nan 0.87135649 0.87135649 0.87135649 0.87135649 0.87135649\n",
      " 0.87135649 0.87135649 0.87135649        nan 0.87135649 0.87135649\n",
      " 0.87135649 0.87135649 0.87135649 0.87135649 0.87135649 0.87135649\n",
      "        nan 0.87135649 0.87135649 0.87135649 0.87135649 0.87135649\n",
      " 0.87135649 0.87135649 0.87135649        nan 0.87135649 0.87135649\n",
      " 0.87135649 0.87135649 0.87135649 0.87135649 0.87135649 0.87135649\n",
      "        nan 0.93503722 0.93503722 0.93503722 0.93503722 0.93503722\n",
      " 0.93503722 0.93503722 0.93503722        nan 0.93503722 0.93503722\n",
      " 0.93503722 0.93503722 0.93503722 0.93503722 0.93503722 0.93503722\n",
      "        nan 0.93503722 0.93503722 0.93503722 0.93503722 0.93503722\n",
      " 0.93503722 0.93503722 0.93503722        nan 0.93503722 0.93503722\n",
      " 0.93503722 0.93503722 0.93503722 0.93503722 0.93503722 0.93503722\n",
      "        nan 0.92860629 0.92860629 0.92860629 0.92860629 0.92860629\n",
      " 0.92860629 0.92860629 0.92860629        nan 0.92860629 0.92860629\n",
      " 0.92860629 0.92860629 0.92860629 0.92860629 0.92860629 0.92860629\n",
      "        nan 0.92860629 0.92860629 0.92860629 0.92860629 0.92860629\n",
      " 0.92860629 0.92860629 0.92860629        nan 0.92860629 0.92860629\n",
      " 0.92860629 0.92860629 0.92860629 0.92860629 0.92860629 0.92860629\n",
      "        nan 0.96076096 0.96076096 0.96076096 0.96076096 0.95947064\n",
      " 0.95754342 0.95368486 0.95497105        nan 0.96076096 0.96076096\n",
      " 0.96076096 0.96076096 0.95947064 0.95754342 0.95368486 0.95497105\n",
      "        nan 0.95947064 0.95947064 0.95947064 0.95947064 0.95947064\n",
      " 0.95754342 0.95368486 0.95497105        nan 0.95239868 0.95239868\n",
      " 0.95239868 0.95239868 0.95239868 0.95239868 0.95239868 0.95433002\n",
      "        nan 0.96205128 0.96205128 0.9601158  0.95947064 0.95947064\n",
      " 0.95626551 0.95112076 0.95047974        nan 0.96140612 0.96140612\n",
      " 0.96140612 0.96076096 0.95947064 0.95626551 0.95112076 0.95047974\n",
      "        nan 0.95754756 0.95754756 0.95754756 0.95754756 0.95754756\n",
      " 0.95626551 0.95112076 0.95047974        nan 0.95176179 0.95176179\n",
      " 0.95176179 0.95176179 0.95176179 0.95176179 0.95176179 0.95112076\n",
      "        nan 0.97361869 0.97361869 0.96846981 0.96911084 0.965244\n",
      " 0.95947891 0.95112076 0.95047974        nan 0.97104218 0.97104218\n",
      " 0.97104218 0.97040116 0.965244   0.95947891 0.95112076 0.95047974\n",
      "        nan 0.96203474 0.96203474 0.96203474 0.96203474 0.96203474\n",
      " 0.95947891 0.95112076 0.95047974        nan 0.95176179 0.95176179\n",
      " 0.95176179 0.95176179 0.95176179 0.95176179 0.95176179 0.95112076\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601        nan 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      "        nan 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601        nan 0.79097601 0.79097601\n",
      " 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601 0.79097601\n",
      "        nan 0.83087262 0.83087262 0.83087262 0.83087262 0.83087262\n",
      " 0.83087262 0.83087262 0.83087262        nan 0.83087262 0.83087262\n",
      " 0.83087262 0.83087262 0.83087262 0.83087262 0.83087262 0.83087262\n",
      "        nan 0.83087262 0.83087262 0.83087262 0.83087262 0.83087262\n",
      " 0.83087262 0.83087262 0.83087262        nan 0.83087262 0.83087262\n",
      " 0.83087262 0.83087262 0.83087262 0.83087262 0.83087262 0.83087262\n",
      "        nan 0.85399504 0.85399504 0.85399504 0.85399504 0.85399504\n",
      " 0.85399504 0.85399504 0.85399504        nan 0.85399504 0.85399504\n",
      " 0.85399504 0.85399504 0.85399504 0.85399504 0.85399504 0.85399504\n",
      "        nan 0.85399504 0.85399504 0.85399504 0.85399504 0.85399504\n",
      " 0.85399504 0.85399504 0.85399504        nan 0.85399504 0.85399504\n",
      " 0.85399504 0.85399504 0.85399504 0.85399504 0.85399504 0.85399504\n",
      "        nan 0.92667907 0.92667907 0.92667907 0.92667907 0.92667907\n",
      " 0.92667907 0.92667907 0.92667907        nan 0.92667907 0.92667907\n",
      " 0.92667907 0.92667907 0.92667907 0.92667907 0.92667907 0.92667907\n",
      "        nan 0.92667907 0.92667907 0.92667907 0.92667907 0.92667907\n",
      " 0.92667907 0.92667907 0.92667907        nan 0.92667907 0.92667907\n",
      " 0.92667907 0.92667907 0.92667907 0.92667907 0.92667907 0.92667907\n",
      "        nan 0.92731183 0.92731183 0.92731183 0.92731183 0.92731183\n",
      " 0.92731183 0.92731183 0.92731183        nan 0.92731183 0.92731183\n",
      " 0.92731183 0.92731183 0.92731183 0.92731183 0.92731183 0.92731183\n",
      "        nan 0.92731183 0.92731183 0.92731183 0.92731183 0.92731183\n",
      " 0.92731183 0.92731183 0.92731183        nan 0.92731183 0.92731183\n",
      " 0.92731183 0.92731183 0.92731183 0.92731183 0.92731183 0.92731183\n",
      "        nan 0.95819686 0.95819686 0.95819686 0.95819686 0.95819686\n",
      " 0.95626964 0.95241108 0.95369727        nan 0.95819686 0.95819686\n",
      " 0.95819686 0.95819686 0.95819686 0.95626964 0.95241108 0.95369727\n",
      "        nan 0.95819686 0.95819686 0.95819686 0.95819686 0.95819686\n",
      " 0.95626964 0.95241108 0.95369727        nan 0.9511249  0.9511249\n",
      " 0.9511249  0.9511249  0.9511249  0.9511249  0.9511249  0.95305624\n",
      "        nan 0.9633416  0.9633416  0.96140612 0.96140612 0.96205128\n",
      " 0.96012407 0.95497932 0.95498346        nan 0.96269644 0.96269644\n",
      " 0.96269644 0.96205128 0.96205128 0.96012407 0.95497932 0.95498346\n",
      "        nan 0.96205128 0.96205128 0.96205128 0.96205128 0.96205128\n",
      " 0.96012407 0.95497932 0.95498346        nan 0.95562035 0.95562035\n",
      " 0.95562035 0.95562035 0.95562035 0.95562035 0.95562035 0.95562448\n",
      "        nan 0.9658933  0.96718362 0.96139371 0.96139785 0.9626799\n",
      " 0.96012407 0.95240695 0.95305624        nan 0.96396609 0.96396609\n",
      " 0.96396609 0.96204301 0.9626799  0.96012407 0.95240695 0.95305624\n",
      "        nan 0.96204301 0.96204301 0.96204301 0.96204301 0.96204301\n",
      " 0.96012407 0.95240695 0.95305624        nan 0.95304797 0.95304797\n",
      " 0.95304797 0.95304797 0.95304797 0.95304797 0.95304797 0.95369727]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766        nan 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      "        nan 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766        nan 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      "        nan 0.84126964 0.84126964 0.84126964 0.84126964 0.84126964\n",
      " 0.84126964 0.84126964 0.84126964        nan 0.84126964 0.84126964\n",
      " 0.84126964 0.84126964 0.84126964 0.84126964 0.84126964 0.84126964\n",
      "        nan 0.84126964 0.84126964 0.84126964 0.84126964 0.84126964\n",
      " 0.84126964 0.84126964 0.84126964        nan 0.84126964 0.84126964\n",
      " 0.84126964 0.84126964 0.84126964 0.84126964 0.84126964 0.84126964\n",
      "        nan 0.85990074 0.85990074 0.85990074 0.85990074 0.85990074\n",
      " 0.85990074 0.85990074 0.85990074        nan 0.85990074 0.85990074\n",
      " 0.85990074 0.85990074 0.85990074 0.85990074 0.85990074 0.85990074\n",
      "        nan 0.85990074 0.85990074 0.85990074 0.85990074 0.85990074\n",
      " 0.85990074 0.85990074 0.85990074        nan 0.85990074 0.85990074\n",
      " 0.85990074 0.85990074 0.85990074 0.85990074 0.85990074 0.85990074\n",
      "        nan 0.92800248 0.92800248 0.92800248 0.92800248 0.92800248\n",
      " 0.92800248 0.92800248 0.92800248        nan 0.92800248 0.92800248\n",
      " 0.92800248 0.92800248 0.92800248 0.92800248 0.92800248 0.92800248\n",
      "        nan 0.92800248 0.92800248 0.92800248 0.92800248 0.92800248\n",
      " 0.92800248 0.92800248 0.92800248        nan 0.92800248 0.92800248\n",
      " 0.92800248 0.92800248 0.92800248 0.92800248 0.92800248 0.92800248\n",
      "        nan 0.91966501 0.91966501 0.91966501 0.91966501 0.91966501\n",
      " 0.91966501 0.91966501 0.91966501        nan 0.91966501 0.91966501\n",
      " 0.91966501 0.91966501 0.91966501 0.91966501 0.91966501 0.91966501\n",
      "        nan 0.91966501 0.91966501 0.91966501 0.91966501 0.91966501\n",
      " 0.91966501 0.91966501 0.91966501        nan 0.91966501 0.91966501\n",
      " 0.91966501 0.91966501 0.91966501 0.91966501 0.91966501 0.91966501\n",
      "        nan 0.96657568 0.96657568 0.96657568 0.96657568 0.9646402\n",
      " 0.95757237 0.95564516 0.95564516        nan 0.96528536 0.96528536\n",
      " 0.96528536 0.96528536 0.9646402  0.95757237 0.95564516 0.95564516\n",
      "        nan 0.96271299 0.96271299 0.96271299 0.96271299 0.96271299\n",
      " 0.95757237 0.95564516 0.95564516        nan 0.95628619 0.95628619\n",
      " 0.95628619 0.95628619 0.95628619 0.95628619 0.95628619 0.95628619\n",
      "        nan 0.97236146 0.97236146 0.97043424 0.96850703 0.96592639\n",
      " 0.95884615 0.9543507  0.95370968        nan 0.971067   0.971067\n",
      " 0.971067   0.96785773 0.96656741 0.95884615 0.9543507  0.95370968\n",
      "        nan 0.96463606 0.96463606 0.96463606 0.96463606 0.96463606\n",
      " 0.96013234 0.95563689 0.95499586        nan 0.95756824 0.95756824\n",
      " 0.95756824 0.95756824 0.95756824 0.95756824 0.95756824 0.95692721\n",
      "        nan 0.98137304 0.97879653 0.97558313 0.97301902 0.96657155\n",
      " 0.95692308 0.95563275 0.95370968        nan 0.97557486 0.97557486\n",
      " 0.97557486 0.97236973 0.96721257 0.95692308 0.95563275 0.95370968\n",
      "        nan 0.96656741 0.96656741 0.96656741 0.96656741 0.96656741\n",
      " 0.95820926 0.95691894 0.95499586        nan 0.95885029 0.95885029\n",
      " 0.95885029 0.95885029 0.95885029 0.95885029 0.95885029 0.95692721\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766        nan 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      "        nan 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766        nan 0.78986766 0.78986766\n",
      " 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766 0.78986766\n",
      "        nan 0.83997932 0.83997932 0.83997932 0.83997932 0.83997932\n",
      " 0.83997932 0.83997932 0.83997932        nan 0.83997932 0.83997932\n",
      " 0.83997932 0.83997932 0.83997932 0.83997932 0.83997932 0.83997932\n",
      "        nan 0.83997932 0.83997932 0.83997932 0.83997932 0.83997932\n",
      " 0.83997932 0.83997932 0.83997932        nan 0.83997932 0.83997932\n",
      " 0.83997932 0.83997932 0.83997932 0.83997932 0.83997932 0.83997932\n",
      "        nan 0.86248139 0.86248139 0.86248139 0.86248139 0.86248139\n",
      " 0.86248139 0.86248139 0.86248139        nan 0.86248139 0.86248139\n",
      " 0.86248139 0.86248139 0.86248139 0.86248139 0.86248139 0.86248139\n",
      "        nan 0.86248139 0.86248139 0.86248139 0.86248139 0.86248139\n",
      " 0.86248139 0.86248139 0.86248139        nan 0.86248139 0.86248139\n",
      " 0.86248139 0.86248139 0.86248139 0.86248139 0.86248139 0.86248139\n",
      "        nan 0.91066584 0.91066584 0.91066584 0.91066584 0.91066584\n",
      " 0.91066584 0.91066584 0.91066584        nan 0.91066584 0.91066584\n",
      " 0.91066584 0.91066584 0.91066584 0.91066584 0.91066584 0.91066584\n",
      "        nan 0.91066584 0.91066584 0.91066584 0.91066584 0.91066584\n",
      " 0.91066584 0.91066584 0.91066584        nan 0.91066584 0.91066584\n",
      " 0.91066584 0.91066584 0.91066584 0.91066584 0.91066584 0.91066584\n",
      "        nan 0.91900744 0.91900744 0.91900744 0.91900744 0.91900744\n",
      " 0.91900744 0.91900744 0.91900744        nan 0.91900744 0.91900744\n",
      " 0.91900744 0.91900744 0.91900744 0.91900744 0.91900744 0.91900744\n",
      "        nan 0.91900744 0.91900744 0.91900744 0.91900744 0.91900744\n",
      " 0.91900744 0.91900744 0.91900744        nan 0.91900744 0.91900744\n",
      " 0.91900744 0.91900744 0.91900744 0.91900744 0.91900744 0.91900744\n",
      "        nan 0.96143921 0.96143921 0.96143921 0.96143921 0.9588627\n",
      " 0.95372208 0.95115385 0.95115385        nan 0.96014888 0.96014888\n",
      " 0.96014888 0.96014888 0.9588627  0.95372208 0.95115385 0.95115385\n",
      "        nan 0.95758065 0.95758065 0.95758065 0.95758065 0.95758065\n",
      " 0.95372208 0.95115385 0.95115385        nan 0.95179901 0.95179901\n",
      " 0.95179901 0.95179901 0.95179901 0.95179901 0.95179901 0.95179901\n",
      "        nan 0.97364351 0.97364351 0.97107113 0.97235318 0.96913565\n",
      " 0.96142266 0.9614268  0.9614268         nan 0.97106286 0.97106286\n",
      " 0.97106286 0.97106286 0.96913565 0.96142266 0.9614268  0.9614268\n",
      "        nan 0.9672043  0.9672043  0.9672043  0.9672043  0.9672043\n",
      " 0.96270885 0.96271299 0.96271299        nan 0.96207196 0.96207196\n",
      " 0.96207196 0.96207196 0.96207196 0.96207196 0.96207196 0.96207196\n",
      "        nan 0.97557899 0.97622829 0.97236973 0.97301075 0.96721671\n",
      " 0.96078991 0.95950372 0.95950372        nan 0.97300662 0.97300662\n",
      " 0.97300662 0.97236146 0.96785773 0.96078991 0.95950372 0.95950372\n",
      "        nan 0.96593052 0.96593052 0.96593052 0.96593052 0.96593052\n",
      " 0.9620761  0.96078991 0.96078991        nan 0.96014888 0.96014888\n",
      " 0.96014888 0.96014888 0.96014888 0.96014888 0.96014888 0.96014888]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624        nan 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      "        nan 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624        nan 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      "        nan 0.85089744 0.85089744 0.85089744 0.85089744 0.85089744\n",
      " 0.85089744 0.85089744 0.85089744        nan 0.85089744 0.85089744\n",
      " 0.85089744 0.85089744 0.85089744 0.85089744 0.85089744 0.85089744\n",
      "        nan 0.85089744 0.85089744 0.85089744 0.85089744 0.85089744\n",
      " 0.85089744 0.85089744 0.85089744        nan 0.85089744 0.85089744\n",
      " 0.85089744 0.85089744 0.85089744 0.85089744 0.85089744 0.85089744\n",
      "        nan 0.87143921 0.87143921 0.87143921 0.87143921 0.87143921\n",
      " 0.87143921 0.87143921 0.87143921        nan 0.87143921 0.87143921\n",
      " 0.87143921 0.87143921 0.87143921 0.87143921 0.87143921 0.87143921\n",
      "        nan 0.87143921 0.87143921 0.87143921 0.87143921 0.87143921\n",
      " 0.87143921 0.87143921 0.87143921        nan 0.87143921 0.87143921\n",
      " 0.87143921 0.87143921 0.87143921 0.87143921 0.87143921 0.87143921\n",
      "        nan 0.93381307 0.93381307 0.93381307 0.93381307 0.93381307\n",
      " 0.93381307 0.93381307 0.93381307        nan 0.93381307 0.93381307\n",
      " 0.93381307 0.93381307 0.93381307 0.93381307 0.93381307 0.93381307\n",
      "        nan 0.93381307 0.93381307 0.93381307 0.93381307 0.93381307\n",
      " 0.93381307 0.93381307 0.93381307        nan 0.93381307 0.93381307\n",
      " 0.93381307 0.93381307 0.93381307 0.93381307 0.93381307 0.93381307\n",
      "        nan 0.91902399 0.91902399 0.91902399 0.91902399 0.91902399\n",
      " 0.91902399 0.91902399 0.91902399        nan 0.91902399 0.91902399\n",
      " 0.91902399 0.91902399 0.91902399 0.91902399 0.91902399 0.91902399\n",
      "        nan 0.91902399 0.91902399 0.91902399 0.91902399 0.91902399\n",
      " 0.91902399 0.91902399 0.91902399        nan 0.91902399 0.91902399\n",
      " 0.91902399 0.91902399 0.91902399 0.91902399 0.91902399 0.91902399\n",
      "        nan 0.96980562 0.96980562 0.96980562 0.96916046 0.96723739\n",
      " 0.9633871  0.96017783 0.96017783        nan 0.96980562 0.96980562\n",
      " 0.96980562 0.96916046 0.96723739 0.9633871  0.96017783 0.96017783\n",
      "        nan 0.96595533 0.96595533 0.96595533 0.96595533 0.96595533\n",
      " 0.9633871  0.96017783 0.96017783        nan 0.95825476 0.95825476\n",
      " 0.95825476 0.95825476 0.95825476 0.95825476 0.95825476 0.95825476\n",
      "        nan 0.97045079 0.96980562 0.96851944 0.96723325 0.96466915\n",
      " 0.96209677 0.95631514 0.95631514        nan 0.97044665 0.97044665\n",
      " 0.97044665 0.96916046 0.96659636 0.96274194 0.9569603  0.9569603\n",
      "        nan 0.96531431 0.96531431 0.96531431 0.96531431 0.96531431\n",
      " 0.96274194 0.9569603  0.9569603         nan 0.95567825 0.95567825\n",
      " 0.95567825 0.95567825 0.95567825 0.95567825 0.95567825 0.95567825\n",
      "        nan 0.97944582 0.97944169 0.97687345 0.9749421  0.97174524\n",
      " 0.96273366 0.95566998 0.95631514        nan 0.97944582 0.97944582\n",
      " 0.97944582 0.97751447 0.97367246 0.96337883 0.95631514 0.9569603\n",
      "        nan 0.96852357 0.96852357 0.96852357 0.96852357 0.96852357\n",
      " 0.96337883 0.95631514 0.9569603         nan 0.95503309 0.95503309\n",
      " 0.95503309 0.95503309 0.95503309 0.95503309 0.95503309 0.95567825\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624        nan 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      "        nan 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624        nan 0.79305624 0.79305624\n",
      " 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624 0.79305624\n",
      "        nan 0.8361249  0.8361249  0.8361249  0.8361249  0.8361249\n",
      " 0.8361249  0.8361249  0.8361249         nan 0.8361249  0.8361249\n",
      " 0.8361249  0.8361249  0.8361249  0.8361249  0.8361249  0.8361249\n",
      "        nan 0.8361249  0.8361249  0.8361249  0.8361249  0.8361249\n",
      " 0.8361249  0.8361249  0.8361249         nan 0.8361249  0.8361249\n",
      " 0.8361249  0.8361249  0.8361249  0.8361249  0.8361249  0.8361249\n",
      "        nan 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251        nan 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      "        nan 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251        nan 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      "        nan 0.90488007 0.90488007 0.90488007 0.90488007 0.90488007\n",
      " 0.90488007 0.90488007 0.90488007        nan 0.90488007 0.90488007\n",
      " 0.90488007 0.90488007 0.90488007 0.90488007 0.90488007 0.90488007\n",
      "        nan 0.90488007 0.90488007 0.90488007 0.90488007 0.90488007\n",
      " 0.90488007 0.90488007 0.90488007        nan 0.90488007 0.90488007\n",
      " 0.90488007 0.90488007 0.90488007 0.90488007 0.90488007 0.90488007\n",
      "        nan 0.92352771 0.92352771 0.92352771 0.92352771 0.92352771\n",
      " 0.92352771 0.92352771 0.92352771        nan 0.92352771 0.92352771\n",
      " 0.92352771 0.92352771 0.92352771 0.92352771 0.92352771 0.92352771\n",
      "        nan 0.92352771 0.92352771 0.92352771 0.92352771 0.92352771\n",
      " 0.92352771 0.92352771 0.92352771        nan 0.92352771 0.92352771\n",
      " 0.92352771 0.92352771 0.92352771 0.92352771 0.92352771 0.92352771\n",
      "        nan 0.9588751  0.9588751  0.9588751  0.95822994 0.95566584\n",
      " 0.95438379 0.95373863 0.95373863        nan 0.9588751  0.9588751\n",
      " 0.9588751  0.95822994 0.95566584 0.95438379 0.95373863 0.95373863\n",
      "        nan 0.95438379 0.95438379 0.95438379 0.95438379 0.95438379\n",
      " 0.95438379 0.95373863 0.95373863        nan 0.95373863 0.95373863\n",
      " 0.95373863 0.95373863 0.95373863 0.95373863 0.95373863 0.95373863\n",
      "        nan 0.96788668 0.96788668 0.96659636 0.9659512  0.96402812\n",
      " 0.96145988 0.95953267 0.95953267        nan 0.96852357 0.96852357\n",
      " 0.96852357 0.96787841 0.96531431 0.96210505 0.96017783 0.96017783\n",
      "        nan 0.96403226 0.96403226 0.96403226 0.96403226 0.96403226\n",
      " 0.96210505 0.96017783 0.96017783        nan 0.95954094 0.95954094\n",
      " 0.95954094 0.95954094 0.95954094 0.95954094 0.95954094 0.95954094\n",
      "        nan 0.97366832 0.97366832 0.97109595 0.9666005  0.96468156\n",
      " 0.95824648 0.95695616 0.95760132        nan 0.97238213 0.97238213\n",
      " 0.97238213 0.96852771 0.96596774 0.95889165 0.95760132 0.95824648\n",
      "        nan 0.96210505 0.96210505 0.96210505 0.96210505 0.96210505\n",
      " 0.95889165 0.95760132 0.95824648        nan 0.95696443 0.95696443\n",
      " 0.95696443 0.95696443 0.95696443 0.95696443 0.95696443 0.95760959]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "param_dict={'criterion':['gini','entropy'], 'max_depth':range(1,11), 'min_samples_leaf':range(1,5), \n",
    "            'min_samples_split':range(1,10)} \n",
    "d_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_tree = GridSearchCV(d_tree, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_tree.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "nested_score_tree = cross_val_score(grid_tree, X=X, y=y, cv=cv) \n",
    "f_measure_score['decision_tree']['mean'] = np.mean(nested_score_tree)\n",
    "f_measure_score['decision_tree']['std'] = np.std(nested_score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a3223f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.94      0.88      0.91       129\n",
      "        good       0.73      0.95      0.83        20\n",
      "       unacc       0.98      0.99      0.99       397\n",
      "       vgood       0.83      0.80      0.82        25\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b64aafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de63bc",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "837b2e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366        nan        nan 0.70268366        nan\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366        nan        nan\n",
      " 0.70268366        nan 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan        nan 0.81763868        nan 0.81676162 0.81676162\n",
      " 0.81676162 0.81676162        nan        nan 0.7744003         nan\n",
      " 0.76493253 0.76493253 0.76493253 0.76493253        nan        nan\n",
      " 0.82107196        nan 0.82194903 0.82194903 0.82194903 0.82194903\n",
      "        nan        nan 0.8228036         nan 0.82194153 0.82194153\n",
      " 0.8228036  0.82194153        nan        nan 0.8228036         nan\n",
      " 0.82193403 0.82193403 0.8228036  0.82193403]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.70418528 0.70418528 0.70418528 0.70418528\n",
      "        nan        nan 0.82383788        nan 0.81933002 0.81933002\n",
      " 0.81933002 0.81933002        nan        nan 0.78137304        nan\n",
      " 0.76786187 0.76786187 0.76786187 0.76786187        nan        nan\n",
      " 0.83090984        nan 0.82897849 0.82897849 0.82897849 0.82897849\n",
      "        nan        nan 0.83155087        nan 0.83219603 0.83219603\n",
      " 0.83284119 0.83219603        nan        nan 0.83155087        nan\n",
      " 0.83155087 0.83155087 0.83155087 0.83155087]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.70546319 0.70546319 0.70546319 0.70546319\n",
      "        nan        nan 0.82767577        nan 0.82443342 0.82443342\n",
      " 0.82443342 0.82443342        nan        nan 0.79162531        nan\n",
      " 0.7742804  0.7742804  0.7742804  0.7742804         nan        nan\n",
      " 0.83218776        nan 0.83218362 0.83153846 0.83218362 0.83218362\n",
      "        nan        nan 0.83411911        nan 0.83347395 0.83347395\n",
      " 0.83283292 0.83347395        nan        nan 0.83411911        nan\n",
      " 0.83347395 0.83411911 0.83411911 0.83347395]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.70483457 0.70483457 0.70483457 0.70483457\n",
      "        nan        nan 0.82186931        nan 0.81737386 0.81737386\n",
      " 0.81737386 0.81737386        nan        nan 0.78522333        nan\n",
      " 0.76722911 0.76722911 0.76722911 0.76722911        nan        nan\n",
      " 0.8302316         nan 0.82766336 0.82830438 0.82766336 0.82766336\n",
      "        nan        nan 0.8302316         nan 0.83087262 0.83087262\n",
      " 0.83087262 0.83087262        nan        nan 0.8302316         nan\n",
      " 0.8302316  0.8302316  0.8302316  0.8302316 ]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.7054756  0.7054756  0.7054756  0.7054756\n",
      "        nan        nan 0.83146816        nan 0.8237469  0.82310587\n",
      " 0.8237469  0.8237469         nan        nan 0.78708437        nan\n",
      " 0.77038875 0.77038875 0.77038875 0.77038875        nan        nan\n",
      " 0.83402399        nan 0.8333871  0.8333871  0.8333871  0.8333871\n",
      "        nan        nan 0.83531431        nan 0.83531431 0.83531431\n",
      " 0.83531431 0.83531431        nan        nan 0.83531431        nan\n",
      " 0.83466915 0.83466915 0.83531431 0.83466915]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.70418941 0.70418941 0.70418941 0.70418941\n",
      "        nan        nan 0.82508685        nan 0.82251861 0.82251861\n",
      " 0.82251861 0.82251861        nan        nan 0.78457403        nan\n",
      " 0.76657568 0.76657568 0.76657568 0.76657568        nan        nan\n",
      " 0.83215054        nan 0.8302316  0.8302316  0.8302316  0.8302316\n",
      "        nan        nan 0.83215054        nan 0.8327957  0.8327957\n",
      " 0.8327957  0.8327957         nan        nan 0.83215054        nan\n",
      " 0.83215054 0.83215054 0.83215054 0.83215054]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.70675352 0.70675352 0.70675352 0.70675352\n",
      "        nan        nan 0.81872622        nan 0.81742763 0.81742763\n",
      " 0.81742763 0.81742763        nan        nan 0.78204301        nan\n",
      " 0.76855252 0.76855252 0.76855252 0.76855252        nan        nan\n",
      " 0.82578991        nan 0.82578991 0.82578991 0.82578991 0.82578991\n",
      "        nan        nan 0.82643093        nan 0.82643093 0.82643093\n",
      " 0.82643093 0.82643093        nan        nan 0.82643093        nan\n",
      " 0.82643093 0.82643093 0.82643093 0.82643093]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.70676592 0.70676592 0.70676592 0.70676592\n",
      "        nan        nan 0.8231555         nan 0.81672457 0.81672457\n",
      " 0.81672457 0.81672457        nan        nan 0.7807196         nan\n",
      " 0.76465674 0.76465674 0.76465674 0.76465674        nan        nan\n",
      " 0.82765095        nan 0.82507858 0.82507858 0.82507858 0.82507858\n",
      "        nan        nan 0.82829611        nan 0.82829611 0.82829611\n",
      " 0.82829611 0.82829611        nan        nan 0.82829611        nan\n",
      " 0.82765509 0.82765509 0.82829611 0.82765509]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.7080397  0.7080397  0.7080397  0.7080397\n",
      "        nan        nan 0.82254342        nan 0.81545906 0.81545906\n",
      " 0.81545906 0.81545906        nan        nan 0.78458644        nan\n",
      " 0.77235732 0.77235732 0.77235732 0.77235732        nan        nan\n",
      " 0.82640612        nan 0.82576096 0.82576096 0.82576096 0.82576096\n",
      "        nan        nan 0.82897436        nan 0.82897436 0.82897436\n",
      " 0.82897436 0.82897436        nan        nan 0.82897436        nan\n",
      " 0.82769231 0.82833333 0.82897436 0.82769231]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593        nan        nan 0.69987593        nan\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593        nan        nan\n",
      " 0.69987593        nan 0.70630687 0.70630687 0.70630687 0.70630687\n",
      "        nan        nan 0.8252316         nan 0.82909016 0.82909016\n",
      " 0.82909016 0.82909016        nan        nan 0.78795285        nan\n",
      " 0.77188999 0.77188999 0.77188999 0.77188999        nan        nan\n",
      " 0.83616625        nan 0.83360215 0.83360215 0.83360215 0.83360215\n",
      "        nan        nan 0.83617039        nan 0.83617039 0.83617039\n",
      " 0.83552523 0.83617039        nan        nan 0.83617039        nan\n",
      " 0.83617039 0.83617039 0.83617039 0.83552936]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593        nan        nan 0.69987593        nan\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593        nan        nan\n",
      " 0.69987593        nan 0.70630687 0.70630687 0.70630687 0.70630687\n",
      "        nan        nan 0.83035567        nan 0.82650538 0.82650538\n",
      " 0.82650538 0.82650538        nan        nan 0.78731183        nan\n",
      " 0.77509926 0.77509926 0.77509926 0.77509926        nan        nan\n",
      " 0.83228288        nan 0.83099256 0.83099256 0.83099256 0.83099256\n",
      "        nan        nan 0.8329239         nan 0.83228288 0.83228288\n",
      " 0.83228288 0.83228288        nan        nan 0.83356907        nan\n",
      " 0.83356907 0.83356907 0.83356907 0.83356907]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'C':[0.0001,0.001, 0.01, 1, 0.1, 10, 100, 1000], 'penalty':['l1','l2'],\n",
    "              'solver':['lbfgs','sag','saga','newton-cg']}\n",
    "\n",
    "logistic = linear_model.LogisticRegression(random_state=42)\n",
    "\n",
    "grid_log = GridSearchCV(logistic, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = grid_log.predict(X_test)\n",
    "nested_score_log = cross_val_score(grid_log, X=X, y=y, cv=cv) \n",
    "f_measure_score['logistic']['mean'] = np.mean(nested_score_log)\n",
    "f_measure_score['logistic']['std'] = np.std(nested_score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f464724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.68      0.58      0.63       129\n",
      "        good       0.67      0.50      0.57        20\n",
      "       unacc       0.88      0.93      0.90       397\n",
      "       vgood       0.73      0.76      0.75        25\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.74      0.69      0.71       571\n",
      "weighted avg       0.82      0.83      0.82       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_log),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2db262a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_log.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9a3e2",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dc598249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'n_neighbors':list(range(1,31)), 'weights':['uniform', 'distance']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "nested_score_knn = cross_val_score(grid_knn, X=X, y=y, cv=cv) \n",
    "f_measure_score['knn']['mean'] = np.mean(nested_score_knn)\n",
    "f_measure_score['knn']['std'] = np.std(nested_score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "81080fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.90      0.91      0.91       129\n",
      "        good       0.83      0.75      0.79        20\n",
      "       unacc       0.98      0.99      0.98       397\n",
      "       vgood       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.86      0.89       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d27510d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 15, 'weights': 'distance'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae1d7a",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fccf1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "nested_score_nb = cross_val_score(nb, X=X, y=y, cv=cv) \n",
    "f_measure_score['NB']['mean'] = np.mean(nested_score_nb)\n",
    "f_measure_score['NB']['std'] = np.std(nested_score_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "58423d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.60      0.20      0.30       129\n",
      "        good       0.45      0.25      0.32        20\n",
      "       unacc       0.87      0.86      0.86       397\n",
      "       vgood       0.20      1.00      0.34        25\n",
      "\n",
      "    accuracy                           0.70       571\n",
      "   macro avg       0.53      0.58      0.46       571\n",
      "weighted avg       0.76      0.70      0.69       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_nb),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c7e6a",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "72c7ec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'C':[0.1,1,100,1000],'kernel':['rbf','linear'], 'gamma':[1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "grid_svm = GridSearchCV(svm, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "nested_score_svm = cross_val_score(grid_svm, X=X, y=y, cv=cv) \n",
    "f_measure_score['svm']['mean'] = np.mean(nested_score_svm)\n",
    "f_measure_score['svm']['std'] = np.std(nested_score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "582461ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.98      0.93      0.96       129\n",
      "        good       0.83      1.00      0.91        20\n",
      "       unacc       0.99      1.00      0.99       397\n",
      "       vgood       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_svm),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e226378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881fe18",
   "metadata": {},
   "source": [
    "### Models Comparision (numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9acd2399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree :  {'mean': 0.9733599946229331, 'std': 0.014727376194893544}\n",
      "knn :  {'mean': 0.9583445355558544, 'std': 0.01432197139682613}\n",
      "logistic :  {'mean': 0.8309819868261863, 'std': 0.02560389666625801}\n",
      "NB :  {'mean': 0.6944448178518619, 'std': 0.018954651788038478}\n",
      "svm :  {'mean': 0.9942028498454093, 'std': 0.008222189044405052}\n"
     ]
    }
   ],
   "source": [
    "for k,v in f_measure_score.items():\n",
    "    print(k, ': ', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1703800",
   "metadata": {},
   "source": [
    "#### Result: SVM got the best performance in numeric attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7b1860be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   4   5   0]\n",
      " [  0  20   0   0]\n",
      " [  1   0 396   0]\n",
      " [  1   0   0  24]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.98      0.93      0.96       129\n",
      "        good       0.83      1.00      0.91        20\n",
      "       unacc       0.99      1.00      0.99       397\n",
      "       vgood       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix and calculate other indicators\n",
    "grid_predictions = grid_svm.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_svm))\n",
    "print(\"\")\n",
    "print(classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e7e192",
   "metadata": {},
   "source": [
    "## Categorical Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c891f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "car = pd.read_csv('car.data', names=['buying','maint','doors','persons','lug_boot','safety','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cf00f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dummy variable\n",
    "X = pd.get_dummies(car.iloc[:,:6])\n",
    "y = car['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bc23d",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "65f93f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=45)\n",
    "f_measure_score_c = {'decision_tree':{},'knn':{},'logistic':{},'NB':{},'svm':{}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e664d1",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d2f645b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756        nan 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      "        nan 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756        nan 0.78988756 0.78988756\n",
      " 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756 0.78988756\n",
      "        nan 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574        nan 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      "        nan 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574        nan 0.79851574 0.79851574\n",
      " 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574 0.79851574\n",
      "        nan 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345        nan 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      "        nan 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345        nan 0.83310345 0.83310345\n",
      " 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345 0.83310345\n",
      "        nan 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609        nan 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      "        nan 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609        nan 0.84782609 0.84782609\n",
      " 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609 0.84782609\n",
      "        nan 0.90404048 0.90404048 0.90404048 0.90404048 0.90404048\n",
      " 0.90317091 0.90317091 0.90230885        nan 0.90404048 0.90404048\n",
      " 0.90404048 0.90404048 0.90404048 0.90317091 0.90317091 0.90230885\n",
      "        nan 0.90317091 0.90317091 0.90317091 0.90317091 0.90317091\n",
      " 0.90317091 0.90317091 0.90230885        nan 0.90144678 0.90144678\n",
      " 0.90144678 0.90144678 0.90144678 0.90144678 0.90144678 0.90058471\n",
      "        nan 0.92133433 0.92305847 0.92392054 0.92392054 0.92305847\n",
      " 0.92218891 0.92218891 0.92132684        nan 0.92392054 0.92392054\n",
      " 0.92392054 0.92392054 0.92305847 0.92218891 0.92218891 0.92132684\n",
      "        nan 0.92478261 0.92478261 0.92478261 0.92478261 0.92478261\n",
      " 0.92478261 0.92478261 0.92392054        nan 0.92478261 0.92478261\n",
      " 0.92478261 0.92478261 0.92478261 0.92478261 0.92478261 0.92392054\n",
      "        nan 0.9489955  0.95072714 0.94727136 0.94727136 0.94295352\n",
      " 0.9412069  0.93862069 0.93342579        nan 0.94553223 0.94553223\n",
      " 0.94553223 0.94985757 0.94553973 0.9437931  0.94034483 0.93514993\n",
      "        nan 0.94467016 0.94467016 0.94467016 0.94467016 0.94467016\n",
      " 0.94465517 0.9412069  0.93601199        nan 0.93688906 0.93688906\n",
      " 0.93688906 0.93688906 0.93688906 0.93688906 0.93688906 0.93341829\n",
      "        nan 0.961994   0.96373313 0.95766867 0.96112444 0.9568066\n",
      " 0.95504498 0.9489955  0.9412069         nan 0.95937781 0.95937781\n",
      " 0.95937781 0.96110945 0.96025487 0.95763118 0.95071964 0.94293103\n",
      "        nan 0.95764618 0.95764618 0.95764618 0.95764618 0.95764618\n",
      " 0.95849325 0.95071214 0.94466267        nan 0.94726387 0.94726387\n",
      " 0.94726387 0.94726387 0.94726387 0.94726387 0.94726387 0.94293103\n",
      "        nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366 0.70268366\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673        nan 0.76653673 0.76653673\n",
      " 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673 0.76653673\n",
      "        nan 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721        nan 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      "        nan 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721        nan 0.78557721 0.78557721\n",
      " 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721 0.78557721\n",
      "        nan 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654        nan 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      "        nan 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654        nan 0.77692654 0.77692654\n",
      " 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654 0.77692654\n",
      "        nan 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099         nan 0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      "        nan 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099         nan 0.8452099  0.8452099\n",
      " 0.8452099  0.8452099  0.8452099  0.8452099  0.8452099  0.8452099\n",
      "        nan 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687        nan 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      "        nan 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687        nan 0.85126687 0.85126687\n",
      " 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687 0.85126687\n",
      "        nan 0.91352324 0.91352324 0.91352324 0.91352324 0.91352324\n",
      " 0.91352324 0.91352324 0.91266117        nan 0.91352324 0.91352324\n",
      " 0.91352324 0.91352324 0.91352324 0.91352324 0.91352324 0.91266117\n",
      "        nan 0.91352324 0.91352324 0.91352324 0.91352324 0.91352324\n",
      " 0.91352324 0.91352324 0.91266117        nan 0.9117991  0.9117991\n",
      " 0.9117991  0.9117991  0.9117991  0.9117991  0.9117991  0.91093703\n",
      "        nan 0.92910795 0.92910795 0.92824588 0.92824588 0.92824588\n",
      " 0.92824588 0.92910795 0.92824588        nan 0.92910795 0.92910795\n",
      " 0.92910795 0.92910795 0.92910795 0.92910795 0.92910795 0.92824588\n",
      "        nan 0.92910795 0.92910795 0.92910795 0.92910795 0.92910795\n",
      " 0.92910795 0.92910795 0.92824588        nan 0.92651424 0.92651424\n",
      " 0.92651424 0.92651424 0.92651424 0.92651424 0.92651424 0.92651424\n",
      "        nan 0.95330585 0.95503748 0.95158921 0.95245127 0.95071964\n",
      " 0.95071964 0.95158171 0.94724888        nan 0.94986507 0.94986507\n",
      " 0.94986507 0.95245127 0.95071964 0.95071964 0.95158171 0.94724888\n",
      "        nan 0.95071964 0.95071964 0.95071964 0.95071964 0.95071964\n",
      " 0.95071964 0.95071964 0.94638681        nan 0.94638681 0.94638681\n",
      " 0.94638681 0.94638681 0.94638681 0.94638681 0.94638681 0.94377811\n",
      "        nan 0.96369565 0.96370315 0.96025487 0.95938531 0.95852324\n",
      " 0.95938531 0.95937031 0.95331334        nan 0.9567916  0.9567916\n",
      " 0.9567916  0.95850825 0.95938531 0.95938531 0.95937031 0.95331334\n",
      "        nan 0.96024738 0.96024738 0.96024738 0.96024738 0.96024738\n",
      " 0.95938531 0.95764618 0.95158921        nan 0.9516042  0.9516042\n",
      " 0.9516042  0.9516042  0.9516042  0.9516042  0.9516042  0.94985757]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.79614971 0.79614971 0.79614971 0.79614971 0.79614971\n",
      " 0.79614971 0.79614971 0.79614971        nan 0.79614971 0.79614971\n",
      " 0.79614971 0.79614971 0.79614971 0.79614971 0.79614971 0.79614971\n",
      "        nan 0.79614971 0.79614971 0.79614971 0.79614971 0.79614971\n",
      " 0.79614971 0.79614971 0.79614971        nan 0.79614971 0.79614971\n",
      " 0.79614971 0.79614971 0.79614971 0.79614971 0.79614971 0.79614971\n",
      "        nan 0.80128619 0.80128619 0.80128619 0.80128619 0.80128619\n",
      " 0.80128619 0.80128619 0.80128619        nan 0.80128619 0.80128619\n",
      " 0.80128619 0.80128619 0.80128619 0.80128619 0.80128619 0.80128619\n",
      "        nan 0.80128619 0.80128619 0.80128619 0.80128619 0.80128619\n",
      " 0.80128619 0.80128619 0.80128619        nan 0.80128619 0.80128619\n",
      " 0.80128619 0.80128619 0.80128619 0.80128619 0.80128619 0.80128619\n",
      "        nan 0.86430108 0.86430108 0.86430108 0.86430108 0.86430108\n",
      " 0.86430108 0.86430108 0.86430108        nan 0.86430108 0.86430108\n",
      " 0.86430108 0.86430108 0.86430108 0.86430108 0.86430108 0.86430108\n",
      "        nan 0.86430108 0.86430108 0.86430108 0.86430108 0.86430108\n",
      " 0.86430108 0.86430108 0.86430108        nan 0.86430108 0.86430108\n",
      " 0.86430108 0.86430108 0.86430108 0.86430108 0.86430108 0.86430108\n",
      "        nan 0.87395368 0.87395368 0.87395368 0.87395368 0.87395368\n",
      " 0.87395368 0.87395368 0.87330852        nan 0.87395368 0.87395368\n",
      " 0.87395368 0.87395368 0.87395368 0.87395368 0.87395368 0.87330852\n",
      "        nan 0.87395368 0.87395368 0.87395368 0.87395368 0.87395368\n",
      " 0.87395368 0.87395368 0.87330852        nan 0.87395368 0.87395368\n",
      " 0.87395368 0.87395368 0.87395368 0.87395368 0.87395368 0.87330852\n",
      "        nan 0.91510339 0.91510339 0.91510339 0.91510339 0.91574855\n",
      " 0.91639371 0.91639371 0.91574855        nan 0.91574855 0.91574855\n",
      " 0.91574855 0.91574855 0.91574855 0.91639371 0.91639371 0.91574855\n",
      "        nan 0.91574855 0.91574855 0.91574855 0.91574855 0.91574855\n",
      " 0.91639371 0.91639371 0.91574855        nan 0.91639371 0.91639371\n",
      " 0.91639371 0.91639371 0.91639371 0.91639371 0.91639371 0.91574855\n",
      "        nan 0.9292225  0.9292225  0.9292225  0.9292225  0.92986766\n",
      " 0.93051282 0.93115385 0.92922663        nan 0.93050868 0.93050868\n",
      " 0.93050868 0.93050868 0.93050868 0.93115385 0.93115385 0.92922663\n",
      "        nan 0.92986352 0.92986352 0.92986352 0.92986352 0.92986352\n",
      " 0.93115385 0.93115385 0.92922663        nan 0.93115385 0.93115385\n",
      " 0.93115385 0.93115385 0.93115385 0.93115385 0.93115385 0.93050868\n",
      "        nan 0.95174524 0.95109595 0.94724566 0.94531017 0.94531431\n",
      " 0.9466005  0.94595533 0.94402812        nan 0.94659636 0.94659636\n",
      " 0.94659636 0.9459512  0.9459512  0.94724152 0.94595533 0.94402812\n",
      "        nan 0.94209264 0.94209264 0.94209264 0.94209264 0.94209264\n",
      " 0.94402812 0.94274194 0.94081472        nan 0.94274607 0.94274607\n",
      " 0.94274607 0.94274607 0.94274607 0.94274607 0.94274607 0.94210091\n",
      "        nan 0.966555   0.96720017 0.96270471 0.96205542 0.96205128\n",
      " 0.95947477 0.95882961 0.9569024         nan 0.96205542 0.96205542\n",
      " 0.96205542 0.9633416  0.96268817 0.9601158  0.95882961 0.9569024\n",
      "        nan 0.95818031 0.95818031 0.95818031 0.95818031 0.95818031\n",
      " 0.95754342 0.95689826 0.95432589        nan 0.95689413 0.95689413\n",
      " 0.95689413 0.95689413 0.95689413 0.95689413 0.95689413 0.95624897\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796        nan 0.77682796 0.77682796\n",
      " 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796 0.77682796\n",
      "        nan 0.79034326 0.79034326 0.79034326 0.79034326 0.79034326\n",
      " 0.79034326 0.79034326 0.79034326        nan 0.79034326 0.79034326\n",
      " 0.79034326 0.79034326 0.79034326 0.79034326 0.79034326 0.79034326\n",
      "        nan 0.79034326 0.79034326 0.79034326 0.79034326 0.79034326\n",
      " 0.79034326 0.79034326 0.79034326        nan 0.79034326 0.79034326\n",
      " 0.79034326 0.79034326 0.79034326 0.79034326 0.79034326 0.79034326\n",
      "        nan 0.79421423 0.79421423 0.79421423 0.79421423 0.79421423\n",
      " 0.79421423 0.79421423 0.79421423        nan 0.79421423 0.79421423\n",
      " 0.79421423 0.79421423 0.79421423 0.79421423 0.79421423 0.79421423\n",
      "        nan 0.79421423 0.79421423 0.79421423 0.79421423 0.79421423\n",
      " 0.79421423 0.79421423 0.79421423        nan 0.79421423 0.79421423\n",
      " 0.79421423 0.79421423 0.79421423 0.79421423 0.79421423 0.79421423\n",
      "        nan 0.8572043  0.8572043  0.8572043  0.8572043  0.8572043\n",
      " 0.8572043  0.8572043  0.8572043         nan 0.8572043  0.8572043\n",
      " 0.8572043  0.8572043  0.8572043  0.8572043  0.8572043  0.8572043\n",
      "        nan 0.8572043  0.8572043  0.8572043  0.8572043  0.8572043\n",
      " 0.8572043  0.8572043  0.8572043         nan 0.8572043  0.8572043\n",
      " 0.8572043  0.8572043  0.8572043  0.8572043  0.8572043  0.8572043\n",
      "        nan 0.87265095 0.87265095 0.87265095 0.87265095 0.87265095\n",
      " 0.87265095 0.87265095 0.87265095        nan 0.87265095 0.87265095\n",
      " 0.87265095 0.87265095 0.87265095 0.87265095 0.87265095 0.87265095\n",
      "        nan 0.87265095 0.87265095 0.87265095 0.87265095 0.87265095\n",
      " 0.87265095 0.87265095 0.87265095        nan 0.87265095 0.87265095\n",
      " 0.87265095 0.87265095 0.87265095 0.87265095 0.87265095 0.87265095\n",
      "        nan 0.9266708  0.9266708  0.9266708  0.9266708  0.9266708\n",
      " 0.9266708  0.9266708  0.9266708         nan 0.9266708  0.9266708\n",
      " 0.9266708  0.9266708  0.9266708  0.9266708  0.9266708  0.9266708\n",
      "        nan 0.9266708  0.9266708  0.9266708  0.9266708  0.9266708\n",
      " 0.9266708  0.9266708  0.9266708         nan 0.9266708  0.9266708\n",
      " 0.9266708  0.9266708  0.9266708  0.9266708  0.9266708  0.9266708\n",
      "        nan 0.93568652 0.93568652 0.93568652 0.93375517 0.93311414\n",
      " 0.93311414 0.93311414 0.93311414        nan 0.93568652 0.93568652\n",
      " 0.93568652 0.93504549 0.93440447 0.93440447 0.93440447 0.93440447\n",
      "        nan 0.93504963 0.93504963 0.93504963 0.93504963 0.93504963\n",
      " 0.93504963 0.93504963 0.93504963        nan 0.93569065 0.93569065\n",
      " 0.93569065 0.93569065 0.93569065 0.93569065 0.93569065 0.93569065\n",
      "        nan 0.96397849 0.96268817 0.95947891 0.9569024  0.95561621\n",
      " 0.95561621 0.95433002 0.9530397         nan 0.95883375 0.95883375\n",
      " 0.95883375 0.95819272 0.95690653 0.95690653 0.95562035 0.95433002\n",
      "        nan 0.9575517  0.9575517  0.9575517  0.9575517  0.9575517\n",
      " 0.9575517  0.95626551 0.95497519        nan 0.9530397  0.9530397\n",
      " 0.9530397  0.9530397  0.9530397  0.9530397  0.9530397  0.95174938\n",
      "        nan 0.96588503 0.96460298 0.96203888 0.96010753 0.95946237\n",
      " 0.9588172  0.9588172  0.95688172        nan 0.96332093 0.96332093\n",
      " 0.96332093 0.9626799  0.96139371 0.96074855 0.96010753 0.95817204\n",
      "        nan 0.96203888 0.96203888 0.96203888 0.96203888 0.96203888\n",
      " 0.96139371 0.96075269 0.95946237        nan 0.95945823 0.95945823\n",
      " 0.95945823 0.95945823 0.95945823 0.95945823 0.95945823 0.95751861]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.80132754 0.80132754 0.80132754 0.80132754 0.80132754\n",
      " 0.80132754 0.80132754 0.80132754        nan 0.80132754 0.80132754\n",
      " 0.80132754 0.80132754 0.80132754 0.80132754 0.80132754 0.80132754\n",
      "        nan 0.80132754 0.80132754 0.80132754 0.80132754 0.80132754\n",
      " 0.80132754 0.80132754 0.80132754        nan 0.80132754 0.80132754\n",
      " 0.80132754 0.80132754 0.80132754 0.80132754 0.80132754 0.80132754\n",
      "        nan 0.80968156 0.80968156 0.80968156 0.80968156 0.80968156\n",
      " 0.80968156 0.80968156 0.80968156        nan 0.80968156 0.80968156\n",
      " 0.80968156 0.80968156 0.80968156 0.80968156 0.80968156 0.80968156\n",
      "        nan 0.80968156 0.80968156 0.80968156 0.80968156 0.80968156\n",
      " 0.80968156 0.80968156 0.80968156        nan 0.80968156 0.80968156\n",
      " 0.80968156 0.80968156 0.80968156 0.80968156 0.80968156 0.80968156\n",
      "        nan 0.87010339 0.87010339 0.87010339 0.87010339 0.87010339\n",
      " 0.87010339 0.87010339 0.87010339        nan 0.87010339 0.87010339\n",
      " 0.87010339 0.87010339 0.87010339 0.87010339 0.87010339 0.87010339\n",
      "        nan 0.87010339 0.87010339 0.87010339 0.87010339 0.87010339\n",
      " 0.87010339 0.87010339 0.87010339        nan 0.87010339 0.87010339\n",
      " 0.87010339 0.87010339 0.87010339 0.87010339 0.87010339 0.87010339\n",
      "        nan 0.86948304 0.86948304 0.86948304 0.86948304 0.86948304\n",
      " 0.86948304 0.86948304 0.86948304        nan 0.86948304 0.86948304\n",
      " 0.86948304 0.86948304 0.86948304 0.86948304 0.86948304 0.86948304\n",
      "        nan 0.86948304 0.86948304 0.86948304 0.86948304 0.86948304\n",
      " 0.86948304 0.86948304 0.86948304        nan 0.86948304 0.86948304\n",
      " 0.86948304 0.86948304 0.86948304 0.86948304 0.86948304 0.86948304\n",
      "        nan 0.91574855 0.91574855 0.91574855 0.91574855 0.91639371\n",
      " 0.91639371 0.91639371 0.91639371        nan 0.91639371 0.91639371\n",
      " 0.91639371 0.91639371 0.91639371 0.91639371 0.91639371 0.91639371\n",
      "        nan 0.91703888 0.91703888 0.91703888 0.91703888 0.91703888\n",
      " 0.91703888 0.91703888 0.91703888        nan 0.91703888 0.91703888\n",
      " 0.91703888 0.91703888 0.91703888 0.91703888 0.91703888 0.91703888\n",
      "        nan 0.93375931 0.93375931 0.93375931 0.93311828 0.93504549\n",
      " 0.93504549 0.93504549 0.93504549        nan 0.93632754 0.93632754\n",
      " 0.93632754 0.93568652 0.93632754 0.93632754 0.93632754 0.93632754\n",
      "        nan 0.9369727  0.9369727  0.9369727  0.9369727  0.9369727\n",
      " 0.9369727  0.9369727  0.9369727         nan 0.93825476 0.93825476\n",
      " 0.93825476 0.93825476 0.93825476 0.93825476 0.93825476 0.93825476\n",
      "        nan 0.94726634 0.94790736 0.9446981  0.94341605 0.9446981\n",
      " 0.94533912 0.94212159 0.94212159        nan 0.9472622  0.9472622\n",
      " 0.9472622  0.94662531 0.94662117 0.94662117 0.94340364 0.94340364\n",
      "        nan 0.94404053 0.94404053 0.94404053 0.94404053 0.94404053\n",
      " 0.94404053 0.94082299 0.94082299        nan 0.93825062 0.93825062\n",
      " 0.93825062 0.93825062 0.93825062 0.93825062 0.93825062 0.93825062\n",
      "        nan 0.96398263 0.96462366 0.96141853 0.95949132 0.96076923\n",
      " 0.95691894 0.95370141 0.95112903        nan 0.96398263 0.96398263\n",
      " 0.96398263 0.96205542 0.96140612 0.95755583 0.95369313 0.95241108\n",
      "        nan 0.95561621 0.95561621 0.95561621 0.95561621 0.95561621\n",
      " 0.95497519 0.95111249 0.94918528        nan 0.9504756  0.9504756\n",
      " 0.9504756  0.9504756  0.9504756  0.9504756  0.9504756  0.94983457\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025        nan 0.78330025 0.78330025\n",
      " 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025 0.78330025\n",
      "        nan 0.80709677 0.80709677 0.80709677 0.80709677 0.80709677\n",
      " 0.80709677 0.80709677 0.80709677        nan 0.80709677 0.80709677\n",
      " 0.80709677 0.80709677 0.80709677 0.80709677 0.80709677 0.80709677\n",
      "        nan 0.80709677 0.80709677 0.80709677 0.80709677 0.80709677\n",
      " 0.80709677 0.80709677 0.80709677        nan 0.80709677 0.80709677\n",
      " 0.80709677 0.80709677 0.80709677 0.80709677 0.80709677 0.80709677\n",
      "        nan 0.79357734 0.79357734 0.79357734 0.79357734 0.79357734\n",
      " 0.79357734 0.79357734 0.79357734        nan 0.79357734 0.79357734\n",
      " 0.79357734 0.79357734 0.79357734 0.79357734 0.79357734 0.79357734\n",
      "        nan 0.79357734 0.79357734 0.79357734 0.79357734 0.79357734\n",
      " 0.79357734 0.79357734 0.79357734        nan 0.79357734 0.79357734\n",
      " 0.79357734 0.79357734 0.79357734 0.79357734 0.79357734 0.79357734\n",
      "        nan 0.86429694 0.86429694 0.86429694 0.86429694 0.86429694\n",
      " 0.86429694 0.86429694 0.86429694        nan 0.86429694 0.86429694\n",
      " 0.86429694 0.86429694 0.86429694 0.86429694 0.86429694 0.86429694\n",
      "        nan 0.86429694 0.86429694 0.86429694 0.86429694 0.86429694\n",
      " 0.86429694 0.86429694 0.86429694        nan 0.86429694 0.86429694\n",
      " 0.86429694 0.86429694 0.86429694 0.86429694 0.86429694 0.86429694\n",
      "        nan 0.86940447 0.86940447 0.86940447 0.86940447 0.86940447\n",
      " 0.86940447 0.86940447 0.86940447        nan 0.86940447 0.86940447\n",
      " 0.86940447 0.86940447 0.86940447 0.86940447 0.86940447 0.86940447\n",
      "        nan 0.86940447 0.86940447 0.86940447 0.86940447 0.86940447\n",
      " 0.86940447 0.86940447 0.86940447        nan 0.86940447 0.86940447\n",
      " 0.86940447 0.86940447 0.86940447 0.86940447 0.86940447 0.86940447\n",
      "        nan 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033        nan 0.93440033 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033\n",
      "        nan 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033        nan 0.93440033 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033\n",
      "        nan 0.936311   0.936311   0.936311   0.936311   0.936311\n",
      " 0.936311   0.936311   0.936311          nan 0.936311   0.936311\n",
      " 0.936311   0.936311   0.936311   0.936311   0.936311   0.936311\n",
      "        nan 0.936311   0.936311   0.936311   0.936311   0.936311\n",
      " 0.936311   0.936311   0.936311          nan 0.93759719 0.93759719\n",
      " 0.93759719 0.93759719 0.93759719 0.93759719 0.93759719 0.93759719\n",
      "        nan 0.96465261 0.96465261 0.9620761  0.96014888 0.96014888\n",
      " 0.96014888 0.96014888 0.95885856        nan 0.95949959 0.95949959\n",
      " 0.95949959 0.95885856 0.95885856 0.95885856 0.95885856 0.95756824\n",
      "        nan 0.95306038 0.95306038 0.95306038 0.95306038 0.95306038\n",
      " 0.95306038 0.95306038 0.95306038        nan 0.94855252 0.94855252\n",
      " 0.94855252 0.94855252 0.94855252 0.94855252 0.94855252 0.94855252\n",
      "        nan 0.97234491 0.97234491 0.96912738 0.96849049 0.96528122\n",
      " 0.96463606 0.96335401 0.96206369        nan 0.96720844 0.96720844\n",
      " 0.96720844 0.96656741 0.96528122 0.96463606 0.96335401 0.96077337\n",
      "        nan 0.96205955 0.96205955 0.96205955 0.96205955 0.96205955\n",
      " 0.96205955 0.96013648 0.95820099        nan 0.95755583 0.95755583\n",
      " 0.95755583 0.95755583 0.95755583 0.95755583 0.95755583 0.95755583]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.78779983 0.78779983 0.78779983 0.78779983 0.78779983\n",
      " 0.78779983 0.78779983 0.78779983        nan 0.78779983 0.78779983\n",
      " 0.78779983 0.78779983 0.78779983 0.78779983 0.78779983 0.78779983\n",
      "        nan 0.78779983 0.78779983 0.78779983 0.78779983 0.78779983\n",
      " 0.78779983 0.78779983 0.78779983        nan 0.78779983 0.78779983\n",
      " 0.78779983 0.78779983 0.78779983 0.78779983 0.78779983 0.78779983\n",
      "        nan 0.7916708  0.7916708  0.7916708  0.7916708  0.7916708\n",
      " 0.7916708  0.7916708  0.7916708         nan 0.7916708  0.7916708\n",
      " 0.7916708  0.7916708  0.7916708  0.7916708  0.7916708  0.7916708\n",
      "        nan 0.7916708  0.7916708  0.7916708  0.7916708  0.7916708\n",
      " 0.7916708  0.7916708  0.7916708         nan 0.7916708  0.7916708\n",
      " 0.7916708  0.7916708  0.7916708  0.7916708  0.7916708  0.7916708\n",
      "        nan 0.86947477 0.86947477 0.86947477 0.86947477 0.86947477\n",
      " 0.86947477 0.86947477 0.86947477        nan 0.86947477 0.86947477\n",
      " 0.86947477 0.86947477 0.86947477 0.86947477 0.86947477 0.86947477\n",
      "        nan 0.86947477 0.86947477 0.86947477 0.86947477 0.86947477\n",
      " 0.86947477 0.86947477 0.86947477        nan 0.86947477 0.86947477\n",
      " 0.86947477 0.86947477 0.86947477 0.86947477 0.86947477 0.86947477\n",
      "        nan 0.87848635 0.87848635 0.87848635 0.87848635 0.87848635\n",
      " 0.87848635 0.87848635 0.87848635        nan 0.87848635 0.87848635\n",
      " 0.87848635 0.87848635 0.87848635 0.87848635 0.87848635 0.87848635\n",
      "        nan 0.87848635 0.87848635 0.87848635 0.87848635 0.87848635\n",
      " 0.87848635 0.87848635 0.87848635        nan 0.87848635 0.87848635\n",
      " 0.87848635 0.87848635 0.87848635 0.87848635 0.87848635 0.87848635\n",
      "        nan 0.91638544 0.91638544 0.91638544 0.91766749 0.91831266\n",
      " 0.91831266 0.91959884 0.91959884        nan 0.91831266 0.91831266\n",
      " 0.91831266 0.91831266 0.91895782 0.91895782 0.91959884 0.91959884\n",
      "        nan 0.91895782 0.91895782 0.91895782 0.91895782 0.91895782\n",
      " 0.91895782 0.91959884 0.91959884        nan 0.91895368 0.91895368\n",
      " 0.91895368 0.91895368 0.91895368 0.91895368 0.91895368 0.91895368\n",
      "        nan 0.93052936 0.93052936 0.92924318 0.93117039 0.93181555\n",
      " 0.93246071 0.93438792 0.93438792        nan 0.93245658 0.93245658\n",
      " 0.93245658 0.93245658 0.93310174 0.9337469  0.93438792 0.93438792\n",
      "        nan 0.9337469  0.9337469  0.9337469  0.9337469  0.9337469\n",
      " 0.9337469  0.93438792 0.93438792        nan 0.93566998 0.93566998\n",
      " 0.93566998 0.93566998 0.93566998 0.93566998 0.93566998 0.93566998\n",
      "        nan 0.95370141 0.95498759 0.94984285 0.95047974 0.94983871\n",
      " 0.94662117 0.94790736 0.94790736        nan 0.95241108 0.95241108\n",
      " 0.95241108 0.95176592 0.9511249  0.94790736 0.94790736 0.94790736\n",
      "        nan 0.94983871 0.94983871 0.94983871 0.94983871 0.94983871\n",
      " 0.94790736 0.94790736 0.94790736        nan 0.9466129  0.9466129\n",
      " 0.9466129  0.9466129  0.9466129  0.9466129  0.9466129  0.9466129\n",
      "        nan 0.96528122 0.96721257 0.96270885 0.96528122 0.96399917\n",
      " 0.95628205 0.95563689 0.95563689        nan 0.96721257 0.96721257\n",
      " 0.96721257 0.96721257 0.96593052 0.9582134  0.95563689 0.95563689\n",
      "        nan 0.96337055 0.96337055 0.96337055 0.96337055 0.96337055\n",
      " 0.96014888 0.95757237 0.95757237        nan 0.95819272 0.95819272\n",
      " 0.95819272 0.95819272 0.95819272 0.95819272 0.95819272 0.95883788\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615        nan 0.78073615 0.78073615\n",
      " 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615 0.78073615\n",
      "        nan 0.78717122 0.78717122 0.78717122 0.78717122 0.78717122\n",
      " 0.78717122 0.78717122 0.78717122        nan 0.78717122 0.78717122\n",
      " 0.78717122 0.78717122 0.78717122 0.78717122 0.78717122 0.78717122\n",
      "        nan 0.78717122 0.78717122 0.78717122 0.78717122 0.78717122\n",
      " 0.78717122 0.78717122 0.78717122        nan 0.78717122 0.78717122\n",
      " 0.78717122 0.78717122 0.78717122 0.78717122 0.78717122 0.78717122\n",
      "        nan 0.79036394 0.79036394 0.79036394 0.79036394 0.79036394\n",
      " 0.79036394 0.79036394 0.79036394        nan 0.79036394 0.79036394\n",
      " 0.79036394 0.79036394 0.79036394 0.79036394 0.79036394 0.79036394\n",
      "        nan 0.79036394 0.79036394 0.79036394 0.79036394 0.79036394\n",
      " 0.79036394 0.79036394 0.79036394        nan 0.79036394 0.79036394\n",
      " 0.79036394 0.79036394 0.79036394 0.79036394 0.79036394 0.79036394\n",
      "        nan 0.85402812 0.85402812 0.85402812 0.85402812 0.85402812\n",
      " 0.85402812 0.85402812 0.85402812        nan 0.85402812 0.85402812\n",
      " 0.85402812 0.85402812 0.85402812 0.85402812 0.85402812 0.85402812\n",
      "        nan 0.85402812 0.85402812 0.85402812 0.85402812 0.85402812\n",
      " 0.85402812 0.85402812 0.85402812        nan 0.85402812 0.85402812\n",
      " 0.85402812 0.85402812 0.85402812 0.85402812 0.85402812 0.85402812\n",
      "        nan 0.86561208 0.86561208 0.86561208 0.86561208 0.86561208\n",
      " 0.86561208 0.86561208 0.86561208        nan 0.86561208 0.86561208\n",
      " 0.86561208 0.86561208 0.86561208 0.86561208 0.86561208 0.86561208\n",
      "        nan 0.86561208 0.86561208 0.86561208 0.86561208 0.86561208\n",
      " 0.86561208 0.86561208 0.86561208        nan 0.86561208 0.86561208\n",
      " 0.86561208 0.86561208 0.86561208 0.86561208 0.86561208 0.86561208\n",
      "        nan 0.92733251 0.92733251 0.92733251 0.92733251 0.92733251\n",
      " 0.92733251 0.92733251 0.92733251        nan 0.92733251 0.92733251\n",
      " 0.92733251 0.92733251 0.92733251 0.92733251 0.92733251 0.92733251\n",
      "        nan 0.92733251 0.92733251 0.92733251 0.92733251 0.92733251\n",
      " 0.92733251 0.92733251 0.92733251        nan 0.92733251 0.92733251\n",
      " 0.92733251 0.92733251 0.92733251 0.92733251 0.92733251 0.92733251\n",
      "        nan 0.93311414 0.93375931 0.93375931 0.93247725 0.93183209\n",
      " 0.93183209 0.93247312 0.93247312        nan 0.93311828 0.93311828\n",
      " 0.93311828 0.93311828 0.93247312 0.93247312 0.93247312 0.93247312\n",
      "        nan 0.9344086  0.9344086  0.9344086  0.9344086  0.9344086\n",
      " 0.9344086  0.9344086  0.9344086         nan 0.93697684 0.93697684\n",
      " 0.93697684 0.93697684 0.93697684 0.93697684 0.93697684 0.93697684\n",
      "        nan 0.95948718 0.96077337 0.95691067 0.95369313 0.95176179\n",
      " 0.95176179 0.95175765 0.95175765        nan 0.95497932 0.95497932\n",
      " 0.95497932 0.953689   0.95175765 0.95175765 0.95175765 0.95175765\n",
      "        nan 0.95304797 0.95304797 0.95304797 0.95304797 0.95304797\n",
      " 0.95304797 0.95304797 0.95304797        nan 0.95497105 0.95497105\n",
      " 0.95497105 0.95497105 0.95497105 0.95497105 0.95497105 0.95497105\n",
      "        nan 0.97171629 0.97300662 0.96786187 0.9652895  0.96143507\n",
      " 0.95885443 0.95691894 0.95627378        nan 0.96722084 0.96722084\n",
      " 0.96722084 0.96593052 0.96143093 0.95885029 0.95691894 0.95627378\n",
      "        nan 0.96078991 0.96078991 0.96078991 0.96078991 0.96078991\n",
      " 0.95949959 0.95756824 0.9582134         nan 0.96012821 0.96012821\n",
      " 0.96012821 0.96012821 0.96012821 0.96012821 0.96012821 0.96141853]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.79163772 0.79163772 0.79163772 0.79163772 0.79163772\n",
      " 0.79163772 0.79163772 0.79163772        nan 0.79163772 0.79163772\n",
      " 0.79163772 0.79163772 0.79163772 0.79163772 0.79163772 0.79163772\n",
      "        nan 0.79163772 0.79163772 0.79163772 0.79163772 0.79163772\n",
      " 0.79163772 0.79163772 0.79163772        nan 0.79163772 0.79163772\n",
      " 0.79163772 0.79163772 0.79163772 0.79163772 0.79163772 0.79163772\n",
      "        nan 0.79999173 0.79999173 0.79999173 0.79999173 0.79999173\n",
      " 0.79999173 0.79999173 0.79999173        nan 0.79999173 0.79999173\n",
      " 0.79999173 0.79999173 0.79999173 0.79999173 0.79999173 0.79999173\n",
      "        nan 0.79999173 0.79999173 0.79999173 0.79999173 0.79999173\n",
      " 0.79999173 0.79999173 0.79999173        nan 0.79999173 0.79999173\n",
      " 0.79999173 0.79999173 0.79999173 0.79999173 0.79999173 0.79999173\n",
      "        nan 0.85916046 0.85916046 0.85916046 0.85916046 0.85916046\n",
      " 0.85916046 0.85916046 0.85916046        nan 0.85916046 0.85916046\n",
      " 0.85916046 0.85916046 0.85916046 0.85916046 0.85916046 0.85916046\n",
      "        nan 0.85916046 0.85916046 0.85916046 0.85916046 0.85916046\n",
      " 0.85916046 0.85916046 0.85916046        nan 0.85916046 0.85916046\n",
      " 0.85916046 0.85916046 0.85916046 0.85916046 0.85916046 0.85916046\n",
      "        nan 0.87652192 0.87652192 0.87652192 0.87652192 0.87652192\n",
      " 0.87652192 0.87652192 0.87652192        nan 0.87652192 0.87652192\n",
      " 0.87652192 0.87652192 0.87652192 0.87652192 0.87652192 0.87652192\n",
      "        nan 0.87652192 0.87652192 0.87652192 0.87652192 0.87652192\n",
      " 0.87652192 0.87652192 0.87652192        nan 0.87652192 0.87652192\n",
      " 0.87652192 0.87652192 0.87652192 0.87652192 0.87652192 0.87652192\n",
      "        nan 0.9080397  0.9080397  0.9080397  0.9080397  0.90868486\n",
      " 0.90868486 0.90868486 0.90868486        nan 0.90868486 0.90868486\n",
      " 0.90868486 0.90868486 0.90868486 0.90868486 0.90868486 0.90868486\n",
      "        nan 0.90868486 0.90868486 0.90868486 0.90868486 0.90868486\n",
      " 0.90868486 0.90868486 0.90868486        nan 0.90933002 0.90933002\n",
      " 0.90933002 0.90933002 0.90933002 0.90933002 0.90933002 0.90933002\n",
      "        nan 0.94210918 0.94210918 0.94146402 0.94210918 0.94275434\n",
      " 0.94275434 0.94275434 0.94275434        nan 0.94275434 0.94275434\n",
      " 0.94275434 0.94275434 0.94275434 0.94275434 0.94275434 0.94275434\n",
      "        nan 0.94210918 0.94210918 0.94210918 0.94210918 0.94210918\n",
      " 0.94210918 0.94275434 0.94275434        nan 0.94468569 0.94468569\n",
      " 0.94468569 0.94468569 0.94468569 0.94468569 0.94468569 0.94468569\n",
      "        nan 0.9498139  0.94917287 0.94659636 0.94530604 0.94530604\n",
      " 0.94531431 0.94466915 0.94466915        nan 0.9466005  0.9466005\n",
      " 0.9466005  0.94466501 0.94466501 0.94531431 0.94466915 0.94466915\n",
      "        nan 0.94595533 0.94595533 0.94595533 0.94595533 0.94595533\n",
      " 0.94531431 0.94595947 0.94595947        nan 0.94854425 0.94854425\n",
      " 0.94854425 0.94854425 0.94854425 0.94854425 0.94854425 0.94854425\n",
      "        nan 0.95624069 0.95495864 0.9491646  0.94979322 0.95236559\n",
      " 0.94915633 0.94787014 0.9485153         nan 0.952378   0.952378\n",
      " 0.952378   0.95172457 0.95301489 0.94980149 0.94787014 0.9485153\n",
      "        nan 0.95173284 0.95173284 0.95173284 0.95173284 0.95173284\n",
      " 0.95044665 0.94980562 0.95045079        nan 0.95110835 0.95110835\n",
      " 0.95110835 0.95110835 0.95110835 0.95110835 0.95110835 0.95110835\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581        nan 0.78133581 0.78133581\n",
      " 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581 0.78133581\n",
      "        nan 0.79548387 0.79548387 0.79548387 0.79548387 0.79548387\n",
      " 0.79548387 0.79548387 0.79548387        nan 0.79548387 0.79548387\n",
      " 0.79548387 0.79548387 0.79548387 0.79548387 0.79548387 0.79548387\n",
      "        nan 0.79548387 0.79548387 0.79548387 0.79548387 0.79548387\n",
      " 0.79548387 0.79548387 0.79548387        nan 0.79548387 0.79548387\n",
      " 0.79548387 0.79548387 0.79548387 0.79548387 0.79548387 0.79548387\n",
      "        nan 0.7916129  0.7916129  0.7916129  0.7916129  0.7916129\n",
      " 0.7916129  0.7916129  0.7916129         nan 0.7916129  0.7916129\n",
      " 0.7916129  0.7916129  0.7916129  0.7916129  0.7916129  0.7916129\n",
      "        nan 0.7916129  0.7916129  0.7916129  0.7916129  0.7916129\n",
      " 0.7916129  0.7916129  0.7916129         nan 0.7916129  0.7916129\n",
      " 0.7916129  0.7916129  0.7916129  0.7916129  0.7916129  0.7916129\n",
      "        nan 0.85337883 0.85337883 0.85337883 0.85337883 0.85337883\n",
      " 0.85337883 0.85337883 0.85337883        nan 0.85337883 0.85337883\n",
      " 0.85337883 0.85337883 0.85337883 0.85337883 0.85337883 0.85337883\n",
      "        nan 0.85337883 0.85337883 0.85337883 0.85337883 0.85337883\n",
      " 0.85337883 0.85337883 0.85337883        nan 0.85337883 0.85337883\n",
      " 0.85337883 0.85337883 0.85337883 0.85337883 0.85337883 0.85337883\n",
      "        nan 0.8688172  0.8688172  0.8688172  0.8688172  0.8688172\n",
      " 0.8688172  0.8688172  0.8688172         nan 0.8688172  0.8688172\n",
      " 0.8688172  0.8688172  0.8688172  0.8688172  0.8688172  0.8688172\n",
      "        nan 0.8688172  0.8688172  0.8688172  0.8688172  0.8688172\n",
      " 0.8688172  0.8688172  0.8688172         nan 0.8688172  0.8688172\n",
      " 0.8688172  0.8688172  0.8688172  0.8688172  0.8688172  0.8688172\n",
      "        nan 0.91383788 0.91383788 0.91383788 0.91383788 0.91383788\n",
      " 0.91383788 0.91383788 0.91383788        nan 0.91383788 0.91383788\n",
      " 0.91383788 0.91383788 0.91383788 0.91383788 0.91383788 0.91383788\n",
      "        nan 0.91383788 0.91383788 0.91383788 0.91383788 0.91383788\n",
      " 0.91383788 0.91383788 0.91383788        nan 0.91383788 0.91383788\n",
      " 0.91383788 0.91383788 0.91383788 0.91383788 0.91383788 0.91383788\n",
      "        nan 0.9395244  0.9395244  0.9395244  0.93887924 0.93887924\n",
      " 0.93887924 0.93887924 0.93887924        nan 0.9395244  0.9395244\n",
      " 0.9395244  0.93887924 0.93887924 0.93887924 0.93887924 0.93887924\n",
      "        nan 0.93887924 0.93887924 0.93887924 0.93887924 0.93887924\n",
      " 0.93887924 0.93887924 0.93887924        nan 0.93824235 0.93824235\n",
      " 0.93824235 0.93824235 0.93824235 0.93824235 0.93824235 0.93824235\n",
      "        nan 0.95946237 0.95818031 0.95753515 0.95559967 0.95495451\n",
      " 0.95366419 0.95366419 0.95494624        nan 0.95624483 0.95624483\n",
      " 0.95624483 0.95495451 0.95495451 0.95366419 0.95366419 0.95494624\n",
      "        nan 0.95495451 0.95495451 0.95495451 0.95495451 0.95495451\n",
      " 0.95495451 0.95495451 0.95623656        nan 0.95303143 0.95303143\n",
      " 0.95303143 0.95303143 0.95303143 0.95303143 0.95303143 0.95303143\n",
      "        nan 0.96396195 0.96332093 0.96011166 0.95944996 0.96009512\n",
      " 0.95686931 0.95428867 0.95557072        nan 0.96010339 0.96010339\n",
      " 0.96010339 0.96073201 0.96073615 0.95686931 0.95428867 0.95557072\n",
      "        nan 0.95816791 0.95816791 0.95816791 0.95816791 0.95816791\n",
      " 0.95752275 0.9549421  0.95622415        nan 0.95622829 0.95622829\n",
      " 0.95622829 0.95622829 0.95622829 0.95622829 0.95622829 0.95622829]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n",
      " 0.79166667 0.79166667 0.79166667        nan 0.79166667 0.79166667\n",
      " 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n",
      "        nan 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n",
      " 0.79166667 0.79166667 0.79166667        nan 0.79166667 0.79166667\n",
      " 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n",
      "        nan 0.79550455 0.79550455 0.79550455 0.79550455 0.79550455\n",
      " 0.79550455 0.79550455 0.79550455        nan 0.79550455 0.79550455\n",
      " 0.79550455 0.79550455 0.79550455 0.79550455 0.79550455 0.79550455\n",
      "        nan 0.79550455 0.79550455 0.79550455 0.79550455 0.79550455\n",
      " 0.79550455 0.79550455 0.79550455        nan 0.79550455 0.79550455\n",
      " 0.79550455 0.79550455 0.79550455 0.79550455 0.79550455 0.79550455\n",
      "        nan 0.84311414 0.84311414 0.84311414 0.84311414 0.84311414\n",
      " 0.84311414 0.84311414 0.84311414        nan 0.84311414 0.84311414\n",
      " 0.84311414 0.84311414 0.84311414 0.84311414 0.84311414 0.84311414\n",
      "        nan 0.84311414 0.84311414 0.84311414 0.84311414 0.84311414\n",
      " 0.84311414 0.84311414 0.84311414        nan 0.84311414 0.84311414\n",
      " 0.84311414 0.84311414 0.84311414 0.84311414 0.84311414 0.84311414\n",
      "        nan 0.86241108 0.86241108 0.86241108 0.86241108 0.86241108\n",
      " 0.86241108 0.86241108 0.86241108        nan 0.86241108 0.86241108\n",
      " 0.86241108 0.86241108 0.86241108 0.86241108 0.86241108 0.86241108\n",
      "        nan 0.86241108 0.86241108 0.86241108 0.86241108 0.86241108\n",
      " 0.86241108 0.86241108 0.86241108        nan 0.86241108 0.86241108\n",
      " 0.86241108 0.86241108 0.86241108 0.86241108 0.86241108 0.86241108\n",
      "        nan 0.91383375 0.91383375 0.91383375 0.91383375 0.91383375\n",
      " 0.91383375 0.91383375 0.91383375        nan 0.91383375 0.91383375\n",
      " 0.91383375 0.91383375 0.91383375 0.91383375 0.91383375 0.91383375\n",
      "        nan 0.91383375 0.91383375 0.91383375 0.91383375 0.91383375\n",
      " 0.91383375 0.91383375 0.91383375        nan 0.91383375 0.91383375\n",
      " 0.91383375 0.91383375 0.91383375 0.91383375 0.91383375 0.91383375\n",
      "        nan 0.94020678 0.94020678 0.94020678 0.94085194 0.942134\n",
      " 0.942134   0.94277916 0.94277916        nan 0.94149297 0.94149297\n",
      " 0.94149297 0.94149297 0.942134   0.942134   0.94277916 0.94277916\n",
      "        nan 0.942134   0.942134   0.942134   0.942134   0.942134\n",
      " 0.942134   0.94277916 0.94277916        nan 0.94276675 0.94276675\n",
      " 0.94276675 0.94276675 0.94276675 0.94276675 0.94276675 0.94276675\n",
      "        nan 0.94918528 0.95111663 0.94533085 0.94533085 0.94532672\n",
      " 0.94468156 0.9433995  0.9433995         nan 0.94597188 0.94597188\n",
      " 0.94597188 0.94532672 0.94532672 0.94468156 0.9433995  0.9433995\n",
      "        nan 0.94532672 0.94532672 0.94532672 0.94532672 0.94532672\n",
      " 0.94532672 0.94404467 0.94404467        nan 0.94274607 0.94274607\n",
      " 0.94274607 0.94274607 0.94274607 0.94274607 0.94274607 0.94274607\n",
      "        nan 0.96397849 0.96655087 0.95818859 0.95947891 0.95947891\n",
      " 0.95754756 0.95112076 0.95240281        nan 0.95947064 0.95947064\n",
      " 0.95947064 0.9601158  0.96011993 0.95882961 0.95240281 0.95240281\n",
      "        nan 0.95689413 0.95689413 0.95689413 0.95689413 0.95689413\n",
      " 0.95818445 0.95304797 0.95304797        nan 0.95175352 0.95175352\n",
      " 0.95175352 0.95175352 0.95175352 0.95175352 0.95175352 0.95175352\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896        nan 0.77813896 0.77813896\n",
      " 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896 0.77813896\n",
      "        nan 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922        nan 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      "        nan 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922        nan 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      "        nan 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922        nan 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      "        nan 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922        nan 0.78265922 0.78265922\n",
      " 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922 0.78265922\n",
      "        nan 0.85015715 0.85015715 0.85015715 0.85015715 0.85015715\n",
      " 0.85015715 0.85015715 0.85015715        nan 0.85015715 0.85015715\n",
      " 0.85015715 0.85015715 0.85015715 0.85015715 0.85015715 0.85015715\n",
      "        nan 0.85015715 0.85015715 0.85015715 0.85015715 0.85015715\n",
      " 0.85015715 0.85015715 0.85015715        nan 0.85015715 0.85015715\n",
      " 0.85015715 0.85015715 0.85015715 0.85015715 0.85015715 0.85015715\n",
      "        nan 0.86365178 0.86365178 0.86365178 0.86365178 0.86365178\n",
      " 0.86365178 0.86365178 0.86365178        nan 0.86365178 0.86365178\n",
      " 0.86365178 0.86365178 0.86365178 0.86365178 0.86365178 0.86365178\n",
      "        nan 0.86365178 0.86365178 0.86365178 0.86365178 0.86365178\n",
      " 0.86365178 0.86365178 0.86365178        nan 0.86365178 0.86365178\n",
      " 0.86365178 0.86365178 0.86365178 0.86365178 0.86365178 0.86365178\n",
      "        nan 0.91765922 0.91765922 0.91765922 0.91765922 0.91765922\n",
      " 0.91765922 0.91765922 0.91765922        nan 0.91765922 0.91765922\n",
      " 0.91765922 0.91765922 0.91765922 0.91765922 0.91765922 0.91765922\n",
      "        nan 0.91765922 0.91765922 0.91765922 0.91765922 0.91765922\n",
      " 0.91765922 0.91765922 0.91765922        nan 0.91765922 0.91765922\n",
      " 0.91765922 0.91765922 0.91765922 0.91765922 0.91765922 0.91765922\n",
      "        nan 0.94339123 0.94339123 0.94339123 0.94339123 0.94145988\n",
      " 0.94145988 0.94210505 0.94210505        nan 0.94403226 0.94403226\n",
      " 0.94403226 0.94403226 0.94145988 0.94145988 0.94210505 0.94210505\n",
      "        nan 0.94145988 0.94145988 0.94145988 0.94145988 0.94145988\n",
      " 0.94145988 0.94210505 0.94210505        nan 0.94274194 0.94274194\n",
      " 0.94274194 0.94274194 0.94274194 0.94274194 0.94274194 0.94274194\n",
      "        nan 0.95880893 0.96074442 0.95688586 0.95624069 0.95495451\n",
      " 0.95431348 0.9556038  0.9556038         nan 0.95752688 0.95752688\n",
      " 0.95752688 0.95752275 0.95431348 0.95431348 0.9556038  0.9556038\n",
      "        nan 0.95173697 0.95173697 0.95173697 0.95173697 0.95173697\n",
      " 0.95173697 0.95238213 0.95238213        nan 0.95301902 0.95301902\n",
      " 0.95301902 0.95301902 0.95301902 0.95301902 0.95301902 0.95301902\n",
      "        nan 0.97233251 0.97233251 0.96782878 0.96911911 0.96590571\n",
      " 0.96396609 0.96203474 0.96332506        nan 0.97040943 0.97040943\n",
      " 0.97040943 0.97040529 0.96719189 0.96525641 0.96397022 0.96397022\n",
      "        nan 0.96267577 0.96267577 0.96267577 0.96267577 0.96267577\n",
      " 0.96267577 0.96203474 0.96203474        nan 0.96074442 0.96074442\n",
      " 0.96074442 0.96074442 0.96074442 0.96074442 0.96074442 0.96074442]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593        nan 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      "        nan 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593        nan 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      "        nan 0.80452026 0.80452026 0.80452026 0.80452026 0.80452026\n",
      " 0.80452026 0.80452026 0.80452026        nan 0.80452026 0.80452026\n",
      " 0.80452026 0.80452026 0.80452026 0.80452026 0.80452026 0.80452026\n",
      "        nan 0.80452026 0.80452026 0.80452026 0.80452026 0.80452026\n",
      " 0.80452026 0.80452026 0.80452026        nan 0.80452026 0.80452026\n",
      " 0.80452026 0.80452026 0.80452026 0.80452026 0.80452026 0.80452026\n",
      "        nan 0.86111249 0.86111249 0.86111249 0.86111249 0.86111249\n",
      " 0.86111249 0.86111249 0.86111249        nan 0.86111249 0.86111249\n",
      " 0.86111249 0.86111249 0.86111249 0.86111249 0.86111249 0.86111249\n",
      "        nan 0.86111249 0.86111249 0.86111249 0.86111249 0.86111249\n",
      " 0.86111249 0.86111249 0.86111249        nan 0.86111249 0.86111249\n",
      " 0.86111249 0.86111249 0.86111249 0.86111249 0.86111249 0.86111249\n",
      "        nan 0.878445   0.878445   0.878445   0.878445   0.878445\n",
      " 0.878445   0.878445   0.878445          nan 0.878445   0.878445\n",
      " 0.878445   0.878445   0.878445   0.878445   0.878445   0.878445\n",
      "        nan 0.878445   0.878445   0.878445   0.878445   0.878445\n",
      " 0.878445   0.878445   0.878445          nan 0.878445   0.878445\n",
      " 0.878445   0.878445   0.878445   0.878445   0.878445   0.878445\n",
      "        nan 0.91188586 0.91188586 0.91188586 0.91188586 0.91188586\n",
      " 0.91188586 0.91188586 0.91188586        nan 0.91188586 0.91188586\n",
      " 0.91188586 0.91188586 0.91188586 0.91188586 0.91188586 0.91188586\n",
      "        nan 0.91188586 0.91188586 0.91188586 0.91188586 0.91188586\n",
      " 0.91188586 0.91188586 0.91188586        nan 0.91188586 0.91188586\n",
      " 0.91188586 0.91188586 0.91188586 0.91188586 0.91188586 0.91188586\n",
      "        nan 0.92604218 0.92604218 0.92604218 0.92668321 0.92732423\n",
      " 0.92732423 0.92732423 0.92732423        nan 0.92732423 0.92732423\n",
      " 0.92732423 0.92732423 0.92732423 0.92732423 0.92732423 0.92732423\n",
      "        nan 0.92732423 0.92732423 0.92732423 0.92732423 0.92732423\n",
      " 0.92732423 0.92732423 0.92732423        nan 0.92860215 0.92860215\n",
      " 0.92860215 0.92860215 0.92860215 0.92860215 0.92860215 0.92860215\n",
      "        nan 0.94404467 0.94340364 0.94083127 0.93955335 0.93889992\n",
      " 0.93889992 0.93889992 0.93825062        nan 0.9401861  0.9401861\n",
      " 0.9401861  0.93954921 0.93889992 0.93889992 0.93889992 0.93825062\n",
      "        nan 0.93760959 0.93760959 0.93760959 0.93760959 0.93760959\n",
      " 0.93760959 0.93760959 0.9369603         nan 0.93695203 0.93695203\n",
      " 0.93695203 0.93695203 0.93695203 0.93695203 0.93695203 0.9356617\n",
      "        nan 0.96014888 0.96272539 0.95949959 0.9575641  0.95562862\n",
      " 0.95563275 0.95242349 0.9511373         nan 0.95820099 0.95820099\n",
      " 0.95820099 0.95820099 0.95498346 0.95563275 0.95242349 0.9511373\n",
      "        nan 0.95240695 0.95240695 0.95240695 0.95240695 0.95240695\n",
      " 0.95305624 0.95177419 0.94920596        nan 0.94983044 0.94983044\n",
      " 0.94983044 0.94983044 0.94983044 0.94983044 0.94983044 0.94983044\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421        nan 0.77299421 0.77299421\n",
      " 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421 0.77299421\n",
      "        nan 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593        nan 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      "        nan 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593        nan 0.79487593 0.79487593\n",
      " 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593 0.79487593\n",
      "        nan 0.79037221 0.79037221 0.79037221 0.79037221 0.79037221\n",
      " 0.79037221 0.79037221 0.79037221        nan 0.79037221 0.79037221\n",
      " 0.79037221 0.79037221 0.79037221 0.79037221 0.79037221 0.79037221\n",
      "        nan 0.79037221 0.79037221 0.79037221 0.79037221 0.79037221\n",
      " 0.79037221 0.79037221 0.79037221        nan 0.79037221 0.79037221\n",
      " 0.79037221 0.79037221 0.79037221 0.79037221 0.79037221 0.79037221\n",
      "        nan 0.85724979 0.85724979 0.85724979 0.85724979 0.85724979\n",
      " 0.85724979 0.85724979 0.85724979        nan 0.85724979 0.85724979\n",
      " 0.85724979 0.85724979 0.85724979 0.85724979 0.85724979 0.85724979\n",
      "        nan 0.85724979 0.85724979 0.85724979 0.85724979 0.85724979\n",
      " 0.85724979 0.85724979 0.85724979        nan 0.85724979 0.85724979\n",
      " 0.85724979 0.85724979 0.85724979 0.85724979 0.85724979 0.85724979\n",
      "        nan 0.86626137 0.86626137 0.86626137 0.86626137 0.86626137\n",
      " 0.86626137 0.86626137 0.86626137        nan 0.86626137 0.86626137\n",
      " 0.86626137 0.86626137 0.86626137 0.86626137 0.86626137 0.86626137\n",
      "        nan 0.86626137 0.86626137 0.86626137 0.86626137 0.86626137\n",
      " 0.86626137 0.86626137 0.86626137        nan 0.86626137 0.86626137\n",
      " 0.86626137 0.86626137 0.86626137 0.86626137 0.86626137 0.86626137\n",
      "        nan 0.92090984 0.92090984 0.92090984 0.92090984 0.92090984\n",
      " 0.92090984 0.92090984 0.92090984        nan 0.92090984 0.92090984\n",
      " 0.92090984 0.92090984 0.92090984 0.92090984 0.92090984 0.92090984\n",
      "        nan 0.92090984 0.92090984 0.92090984 0.92090984 0.92090984\n",
      " 0.92090984 0.92090984 0.92090984        nan 0.92090984 0.92090984\n",
      " 0.92090984 0.92090984 0.92090984 0.92090984 0.92090984 0.92090984\n",
      "        nan 0.93504136 0.93504136 0.93504136 0.93504136 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033        nan 0.93504136 0.93504136\n",
      " 0.93504136 0.93504136 0.93440033 0.93440033 0.93440033 0.93440033\n",
      "        nan 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033        nan 0.93440033 0.93440033\n",
      " 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033 0.93440033\n",
      "        nan 0.95435897 0.95435484 0.95306452 0.95178246 0.95114144\n",
      " 0.95049628 0.95049628 0.95049628        nan 0.95178246 0.95178246\n",
      " 0.95178246 0.95178246 0.95114144 0.95049628 0.95049628 0.95049628\n",
      "        nan 0.9511373  0.9511373  0.9511373  0.9511373  0.9511373\n",
      " 0.9511373  0.9511373  0.9511373         nan 0.94662117 0.94662117\n",
      " 0.94662117 0.94662117 0.94662117 0.94662117 0.94662117 0.94662117\n",
      "        nan 0.96594293 0.9653019  0.96208437 0.96209264 0.95952854\n",
      " 0.95695203 0.956311   0.956311          nan 0.96080232 0.96080232\n",
      " 0.96080232 0.96209264 0.95952854 0.95695203 0.956311   0.956311\n",
      "        nan 0.96080645 0.96080645 0.96080645 0.96080645 0.96080645\n",
      " 0.9588751  0.95823408 0.95823408        nan 0.95694376 0.95694376\n",
      " 0.95694376 0.95694376 0.95694376 0.95694376 0.95694376 0.95694376]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.79807692 0.79807692 0.79807692 0.79807692 0.79807692\n",
      " 0.79807692 0.79807692 0.79807692        nan 0.79807692 0.79807692\n",
      " 0.79807692 0.79807692 0.79807692 0.79807692 0.79807692 0.79807692\n",
      "        nan 0.79807692 0.79807692 0.79807692 0.79807692 0.79807692\n",
      " 0.79807692 0.79807692 0.79807692        nan 0.79807692 0.79807692\n",
      " 0.79807692 0.79807692 0.79807692 0.79807692 0.79807692 0.79807692\n",
      "        nan 0.7948842  0.7948842  0.7948842  0.7948842  0.7948842\n",
      " 0.7948842  0.7948842  0.7948842         nan 0.7948842  0.7948842\n",
      " 0.7948842  0.7948842  0.7948842  0.7948842  0.7948842  0.7948842\n",
      "        nan 0.7948842  0.7948842  0.7948842  0.7948842  0.7948842\n",
      " 0.7948842  0.7948842  0.7948842         nan 0.7948842  0.7948842\n",
      " 0.7948842  0.7948842  0.7948842  0.7948842  0.7948842  0.7948842\n",
      "        nan 0.86108768 0.86108768 0.86108768 0.86108768 0.86108768\n",
      " 0.86108768 0.86108768 0.86108768        nan 0.86108768 0.86108768\n",
      " 0.86108768 0.86108768 0.86108768 0.86108768 0.86108768 0.86108768\n",
      "        nan 0.86108768 0.86108768 0.86108768 0.86108768 0.86108768\n",
      " 0.86108768 0.86108768 0.86108768        nan 0.86108768 0.86108768\n",
      " 0.86108768 0.86108768 0.86108768 0.86108768 0.86108768 0.86108768\n",
      "        nan 0.88619107 0.88619107 0.88619107 0.88619107 0.88619107\n",
      " 0.88619107 0.88619107 0.88619107        nan 0.88619107 0.88619107\n",
      " 0.88619107 0.88619107 0.88619107 0.88619107 0.88619107 0.88619107\n",
      "        nan 0.88619107 0.88619107 0.88619107 0.88619107 0.88619107\n",
      " 0.88619107 0.88619107 0.88619107        nan 0.88619107 0.88619107\n",
      " 0.88619107 0.88619107 0.88619107 0.88619107 0.88619107 0.88619107\n",
      "        nan 0.92090571 0.92090571 0.92090571 0.92090571 0.92090571\n",
      " 0.92155087 0.92155087 0.92155087        nan 0.92155087 0.92155087\n",
      " 0.92155087 0.92155087 0.92155087 0.92155087 0.92155087 0.92155087\n",
      "        nan 0.92155087 0.92155087 0.92155087 0.92155087 0.92155087\n",
      " 0.92155087 0.92155087 0.92155087        nan 0.92155087 0.92155087\n",
      " 0.92155087 0.92155087 0.92155087 0.92155087 0.92155087 0.92155087\n",
      "        nan 0.94919768 0.94855666 0.94855666 0.95049214 0.94856493\n",
      " 0.94921009 0.94792804 0.94792804        nan 0.95113317 0.95113317\n",
      " 0.95113317 0.95177833 0.94985112 0.94985112 0.94856907 0.94856907\n",
      "        nan 0.94985112 0.94985112 0.94985112 0.94985112 0.94985112\n",
      " 0.94985112 0.94856907 0.94856907        nan 0.94921009 0.94921009\n",
      " 0.94921009 0.94921009 0.94921009 0.94921009 0.94921009 0.94921009\n",
      "        nan 0.95048387 0.95176592 0.95047974 0.95048387 0.9479115\n",
      " 0.94856493 0.94728288 0.94663772        nan 0.95048387 0.95048387\n",
      " 0.95048387 0.95241522 0.94984285 0.94920596 0.9479239  0.94727874\n",
      "        nan 0.94791563 0.94791563 0.94791563 0.94791563 0.94791563\n",
      " 0.94727047 0.94663358 0.94598842        nan 0.94662945 0.94662945\n",
      " 0.94662945 0.94662945 0.94662945 0.94662945 0.94662945 0.94598428\n",
      "        nan 0.95884202 0.95820513 0.95499173 0.95499586 0.95307279\n",
      " 0.95242349 0.95242763 0.94921423        nan 0.95756824 0.95756824\n",
      " 0.95756824 0.9582134  0.955      0.95306452 0.95306865 0.94985525\n",
      "        nan 0.95242763 0.95242763 0.95242763 0.95242763 0.95242763\n",
      " 0.9511373  0.95178246 0.94856907        nan 0.9511373  0.9511373\n",
      " 0.9511373  0.9511373  0.9511373  0.9511373  0.9511373  0.94921009\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837        nan 0.77232837 0.77232837\n",
      " 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837 0.77232837\n",
      "        nan 0.77814723 0.77814723 0.77814723 0.77814723 0.77814723\n",
      " 0.77814723 0.77814723 0.77814723        nan 0.77814723 0.77814723\n",
      " 0.77814723 0.77814723 0.77814723 0.77814723 0.77814723 0.77814723\n",
      "        nan 0.77814723 0.77814723 0.77814723 0.77814723 0.77814723\n",
      " 0.77814723 0.77814723 0.77814723        nan 0.77814723 0.77814723\n",
      " 0.77814723 0.77814723 0.77814723 0.77814723 0.77814723 0.77814723\n",
      "        nan 0.78520265 0.78520265 0.78520265 0.78520265 0.78520265\n",
      " 0.78520265 0.78520265 0.78520265        nan 0.78520265 0.78520265\n",
      " 0.78520265 0.78520265 0.78520265 0.78520265 0.78520265 0.78520265\n",
      "        nan 0.78520265 0.78520265 0.78520265 0.78520265 0.78520265\n",
      " 0.78520265 0.78520265 0.78520265        nan 0.78520265 0.78520265\n",
      " 0.78520265 0.78520265 0.78520265 0.78520265 0.78520265 0.78520265\n",
      "        nan 0.85270471 0.85270471 0.85270471 0.85270471 0.85270471\n",
      " 0.85270471 0.85270471 0.85270471        nan 0.85270471 0.85270471\n",
      " 0.85270471 0.85270471 0.85270471 0.85270471 0.85270471 0.85270471\n",
      "        nan 0.85270471 0.85270471 0.85270471 0.85270471 0.85270471\n",
      " 0.85270471 0.85270471 0.85270471        nan 0.85270471 0.85270471\n",
      " 0.85270471 0.85270471 0.85270471 0.85270471 0.85270471 0.85270471\n",
      "        nan 0.87781638 0.87781638 0.87781638 0.87781638 0.87781638\n",
      " 0.87781638 0.87781638 0.87781638        nan 0.87781638 0.87781638\n",
      " 0.87781638 0.87781638 0.87781638 0.87781638 0.87781638 0.87781638\n",
      "        nan 0.87781638 0.87781638 0.87781638 0.87781638 0.87781638\n",
      " 0.87781638 0.87781638 0.87781638        nan 0.87781638 0.87781638\n",
      " 0.87781638 0.87781638 0.87781638 0.87781638 0.87781638 0.87781638\n",
      "        nan 0.91705128 0.91705128 0.91705128 0.91705128 0.91705128\n",
      " 0.91705128 0.91705128 0.91705128        nan 0.91705128 0.91705128\n",
      " 0.91705128 0.91705128 0.91705128 0.91705128 0.91705128 0.91705128\n",
      "        nan 0.91705128 0.91705128 0.91705128 0.91705128 0.91705128\n",
      " 0.91705128 0.91705128 0.91705128        nan 0.91705128 0.91705128\n",
      " 0.91705128 0.91705128 0.91705128 0.91705128 0.91705128 0.91705128\n",
      "        nan 0.93633581 0.93633581 0.93633581 0.93633581 0.93698098\n",
      " 0.93698098 0.93698098 0.93698098        nan 0.93633995 0.93633995\n",
      " 0.93633995 0.93633995 0.93633995 0.93633995 0.93633995 0.93633995\n",
      "        nan 0.93633995 0.93633995 0.93633995 0.93633995 0.93633995\n",
      " 0.93633995 0.93633995 0.93633995        nan 0.93762614 0.93762614\n",
      " 0.93762614 0.93762614 0.93762614 0.93762614 0.93762614 0.93762614\n",
      "        nan 0.95563275 0.95563275 0.95434657 0.95370554 0.95370554\n",
      " 0.95370141 0.95177833 0.95177833        nan 0.94984698 0.94984698\n",
      " 0.94984698 0.95113317 0.94984698 0.94984285 0.94856079 0.94856079\n",
      "        nan 0.94856079 0.94856079 0.94856079 0.94856079 0.94856079\n",
      " 0.9479115  0.94727047 0.94727047        nan 0.94597601 0.94597601\n",
      " 0.94597601 0.94597601 0.94597601 0.94597601 0.94597601 0.94597601\n",
      "        nan 0.97041356 0.97041356 0.9672043  0.96656328 0.9672043\n",
      " 0.96269644 0.95948718 0.95820513        nan 0.96205955 0.96205955\n",
      " 0.96205955 0.96463606 0.9639909  0.96012821 0.95626964 0.95498759\n",
      "        nan 0.95884615 0.95884615 0.95884615 0.95884615 0.95884615\n",
      " 0.9575517  0.95562448 0.95434243        nan 0.95691067 0.95691067\n",
      " 0.95691067 0.95691067 0.95691067 0.95691067 0.95691067 0.95562862]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.80901985 0.80901985 0.80901985 0.80901985 0.80901985\n",
      " 0.80901985 0.80901985 0.80901985        nan 0.80901985 0.80901985\n",
      " 0.80901985 0.80901985 0.80901985 0.80901985 0.80901985 0.80901985\n",
      "        nan 0.80901985 0.80901985 0.80901985 0.80901985 0.80901985\n",
      " 0.80901985 0.80901985 0.80901985        nan 0.80901985 0.80901985\n",
      " 0.80901985 0.80901985 0.80901985 0.80901985 0.80901985 0.80901985\n",
      "        nan 0.80708437 0.80708437 0.80708437 0.80708437 0.80708437\n",
      " 0.80708437 0.80708437 0.80708437        nan 0.80708437 0.80708437\n",
      " 0.80708437 0.80708437 0.80708437 0.80708437 0.80708437 0.80708437\n",
      "        nan 0.80708437 0.80708437 0.80708437 0.80708437 0.80708437\n",
      " 0.80708437 0.80708437 0.80708437        nan 0.80708437 0.80708437\n",
      " 0.80708437 0.80708437 0.80708437 0.80708437 0.80708437 0.80708437\n",
      "        nan 0.84500827 0.84500827 0.84500827 0.84500827 0.84500827\n",
      " 0.84500827 0.84500827 0.84500827        nan 0.84500827 0.84500827\n",
      " 0.84500827 0.84500827 0.84500827 0.84500827 0.84500827 0.84500827\n",
      "        nan 0.84500827 0.84500827 0.84500827 0.84500827 0.84500827\n",
      " 0.84500827 0.84500827 0.84500827        nan 0.84500827 0.84500827\n",
      " 0.84500827 0.84500827 0.84500827 0.84500827 0.84500827 0.84500827\n",
      "        nan 0.88875103 0.88875103 0.88875103 0.88875103 0.88875103\n",
      " 0.88875103 0.88875103 0.88875103        nan 0.88875103 0.88875103\n",
      " 0.88875103 0.88875103 0.88875103 0.88875103 0.88875103 0.88875103\n",
      "        nan 0.88875103 0.88875103 0.88875103 0.88875103 0.88875103\n",
      " 0.88875103 0.88875103 0.88875103        nan 0.88875103 0.88875103\n",
      " 0.88875103 0.88875103 0.88875103 0.88875103 0.88875103 0.88875103\n",
      "        nan 0.92346154 0.92346154 0.92346154 0.92410256 0.92410256\n",
      " 0.92410256 0.92474359 0.92474359        nan 0.92410256 0.92410256\n",
      " 0.92410256 0.92410256 0.92410256 0.92410256 0.92474359 0.92474359\n",
      "        nan 0.92410256 0.92410256 0.92410256 0.92410256 0.92410256\n",
      " 0.92410256 0.92474359 0.92474359        nan 0.92474359 0.92474359\n",
      " 0.92474359 0.92474359 0.92474359 0.92474359 0.92474359 0.92474359\n",
      "        nan 0.94791977 0.94920596 0.94856493 0.94920596 0.94920596\n",
      " 0.95049214 0.95113317 0.95113317        nan 0.94984698 0.94984698\n",
      " 0.94984698 0.94984698 0.94984698 0.94984698 0.95113317 0.95113317\n",
      "        nan 0.95048801 0.95048801 0.95048801 0.95048801 0.95048801\n",
      " 0.95048801 0.95177419 0.95177419        nan 0.95305624 0.95305624\n",
      " 0.95305624 0.95305624 0.95305624 0.95305624 0.95305624 0.95305624\n",
      "        nan 0.9498263  0.95047146 0.94725806 0.94468569 0.94533085\n",
      " 0.94597188 0.9466129  0.94725393        nan 0.94660877 0.94660877\n",
      " 0.94660877 0.94532672 0.94597188 0.94597188 0.94725806 0.94789909\n",
      "        nan 0.94468156 0.94468156 0.94468156 0.94468156 0.94468156\n",
      " 0.94532258 0.94660877 0.94724979        nan 0.94724152 0.94724152\n",
      " 0.94724152 0.94724152 0.94724152 0.94724152 0.94724152 0.94788255\n",
      "        nan 0.96205542 0.96720017 0.96012821 0.95562448 0.95626964\n",
      " 0.95818859 0.95947477 0.95882961        nan 0.95754342 0.95754342\n",
      " 0.95754342 0.95561621 0.95626137 0.95818859 0.96011993 0.95947477\n",
      "        nan 0.9569024  0.9569024  0.9569024  0.9569024  0.9569024\n",
      " 0.95882961 0.96076096 0.9601158         nan 0.96268404 0.96268404\n",
      " 0.96268404 0.96268404 0.96268404 0.96268404 0.96268404 0.9626799\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672 0.70032672\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687        nan 0.77941687 0.77941687\n",
      " 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687 0.77941687\n",
      "        nan 0.79998759 0.79998759 0.79998759 0.79998759 0.79998759\n",
      " 0.79998759 0.79998759 0.79998759        nan 0.79998759 0.79998759\n",
      " 0.79998759 0.79998759 0.79998759 0.79998759 0.79998759 0.79998759\n",
      "        nan 0.79998759 0.79998759 0.79998759 0.79998759 0.79998759\n",
      " 0.79998759 0.79998759 0.79998759        nan 0.79998759 0.79998759\n",
      " 0.79998759 0.79998759 0.79998759 0.79998759 0.79998759 0.79998759\n",
      "        nan 0.80001241 0.80001241 0.80001241 0.80001241 0.80001241\n",
      " 0.80001241 0.80001241 0.80001241        nan 0.80001241 0.80001241\n",
      " 0.80001241 0.80001241 0.80001241 0.80001241 0.80001241 0.80001241\n",
      "        nan 0.80001241 0.80001241 0.80001241 0.80001241 0.80001241\n",
      " 0.80001241 0.80001241 0.80001241        nan 0.80001241 0.80001241\n",
      " 0.80001241 0.80001241 0.80001241 0.80001241 0.80001241 0.80001241\n",
      "        nan 0.85145988 0.85145988 0.85145988 0.85145988 0.85145988\n",
      " 0.85145988 0.85145988 0.85145988        nan 0.85145988 0.85145988\n",
      " 0.85145988 0.85145988 0.85145988 0.85145988 0.85145988 0.85145988\n",
      "        nan 0.85145988 0.85145988 0.85145988 0.85145988 0.85145988\n",
      " 0.85145988 0.85145988 0.85145988        nan 0.85145988 0.85145988\n",
      " 0.85145988 0.85145988 0.85145988 0.85145988 0.85145988 0.85145988\n",
      "        nan 0.8675062  0.8675062  0.8675062  0.8675062  0.8675062\n",
      " 0.8675062  0.8675062  0.8675062         nan 0.8675062  0.8675062\n",
      " 0.8675062  0.8675062  0.8675062  0.8675062  0.8675062  0.8675062\n",
      "        nan 0.8675062  0.8675062  0.8675062  0.8675062  0.8675062\n",
      " 0.8675062  0.8675062  0.8675062         nan 0.8675062  0.8675062\n",
      " 0.8675062  0.8675062  0.8675062  0.8675062  0.8675062  0.8675062\n",
      "        nan 0.92027709 0.92027709 0.92027709 0.92027709 0.92027709\n",
      " 0.92027709 0.92027709 0.92027709        nan 0.92027709 0.92027709\n",
      " 0.92027709 0.92027709 0.92027709 0.92027709 0.92027709 0.92027709\n",
      "        nan 0.92027709 0.92027709 0.92027709 0.92027709 0.92027709\n",
      " 0.92027709 0.92027709 0.92027709        nan 0.92027709 0.92027709\n",
      " 0.92027709 0.92027709 0.92027709 0.92027709 0.92027709 0.92027709\n",
      "        nan 0.9479115  0.9479115  0.9479115  0.94598015 0.94533499\n",
      " 0.94597601 0.94597601 0.94597601        nan 0.9472622  0.9472622\n",
      " 0.9472622  0.94662117 0.94597601 0.94597601 0.94597601 0.94597601\n",
      "        nan 0.94661704 0.94661704 0.94661704 0.94661704 0.94661704\n",
      " 0.94661704 0.94661704 0.94661704        nan 0.94725806 0.94725806\n",
      " 0.94725806 0.94725806 0.94725806 0.94725806 0.94725806 0.94725806\n",
      "        nan 0.96078577 0.95949545 0.95885443 0.95499173 0.95370141\n",
      " 0.95562862 0.95562862 0.95370554        nan 0.95691481 0.95691481\n",
      " 0.95691481 0.95691894 0.95562862 0.95562862 0.95562862 0.95370554\n",
      "        nan 0.95176592 0.95176592 0.95176592 0.95176592 0.95176592\n",
      " 0.95176592 0.95241108 0.95241108        nan 0.9504756  0.9504756\n",
      " 0.9504756  0.9504756  0.9504756  0.9504756  0.9504756  0.9504756\n",
      "        nan 0.96528536 0.96655914 0.96335401 0.95691481 0.95691067\n",
      " 0.95883375 0.95819272 0.95819272        nan 0.96077337 0.96077337\n",
      " 0.96077337 0.95819686 0.9575517  0.95883375 0.95819272 0.95819272\n",
      "        nan 0.95690653 0.95690653 0.95690653 0.95690653 0.95690653\n",
      " 0.95690653 0.95691067 0.95691067        nan 0.95497105 0.95497105\n",
      " 0.95497105 0.95497105 0.95497105 0.95497105 0.95497105 0.95625724]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.79628205 0.79628205 0.79628205 0.79628205 0.79628205\n",
      " 0.79628205 0.79628205 0.79628205        nan 0.79628205 0.79628205\n",
      " 0.79628205 0.79628205 0.79628205 0.79628205 0.79628205 0.79628205\n",
      "        nan 0.79628205 0.79628205 0.79628205 0.79628205 0.79628205\n",
      " 0.79628205 0.79628205 0.79628205        nan 0.79628205 0.79628205\n",
      " 0.79628205 0.79628205 0.79628205 0.79628205 0.79628205 0.79628205\n",
      "        nan 0.79306865 0.79306865 0.79306865 0.79306865 0.79306865\n",
      " 0.79306865 0.79306865 0.79306865        nan 0.79306865 0.79306865\n",
      " 0.79306865 0.79306865 0.79306865 0.79306865 0.79306865 0.79306865\n",
      "        nan 0.79306865 0.79306865 0.79306865 0.79306865 0.79306865\n",
      " 0.79306865 0.79306865 0.79306865        nan 0.79306865 0.79306865\n",
      " 0.79306865 0.79306865 0.79306865 0.79306865 0.79306865 0.79306865\n",
      "        nan 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251        nan 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      "        nan 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251        nan 0.85733251 0.85733251\n",
      " 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251 0.85733251\n",
      "        nan 0.88754342 0.88754342 0.88754342 0.88754342 0.88754342\n",
      " 0.88754342 0.88754342 0.88754342        nan 0.88754342 0.88754342\n",
      " 0.88754342 0.88754342 0.88754342 0.88754342 0.88754342 0.88754342\n",
      "        nan 0.88754342 0.88754342 0.88754342 0.88754342 0.88754342\n",
      " 0.88754342 0.88754342 0.88754342        nan 0.88754342 0.88754342\n",
      " 0.88754342 0.88754342 0.88754342 0.88754342 0.88754342 0.88754342\n",
      "        nan 0.91710091 0.91710091 0.91710091 0.91710091 0.91710091\n",
      " 0.91774194 0.91774194 0.91774194        nan 0.91774194 0.91774194\n",
      " 0.91774194 0.91774194 0.91774194 0.91774194 0.91774194 0.91774194\n",
      "        nan 0.91774194 0.91774194 0.91774194 0.91774194 0.91774194\n",
      " 0.91774194 0.91774194 0.91774194        nan 0.91774194 0.91774194\n",
      " 0.91774194 0.91774194 0.91774194 0.91774194 0.91774194 0.91774194\n",
      "        nan 0.9492349  0.9492349  0.9492349  0.95052109 0.95052109\n",
      " 0.95116212 0.95116212 0.95116212        nan 0.95116212 0.95116212\n",
      " 0.95116212 0.95116212 0.95116212 0.95116212 0.95116212 0.95116212\n",
      "        nan 0.95116212 0.95116212 0.95116212 0.95116212 0.95116212\n",
      " 0.95116212 0.95116212 0.95116212        nan 0.9530976  0.9530976\n",
      " 0.9530976  0.9530976  0.9530976  0.9530976  0.9530976  0.9530976\n",
      "        nan 0.96143507 0.96143507 0.9556493  0.95629446 0.95500827\n",
      " 0.95436311 0.95436311 0.95436311        nan 0.95822167 0.95822167\n",
      " 0.95822167 0.95758065 0.95629446 0.95436311 0.95436311 0.95436311\n",
      "        nan 0.95565343 0.95565343 0.95565343 0.95565343 0.95565343\n",
      " 0.95436311 0.95500414 0.95500414        nan 0.95565343 0.95565343\n",
      " 0.95565343 0.95565343 0.95565343 0.95565343 0.95565343 0.95565343\n",
      "        nan 0.96272126 0.96208023 0.95629032 0.95629446 0.95629446\n",
      " 0.95951199 0.96015302 0.96015302        nan 0.96079404 0.96079404\n",
      " 0.96079404 0.95951199 0.95886683 0.96080232 0.96144334 0.96144334\n",
      "        nan 0.96144748 0.96144748 0.96144748 0.96144748 0.96144748\n",
      " 0.96209264 0.96337469 0.96208437        nan 0.96080645 0.96080645\n",
      " 0.96080645 0.96080645 0.96080645 0.96080645 0.96080645 0.96080645\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409        nan 0.77634409 0.77634409\n",
      " 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409 0.77634409\n",
      "        nan 0.78794872 0.78794872 0.78794872 0.78794872 0.78794872\n",
      " 0.78794872 0.78794872 0.78794872        nan 0.78794872 0.78794872\n",
      " 0.78794872 0.78794872 0.78794872 0.78794872 0.78794872 0.78794872\n",
      "        nan 0.78794872 0.78794872 0.78794872 0.78794872 0.78794872\n",
      " 0.78794872 0.78794872 0.78794872        nan 0.78794872 0.78794872\n",
      " 0.78794872 0.78794872 0.78794872 0.78794872 0.78794872 0.78794872\n",
      "        nan 0.78408189 0.78408189 0.78408189 0.78408189 0.78408189\n",
      " 0.78408189 0.78408189 0.78408189        nan 0.78408189 0.78408189\n",
      " 0.78408189 0.78408189 0.78408189 0.78408189 0.78408189 0.78408189\n",
      "        nan 0.78408189 0.78408189 0.78408189 0.78408189 0.78408189\n",
      " 0.78408189 0.78408189 0.78408189        nan 0.78408189 0.78408189\n",
      " 0.78408189 0.78408189 0.78408189 0.78408189 0.78408189 0.78408189\n",
      "        nan 0.8541067  0.8541067  0.8541067  0.8541067  0.8541067\n",
      " 0.8541067  0.8541067  0.8541067         nan 0.8541067  0.8541067\n",
      " 0.8541067  0.8541067  0.8541067  0.8541067  0.8541067  0.8541067\n",
      "        nan 0.8541067  0.8541067  0.8541067  0.8541067  0.8541067\n",
      " 0.8541067  0.8541067  0.8541067         nan 0.8541067  0.8541067\n",
      " 0.8541067  0.8541067  0.8541067  0.8541067  0.8541067  0.8541067\n",
      "        nan 0.87404467 0.87404467 0.87404467 0.87404467 0.87404467\n",
      " 0.87404467 0.87404467 0.87404467        nan 0.87404467 0.87404467\n",
      " 0.87404467 0.87404467 0.87404467 0.87404467 0.87404467 0.87404467\n",
      "        nan 0.87404467 0.87404467 0.87404467 0.87404467 0.87404467\n",
      " 0.87404467 0.87404467 0.87404467        nan 0.87404467 0.87404467\n",
      " 0.87404467 0.87404467 0.87404467 0.87404467 0.87404467 0.87404467\n",
      "        nan 0.92095533 0.92095533 0.92095533 0.92095533 0.92095533\n",
      " 0.92095533 0.92095533 0.92095533        nan 0.92095533 0.92095533\n",
      " 0.92095533 0.92095533 0.92095533 0.92095533 0.92095533 0.92095533\n",
      "        nan 0.92159636 0.92159636 0.92159636 0.92159636 0.92159636\n",
      " 0.92159636 0.92159636 0.92159636        nan 0.92159636 0.92159636\n",
      " 0.92159636 0.92159636 0.92159636 0.92159636 0.92159636 0.92159636\n",
      "        nan 0.94409016 0.94409016 0.94409016 0.94537634 0.94280397\n",
      " 0.94280397 0.94280397 0.94280397        nan 0.94537634 0.94537634\n",
      " 0.94537634 0.94537634 0.94280397 0.94280397 0.94280397 0.94280397\n",
      "        nan 0.943445   0.943445   0.943445   0.943445   0.943445\n",
      " 0.943445   0.943445   0.943445          nan 0.94537221 0.94537221\n",
      " 0.94537221 0.94537221 0.94537221 0.94537221 0.94537221 0.94537221\n",
      "        nan 0.96014888 0.96014888 0.95500827 0.95565343 0.95179487\n",
      " 0.95436725 0.95436725 0.95436725        nan 0.95565343 0.95565343\n",
      " 0.95565343 0.95501241 0.95179487 0.95436725 0.95436725 0.95436725\n",
      "        nan 0.95307692 0.95307692 0.95307692 0.95307692 0.95307692\n",
      " 0.95371795 0.95371795 0.95371795        nan 0.95178246 0.95178246\n",
      " 0.95178246 0.95178246 0.95178246 0.95178246 0.95178246 0.95178246\n",
      "        nan 0.96721257 0.96592639 0.96142266 0.96335401 0.95949132\n",
      " 0.9607775  0.96142266 0.96271299        nan 0.96334988 0.96334988\n",
      " 0.96334988 0.96335401 0.96078164 0.96206782 0.96271299 0.96400331\n",
      "        nan 0.9652895  0.9652895  0.9652895  0.9652895  0.9652895\n",
      " 0.96464433 0.9652895  0.96464433        nan 0.96336228 0.96336228\n",
      " 0.96336228 0.96336228 0.96336228 0.96336228 0.96336228 0.96271712]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 720 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.79886683 0.79886683 0.79886683 0.79886683 0.79886683\n",
      " 0.79886683 0.79886683 0.79886683        nan 0.79886683 0.79886683\n",
      " 0.79886683 0.79886683 0.79886683 0.79886683 0.79886683 0.79886683\n",
      "        nan 0.79886683 0.79886683 0.79886683 0.79886683 0.79886683\n",
      " 0.79886683 0.79886683 0.79886683        nan 0.79886683 0.79886683\n",
      " 0.79886683 0.79886683 0.79886683 0.79886683 0.79886683 0.79886683\n",
      "        nan 0.7956493  0.7956493  0.7956493  0.7956493  0.7956493\n",
      " 0.7956493  0.7956493  0.7956493         nan 0.7956493  0.7956493\n",
      " 0.7956493  0.7956493  0.7956493  0.7956493  0.7956493  0.7956493\n",
      "        nan 0.7956493  0.7956493  0.7956493  0.7956493  0.7956493\n",
      " 0.7956493  0.7956493  0.7956493         nan 0.7956493  0.7956493\n",
      " 0.7956493  0.7956493  0.7956493  0.7956493  0.7956493  0.7956493\n",
      "        nan 0.87598842 0.87598842 0.87598842 0.87598842 0.87598842\n",
      " 0.87598842 0.87598842 0.87598842        nan 0.87598842 0.87598842\n",
      " 0.87598842 0.87598842 0.87598842 0.87598842 0.87598842 0.87598842\n",
      "        nan 0.87598842 0.87598842 0.87598842 0.87598842 0.87598842\n",
      " 0.87598842 0.87598842 0.87598842        nan 0.87598842 0.87598842\n",
      " 0.87598842 0.87598842 0.87598842 0.87598842 0.87598842 0.87598842\n",
      "        nan 0.88627378 0.88627378 0.88627378 0.88627378 0.88627378\n",
      " 0.88627378 0.88627378 0.88627378        nan 0.88627378 0.88627378\n",
      " 0.88627378 0.88627378 0.88627378 0.88627378 0.88627378 0.88627378\n",
      "        nan 0.88627378 0.88627378 0.88627378 0.88627378 0.88627378\n",
      " 0.88627378 0.88627378 0.88627378        nan 0.88627378 0.88627378\n",
      " 0.88627378 0.88627378 0.88627378 0.88627378 0.88627378 0.88627378\n",
      "        nan 0.92738627 0.92738627 0.92738627 0.92738627 0.92738627\n",
      " 0.92738627 0.92738627 0.92738627        nan 0.92738627 0.92738627\n",
      " 0.92738627 0.92738627 0.92738627 0.92738627 0.92738627 0.92738627\n",
      "        nan 0.92738627 0.92738627 0.92738627 0.92738627 0.92738627\n",
      " 0.92738627 0.92738627 0.92738627        nan 0.92803143 0.92803143\n",
      " 0.92803143 0.92803143 0.92803143 0.92803143 0.92803143 0.92803143\n",
      "        nan 0.9370306  0.9370306  0.93638544 0.93638544 0.93638544\n",
      " 0.93638544 0.93638544 0.93638544        nan 0.93638544 0.93638544\n",
      " 0.93638544 0.93638544 0.93638544 0.93638544 0.93638544 0.93638544\n",
      "        nan 0.93638544 0.93638544 0.93638544 0.93638544 0.93638544\n",
      " 0.93638544 0.93638544 0.93638544        nan 0.94023987 0.94023987\n",
      " 0.94023987 0.94023987 0.94023987 0.94023987 0.94023987 0.94023987\n",
      "        nan 0.96013648 0.95949545 0.95371381 0.95242763 0.9492225\n",
      " 0.94986766 0.94665012 0.94665012        nan 0.95243176 0.95243176\n",
      " 0.95243176 0.9517866  0.9492225  0.94986766 0.94665012 0.94665012\n",
      "        nan 0.94858561 0.94858561 0.94858561 0.94858561 0.94858561\n",
      " 0.94858561 0.94536807 0.94536807        nan 0.94729529 0.94729529\n",
      " 0.94729529 0.94729529 0.94729529 0.94729529 0.94729529 0.94729529\n",
      "        nan 0.96851944 0.97044665 0.96144334 0.96143921 0.95759305\n",
      " 0.95566584 0.95116625 0.95051696        nan 0.96144334 0.96144334\n",
      " 0.96144334 0.96079818 0.95759305 0.95566584 0.95181141 0.95116212\n",
      "        nan 0.95695616 0.95695616 0.95695616 0.95695616 0.95695616\n",
      " 0.95566584 0.95181141 0.95116212        nan 0.95438792 0.95438792\n",
      " 0.95438792 0.95438792 0.95438792 0.95438792 0.95438792 0.95373863\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593 0.69987593\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649        nan 0.77635649 0.77635649\n",
      " 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649 0.77635649\n",
      "        nan 0.77508685 0.77508685 0.77508685 0.77508685 0.77508685\n",
      " 0.77508685 0.77508685 0.77508685        nan 0.77508685 0.77508685\n",
      " 0.77508685 0.77508685 0.77508685 0.77508685 0.77508685 0.77508685\n",
      "        nan 0.77508685 0.77508685 0.77508685 0.77508685 0.77508685\n",
      " 0.77508685 0.77508685 0.77508685        nan 0.77508685 0.77508685\n",
      " 0.77508685 0.77508685 0.77508685 0.77508685 0.77508685 0.77508685\n",
      "        nan 0.79499173 0.79499173 0.79499173 0.79499173 0.79499173\n",
      " 0.79499173 0.79499173 0.79499173        nan 0.79499173 0.79499173\n",
      " 0.79499173 0.79499173 0.79499173 0.79499173 0.79499173 0.79499173\n",
      "        nan 0.79499173 0.79499173 0.79499173 0.79499173 0.79499173\n",
      " 0.79499173 0.79499173 0.79499173        nan 0.79499173 0.79499173\n",
      " 0.79499173 0.79499173 0.79499173 0.79499173 0.79499173 0.79499173\n",
      "        nan 0.85669975 0.85669975 0.85669975 0.85669975 0.85669975\n",
      " 0.85669975 0.85669975 0.85669975        nan 0.85669975 0.85669975\n",
      " 0.85669975 0.85669975 0.85669975 0.85669975 0.85669975 0.85669975\n",
      "        nan 0.85669975 0.85669975 0.85669975 0.85669975 0.85669975\n",
      " 0.85669975 0.85669975 0.85669975        nan 0.85669975 0.85669975\n",
      " 0.85669975 0.85669975 0.85669975 0.85669975 0.85669975 0.85669975\n",
      "        nan 0.86247725 0.86247725 0.86247725 0.86247725 0.86247725\n",
      " 0.86247725 0.86247725 0.86247725        nan 0.86247725 0.86247725\n",
      " 0.86247725 0.86247725 0.86247725 0.86247725 0.86247725 0.86247725\n",
      "        nan 0.86247725 0.86247725 0.86247725 0.86247725 0.86247725\n",
      " 0.86247725 0.86247725 0.86247725        nan 0.86247725 0.86247725\n",
      " 0.86247725 0.86247725 0.86247725 0.86247725 0.86247725 0.86247725\n",
      "        nan 0.9138751  0.9138751  0.9138751  0.91452026 0.91452026\n",
      " 0.91452026 0.91452026 0.91452026        nan 0.91452026 0.91452026\n",
      " 0.91452026 0.91452026 0.91452026 0.91452026 0.91452026 0.91452026\n",
      "        nan 0.91452026 0.91452026 0.91452026 0.91452026 0.91452026\n",
      " 0.91452026 0.91452026 0.91452026        nan 0.91452026 0.91452026\n",
      " 0.91452026 0.91452026 0.91452026 0.91452026 0.91452026 0.91452026\n",
      "        nan 0.94343259 0.94343259 0.94343259 0.94407775 0.94407361\n",
      " 0.94406948 0.94406948 0.9421464         nan 0.9447105  0.9447105\n",
      " 0.9447105  0.9447105  0.9447105  0.9447105  0.9447105  0.94278743\n",
      "        nan 0.9447105  0.9447105  0.9447105  0.9447105  0.9447105\n",
      " 0.9447105  0.9447105  0.94278743        nan 0.94343259 0.94343259\n",
      " 0.94343259 0.94343259 0.94343259 0.94343259 0.94343259 0.94343259\n",
      "        nan 0.96210918 0.96146402 0.96081886 0.95888751 0.95695203\n",
      " 0.95501654 0.95373449 0.95245244        nan 0.96210091 0.96210091\n",
      " 0.96210091 0.9595244  0.95694789 0.95501654 0.95437552 0.95309347\n",
      "        nan 0.9556617  0.9556617  0.9556617  0.9556617  0.9556617\n",
      " 0.95501654 0.95501654 0.95309347        nan 0.95501654 0.95501654\n",
      " 0.95501654 0.95501654 0.95501654 0.95501654 0.95501654 0.95501654\n",
      "        nan 0.96980976 0.97045906 0.96532258 0.96339537 0.96210091\n",
      " 0.95823821 0.95566998 0.95502895        nan 0.96532258 0.96532258\n",
      " 0.96532258 0.96467328 0.9627378  0.95887924 0.95695616 0.95631514\n",
      "        nan 0.96209264 0.96209264 0.96209264 0.96209264 0.96209264\n",
      " 0.95952026 0.95823821 0.95631514        nan 0.95758892 0.95758892\n",
      " 0.95758892 0.95758892 0.95758892 0.95758892 0.95758892 0.95823408]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set up possible values of parameters to optimize over\n",
    "param_dict={'criterion':['gini','entropy'], 'max_depth':range(1,11), 'min_samples_leaf':range(1,5), \n",
    "            'min_samples_split':range(1,10)} \n",
    "d_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid_tree = GridSearchCV(d_tree, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_tree.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "nested_score_tree = cross_val_score(grid_tree, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['decision_tree']['mean'] = np.mean(nested_score_tree)\n",
    "f_measure_score_c['decision_tree']['std'] = np.std(nested_score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "358a29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.94      0.88      0.91       129\n",
      "        good       0.73      0.95      0.83        20\n",
      "       unacc       0.98      0.99      0.99       397\n",
      "       vgood       0.83      0.80      0.82        25\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f2fdc73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b05036",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3b284f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70268366        nan 0.70268366 0.70268366\n",
      " 0.70268366 0.70268366        nan        nan 0.70268366        nan\n",
      " 0.70268366 0.70268366 0.70268366 0.70268366        nan        nan\n",
      " 0.70268366        nan 0.71132684 0.71132684 0.71132684 0.71132684\n",
      "        nan        nan 0.90491754        nan 0.90148426 0.90148426\n",
      " 0.90148426 0.90148426        nan        nan 0.84270615        nan\n",
      " 0.8495952  0.8495952  0.8495952  0.8495952         nan        nan\n",
      " 0.92997001        nan 0.92306597 0.90228636 0.92306597 0.92392804\n",
      "        nan        nan 0.93342579        nan 0.93256372 0.90317091\n",
      " 0.93256372 0.93256372        nan        nan 0.93342579        nan\n",
      " 0.93256372 0.91438531 0.93342579 0.93256372]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.73183209 0.73183209 0.73183209 0.73183209\n",
      "        nan        nan 0.91639371        nan 0.90354012 0.90354012\n",
      " 0.90354012 0.90354012        nan        nan 0.85078164        nan\n",
      " 0.85980976 0.85980976 0.85980976 0.85980976        nan        nan\n",
      " 0.9298842         nan 0.92796526 0.90802316 0.92732423 0.92796526\n",
      "        nan        nan 0.93180314        nan 0.93052109 0.91318031\n",
      " 0.93052109 0.93244417        nan        nan 0.93115798        nan\n",
      " 0.93308933 0.92026882 0.93180314 0.93308933]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.73312242 0.73312242 0.73312242 0.73312242\n",
      "        nan        nan 0.91641853        nan 0.91062035 0.91126137\n",
      " 0.91062035 0.91062035        nan        nan 0.85145161        nan\n",
      " 0.85979322 0.85979322 0.85979322 0.85979322        nan        nan\n",
      " 0.93248553        nan 0.92798594 0.91061208 0.92669975 0.92862696\n",
      "        nan        nan 0.93377585        nan 0.93377585 0.93120347\n",
      " 0.93377585 0.93377585        nan        nan 0.93377585        nan\n",
      " 0.93378412 0.92861456 0.93377585 0.93313896]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.7343962  0.7343962  0.7343962  0.7343962\n",
      "        nan        nan 0.91383375        nan 0.90677006 0.90741108\n",
      " 0.90677006 0.90677006        nan        nan 0.85595947        nan\n",
      " 0.8610794  0.8610794  0.8610794  0.8610794         nan        nan\n",
      " 0.93184036        nan 0.92991315 0.90736146 0.92991315 0.92991315\n",
      "        nan        nan 0.93119934        nan 0.93055418 0.92028122\n",
      " 0.9311952  0.93119934        nan        nan 0.93119934        nan\n",
      " 0.93312655 0.926067   0.93119934 0.93248553]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.73504549 0.73504549 0.73504549 0.73504549\n",
      "        nan        nan 0.91770471        nan 0.91318859 0.91254756\n",
      " 0.91318859 0.91318859        nan        nan 0.8553019         nan\n",
      " 0.86108354 0.86108354 0.86108354 0.86108354        nan        nan\n",
      " 0.93311828        nan 0.93247725 0.90485112 0.93183623 0.93247725\n",
      "        nan        nan 0.93311828        nan 0.9344086  0.93056658\n",
      " 0.93376344 0.93376344        nan        nan 0.93375931        nan\n",
      " 0.93440447 0.93182382 0.93311828 0.93440447]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.73633995 0.73633995 0.73633995 0.73633995\n",
      "        nan        nan 0.9138172         nan 0.90932589 0.90932589\n",
      " 0.90932589 0.90932589        nan        nan 0.84950372        nan\n",
      " 0.85656741 0.85656741 0.85656741 0.85656741        nan        nan\n",
      " 0.92924318        nan 0.92538875 0.91257651 0.92602978 0.92602978\n",
      "        nan        nan 0.93052109        nan 0.93117039 0.91253102\n",
      " 0.93052523 0.93052109        nan        nan 0.93052109        nan\n",
      " 0.93181555 0.92215881 0.93052109 0.93245658]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.73054177 0.73054177 0.73054177 0.73054177\n",
      "        nan        nan 0.91832093        nan 0.90866832 0.90930935\n",
      " 0.90866832 0.90866832        nan        nan 0.85529777        nan\n",
      " 0.86300248 0.86300248 0.86300248 0.86300248        nan        nan\n",
      " 0.9279818         nan 0.92733664 0.91385856 0.92734078 0.92734078\n",
      "        nan        nan 0.92862283        nan 0.92862283 0.90289495\n",
      " 0.92862283 0.92862283        nan        nan 0.92862283        nan\n",
      " 0.92669148 0.92093052 0.92862283 0.92669148]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.72991729 0.72991729 0.72991729 0.72991729\n",
      "        nan        nan 0.91380893        nan 0.90673284 0.90545079\n",
      " 0.90673284 0.90673284        nan        nan 0.85398263        nan\n",
      " 0.85528122 0.85528122 0.85528122 0.85528122        nan        nan\n",
      " 0.9305335         nan 0.93117866 0.91060794 0.9305335  0.93117866\n",
      "        nan        nan 0.93117866        nan 0.93181969 0.92669148\n",
      " 0.9305335  0.93117866        nan        nan 0.93117866        nan\n",
      " 0.93246071 0.92666667 0.93117866 0.93310174]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.70032672        nan 0.70032672 0.70032672\n",
      " 0.70032672 0.70032672        nan        nan 0.70032672        nan\n",
      " 0.70032672 0.70032672 0.70032672 0.70032672        nan        nan\n",
      " 0.70032672        nan 0.73377171 0.73377171 0.73377171 0.73377171\n",
      "        nan        nan 0.91444169        nan 0.91057899 0.91122002\n",
      " 0.91057899 0.91057899        nan        nan 0.85656741        nan\n",
      " 0.85141853 0.85141853 0.85141853 0.85141853        nan        nan\n",
      " 0.93372622        nan 0.93180314 0.91058726 0.93180314 0.93180314\n",
      "        nan        nan 0.93501241        nan 0.93436725 0.91701406\n",
      " 0.93501241 0.93501241        nan        nan 0.93501241        nan\n",
      " 0.93565343 0.92086849 0.93501241 0.93565757]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593        nan        nan 0.69987593        nan\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593        nan        nan\n",
      " 0.69987593        nan 0.73522333 0.73522333 0.73522333 0.73522333\n",
      "        nan        nan 0.9203019         nan 0.91901572 0.91901572\n",
      " 0.91901572 0.91901572        nan        nan 0.85028536        nan\n",
      " 0.86247312 0.86247312 0.86247312 0.86247312        nan        nan\n",
      " 0.93251861        nan 0.93123242 0.90805624 0.93123242 0.93123242\n",
      "        nan        nan 0.93251861        nan 0.93251447 0.92032672\n",
      " 0.93315964 0.93251861        nan        nan 0.93251861        nan\n",
      " 0.93508685 0.93057072 0.93251861 0.93508685]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 64 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.69987593        nan 0.69987593 0.69987593\n",
      " 0.69987593 0.69987593        nan        nan 0.69987593        nan\n",
      " 0.69987593 0.69987593 0.69987593 0.69987593        nan        nan\n",
      " 0.69987593        nan 0.73651365 0.73651365 0.73651365 0.73651365\n",
      "        nan        nan 0.91647643        nan 0.91198098 0.91198098\n",
      " 0.91198098 0.91198098        nan        nan 0.85541356        nan\n",
      " 0.85992142 0.85992142 0.85992142 0.85992142        nan        nan\n",
      " 0.93445823        nan 0.93059553 0.9177378  0.92995037 0.93059553\n",
      "        nan        nan 0.93510339        nan 0.93381307 0.92224979\n",
      " 0.93445823 0.93445823        nan        nan 0.93510339        nan\n",
      " 0.93445823 0.92672457 0.93510339 0.93509926]\n",
      "  warnings.warn(\n",
      "/Users/jasminhsu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'C':[0.0001,0.001, 0.01, 1, 0.1, 10, 100, 1000], 'penalty':['l1','l2'],\n",
    "              'solver':['lbfgs','sag','saga','newton-cg']}\n",
    "\n",
    "logistic = linear_model.LogisticRegression(random_state=42)\n",
    "\n",
    "grid_log = GridSearchCV(logistic, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_log.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = grid_log.predict(X_test)\n",
    "nested_score_log = cross_val_score(grid_log, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['logistic']['mean'] = np.mean(nested_score_log)\n",
    "f_measure_score_c['logistic']['std'] = np.std(nested_score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "590de22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.91      0.82      0.86       129\n",
      "        good       0.72      0.90      0.80        20\n",
      "       unacc       0.97      0.97      0.97       397\n",
      "       vgood       0.80      0.96      0.87        25\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.85      0.91      0.88       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_log),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "097efa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'penalty': 'l1', 'solver': 'saga'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_log.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8a638",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a4cece7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n",
      "Fitting 10 folds for each of 60 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'n_neighbors':list(range(1,31)), 'weights':['uniform', 'distance']}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "grid_knn = GridSearchCV(knn, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "nested_score_knn = cross_val_score(grid_knn, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['knn']['mean'] = np.mean(nested_score_knn)\n",
    "f_measure_score_c['knn']['std'] = np.std(nested_score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4285442f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.80      0.86      0.83       129\n",
      "        good       0.57      0.20      0.30        20\n",
      "       unacc       0.96      0.99      0.98       397\n",
      "       vgood       0.93      0.56      0.70        25\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.65      0.70       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e1135fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9, 'weights': 'distance'}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6d6a2",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fa31f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "nested_score_nb = cross_val_score(nb, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['NB']['mean'] = np.mean(nested_score_nb)\n",
    "f_measure_score_c['NB']['std'] = np.std(nested_score_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1ef33bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.59      0.77      0.67       129\n",
      "        good       0.44      0.85      0.58        20\n",
      "       unacc       1.00      0.83      0.90       397\n",
      "       vgood       0.68      1.00      0.81        25\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.68      0.86      0.74       571\n",
      "weighted avg       0.87      0.82      0.84       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_nb),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff1da7",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0aeb906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n",
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    }
   ],
   "source": [
    "param_dict = {'C':[0.1,1,100,1000],'kernel':['rbf','linear'], 'gamma':[1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "svm = SVC(probability=True)\n",
    "\n",
    "grid_svm = GridSearchCV(svm, param_dict, cv=cv, n_jobs=-1, verbose=1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "nested_score_svm = cross_val_score(grid_svm, X=X, y=y, cv=cv) \n",
    "f_measure_score_c['svm']['mean'] = np.mean(nested_score_svm)\n",
    "f_measure_score_c['svm']['std'] = np.std(nested_score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "072f8626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.98      0.97      0.98       129\n",
      "        good       0.86      0.95      0.90        20\n",
      "       unacc       1.00      1.00      1.00       397\n",
      "       vgood       0.92      0.92      0.92        25\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.96      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_svm),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0cf639b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View best hyperparameters\n",
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8c77e",
   "metadata": {},
   "source": [
    "### Models Comparision (categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b0713dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree :  {'mean': 0.972788681274365, 'std': 0.011899684402510432}\n",
      "knn :  {'mean': 0.9317112515123, 'std': 0.0171712971111848}\n",
      "logistic :  {'mean': 0.9346014249227046, 'std': 0.01830887424272436}\n",
      "NB :  {'mean': 0.8026582874042208, 'std': 0.03286866941083019}\n",
      "svm :  {'mean': 0.9982591746202447, 'std': 0.0026591688489214986}\n"
     ]
    }
   ],
   "source": [
    "for a,b in f_measure_score_c.items():\n",
    "    print(a, ': ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8a5d9",
   "metadata": {},
   "source": [
    "#### Result: SVM outperforms other models in categorical attempt\n",
    "#### We should treat variables as categorical. Because SVM model would calculate the distance using the method of numeric data, but distance between categories cannot be measured. Thus, it's not a good method to use numeric variable in this kind of cases, although the outcome seems exceptional."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
